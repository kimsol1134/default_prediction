"""
ë¶€ë„ ì˜ˆì¸¡ ëª¨ë¸ ë¡œë”© ë° ì˜ˆì¸¡

Part3 ë…¸íŠ¸ë¶ê³¼ ë™ì¼í•œ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰
í•™ìŠµëœ ëª¨ë¸ì„ ë¡œë“œí•˜ê³  ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•´ ì˜ˆì¸¡ ìˆ˜í–‰
"""

import joblib
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, Optional
import logging
import sys

# ì „ì²˜ë¦¬ ëª¨ë“ˆ import (pickle ë¡œë”©ì„ ìœ„í•´ í´ë˜ìŠ¤ë“¤ import í•„ìš”)
try:
    from src.preprocessing.transformers import (
        create_preprocessing_pipeline,
        InfiniteHandler,
        LogTransformer,
        Winsorizer
    )
except ImportError:
    # deployment í´ë”ì—ì„œ ì‹¤í–‰ë  ê²½ìš°
    try:
        from preprocessing.transformers import (
            create_preprocessing_pipeline,
            InfiniteHandler,
            LogTransformer,
            Winsorizer
        )
    except ImportError:
        create_preprocessing_pipeline = None
        InfiniteHandler = None
        LogTransformer = None
        Winsorizer = None
        logging.warning("ì „ì²˜ë¦¬ ëª¨ë“ˆì„ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì „ì²˜ë¦¬ ì‚¬ìš©")

logger = logging.getLogger(__name__)


class BankruptcyPredictor:
    """
    ë¶€ë„ ì˜ˆì¸¡ ëª¨ë¸

    Part3 ë…¸íŠ¸ë¶ê³¼ ë™ì¼í•œ íŒŒì´í”„ë¼ì¸ ì§€ì›:
    - ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ (InfiniteHandler, LogTransformer, Scaler ë“±)
    - ì „ì²´ íŒŒì´í”„ë¼ì¸ (ì „ì²˜ë¦¬ + ëª¨ë¸)
    - íœ´ë¦¬ìŠ¤í‹± ë°©ì‹ (ëª¨ë¸ ì—†ì„ ë•Œ)
    """

    def __init__(
        self,
        model_path: Optional[Path] = None,
        pipeline_path: Optional[Path] = None,
        scaler_path: Optional[Path] = None,
        use_pipeline: bool = True
    ):
        """
        Args:
            model_path: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (ë‹¨ë… ëª¨ë¸)
            pipeline_path: íŒŒì´í”„ë¼ì¸ íŒŒì¼ ê²½ë¡œ (ì „ì²˜ë¦¬ + ëª¨ë¸)
            scaler_path: ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ ê²½ë¡œ (ë‹¨ë… ìŠ¤ì¼€ì¼ëŸ¬)
            use_pipeline: íŒŒì´í”„ë¼ì¸ ì‚¬ìš© ì—¬ë¶€ (Part3 ë°©ì‹)
        """
        self.model = None
        self.pipeline = None
        self.scaler = None
        self.preprocessing_pipeline = None

        self.model_path = model_path
        self.pipeline_path = pipeline_path
        self.scaler_path = scaler_path
        self.use_pipeline = use_pipeline
        self.expected_features = None

    def load_model(self):
        """
        ëª¨ë¸ ë¡œë“œ (ìš°ì„ ìˆœìœ„):
        1. ì „ì²´ íŒŒì´í”„ë¼ì¸ (ì „ì²˜ë¦¬ + ëª¨ë¸) - Part3 ë°©ì‹
        2. ëª¨ë¸ + ìŠ¤ì¼€ì¼ëŸ¬ ë¶„ë¦¬
        3. íœ´ë¦¬ìŠ¤í‹± ë°©ì‹
        """
        try:
            # 1. ì „ì²´ íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì‹œë„ (Part3 ë°©ì‹)
            if self.use_pipeline and self.pipeline_path and self.pipeline_path.exists():
                logger.info(f"ğŸ“¦ ì „ì²´ íŒŒì´í”„ë¼ì¸ ë¡œë”© ì¤‘: {self.pipeline_path}")
                self.pipeline = joblib.load(self.pipeline_path)
                logger.info("âœ“ Part3 íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì„±ê³µ!")
                
                if hasattr(self.pipeline, 'steps'):
                    logger.info(f"   íŒŒì´í”„ë¼ì¸ ë‹¨ê³„: {len(self.pipeline.steps)}ê°œ")
                    for step_name, _ in self.pipeline.steps:
                        logger.info(f"   - {step_name}")
                elif hasattr(self.pipeline, 'estimators_'):
                    logger.info(f"   ëª¨ë¸ íƒ€ì…: VotingClassifier (estimators: {len(self.pipeline.estimators_)})")
                else:
                    logger.info(f"   ëª¨ë¸ íƒ€ì…: {type(self.pipeline).__name__}")
                return

            # 2. ëª¨ë¸ ë‹¨ë… ë¡œë“œ
            if self.model_path and self.model_path.exists():
                logger.info(f"ğŸ¯ ëª¨ë¸ ë¡œë”© ì¤‘: {self.model_path}")
                self.model = joblib.load(self.model_path)
                logger.info("âœ“ ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
            else:
                logger.warning("ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                self.model = None

            # 3. ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
            if self.scaler_path and self.scaler_path.exists():
                logger.info(f"ğŸ“ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë”© ì¤‘: {self.scaler_path}")
                self.scaler = joblib.load(self.scaler_path)
                logger.info("âœ“ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì„±ê³µ")
            else:
                logger.warning("ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

                # ìŠ¤ì¼€ì¼ëŸ¬ ì—†ìœ¼ë©´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ìƒì„±
                if create_preprocessing_pipeline:
                    logger.info("ê¸°ë³¸ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ìƒì„± ì¤‘...")
                    self.preprocessing_pipeline = create_preprocessing_pipeline(
                        use_log_transform=True,
                        use_winsorizer=False,
                        scaler_type='robust'
                    )
                    logger.info("âœ“ Part3 ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ìƒì„± ì™„ë£Œ")

        except Exception as e:
            logger.error(f"ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
            logger.warning("íœ´ë¦¬ìŠ¤í‹± ë°©ì‹ìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            self.model = None
            self.pipeline = None
            self.scaler = None

    def predict(self, features_df: pd.DataFrame) -> Dict:
        """
        ë¶€ë„ í™•ë¥  ì˜ˆì¸¡

        Args:
            features_df: íŠ¹ì„± DataFrame (1í–‰)

        Returns:
            {
                'bankruptcy_probability': 0.15,
                'risk_level': 'ì£¼ì˜',
                'confidence': 0.85,
                'features_used': [...],
                'model_info': {...}
            }
        """
        try:
            # 1. ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‚¬ìš© (Part3 ë°©ì‹)
            if self.pipeline is not None:
                logger.info("Part3 íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì˜ˆì¸¡ ì¤‘...")
                X = self._prepare_features(features_df)

                # íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì§ì ‘ ì˜ˆì¸¡
                if hasattr(self.pipeline, 'predict_proba'):
                    proba = self.pipeline.predict_proba(X)[0]
                    bankruptcy_prob = proba[1]
                    confidence = max(proba)
                else:
                    prediction = self.pipeline.predict(X)[0]
                    bankruptcy_prob = 0.8 if prediction == 1 else 0.2
                    confidence = 0.7

                # íŒŒì´í”„ë¼ì¸ ë‚´ë¶€ ëª¨ë¸ ì¶”ì¶œ (SHAPìš©)
                # Part4 ë…¸íŠ¸ë¶ ë°©ì‹: Pipelineì˜ ë§ˆì§€ë§‰ ë‹¨ê³„ (CatBoost) ì¶”ì¶œ
                if hasattr(self.pipeline, 'steps'):
                    # Pipelineì˜ ë§ˆì§€ë§‰ ë‹¨ê³„ê°€ classifier (CatBoost)
                    model_for_shap = self.pipeline.steps[-1][1]
                    logger.info(f"   - Pipelineì—ì„œ ìµœì¢… ëª¨ë¸ ì¶”ì¶œ: {type(model_for_shap).__name__}")

                    # VotingClassifierì¸ ê²½ìš° SHAP ê³„ì‚° ìŠ¤í‚µ
                    if hasattr(model_for_shap, 'estimators_'):
                        logger.warning("VotingClassifierëŠ” SHAP TreeExplainer ë¯¸ì§€ì› - SHAP ê³„ì‚° ìƒëµ")
                        model_for_shap = None

                elif hasattr(self.pipeline, 'named_steps'):
                    model_for_shap = self.pipeline.named_steps.get('classifier', self.pipeline)
                    if hasattr(model_for_shap, 'estimators_'):
                        logger.warning("VotingClassifierëŠ” SHAP TreeExplainer ë¯¸ì§€ì› - SHAP ê³„ì‚° ìƒëµ")
                        model_for_shap = None
                else:
                    model_for_shap = self.pipeline
                    if hasattr(model_for_shap, 'estimators_'):
                        logger.warning("VotingClassifierëŠ” SHAP TreeExplainer ë¯¸ì§€ì› - SHAP ê³„ì‚° ìƒëµ")
                        model_for_shap = None

                # SHAP ê³„ì‚°ìš© ë°ì´í„°ëŠ” ì „ì²˜ë¦¬ëœ ë°ì´í„° (Pipeline ì…ë ¥ê³¼ ë™ì¼)
                X_for_shap = X

            # 2. ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ + ëª¨ë¸ ë¶„ë¦¬ ì‚¬ìš©
            elif self.preprocessing_pipeline is not None and self.model is not None:
                logger.info("ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ + ëª¨ë¸ë¡œ ì˜ˆì¸¡ ì¤‘...")
                X = self._prepare_features(features_df)
                X_preprocessed = self.preprocessing_pipeline.transform(X)

                if hasattr(self.model, 'predict_proba'):
                    proba = self.model.predict_proba(X_preprocessed)[0]
                    bankruptcy_prob = proba[1]
                    confidence = max(proba)
                else:
                    prediction = self.model.predict(X_preprocessed)[0]
                    bankruptcy_prob = 0.8 if prediction == 1 else 0.2
                    confidence = 0.7

                model_for_shap = self.model
                X_for_shap = X_preprocessed

            # 3. ëª¨ë¸ë§Œ ì‚¬ìš© (ìŠ¤ì¼€ì¼ëŸ¬ í¬í•¨)
            elif self.model is not None:
                logger.info("ëª¨ë¸ ë‹¨ë… ì˜ˆì¸¡ ì¤‘...")
                X = self._prepare_features(features_df)

                # ìŠ¤ì¼€ì¼ë§
                if self.scaler is not None:
                    X_scaled = self.scaler.transform(X)
                else:
                    X_scaled = X

                # ì˜ˆì¸¡
                if hasattr(self.model, 'predict_proba'):
                    proba = self.model.predict_proba(X_scaled)[0]
                    bankruptcy_prob = proba[1]
                    confidence = max(proba)
                else:
                    prediction = self.model.predict(X_scaled)[0]
                    bankruptcy_prob = 0.8 if prediction == 1 else 0.2
                    confidence = 0.7

                model_for_shap = self.model
                X_for_shap = X_scaled

            # 4. ëª¨ë¸ì´ ì—†ìœ¼ë©´ íœ´ë¦¬ìŠ¤í‹±
            else:
                logger.warning("ëª¨ë¸ ì—†ìŒ. íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ ì˜ˆì¸¡ ì‚¬ìš©")
                return self._heuristic_prediction(features_df)

            # SHAP ê°’ ê³„ì‚°
            shap_values = None
            shap_base_value = None
            try:
                import shap
                # CatBoostëŠ” ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ â†’ ë¶€ë„(1) í´ë˜ìŠ¤ë§Œ ì‚¬ìš©
                logger.info(f"X_for_shap shape: {X_for_shap.shape}")
                logger.info(f"X_for_shap dtypes: {X_for_shap.dtypes}")
                
                if model_for_shap is not None:
                    logger.info(f"Creating TreeExplainer for {type(model_for_shap)}")
                    try:
                        explainer = shap.TreeExplainer(model_for_shap)
                        logger.info("Calculating shap_values...")
                        shap_values_result = explainer.shap_values(X_for_shap)
                        logger.info("shap_values calculated.")
                    except Exception as e:
                        logger.warning(f"TreeExplainer ì´ˆê¸°í™” ì‹¤íŒ¨: {e}. SHAP ê³„ì‚°ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                        raise ValueError(f"SHAP ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                else:
                    logger.info("SHAP ê³„ì‚° ìƒëµ (VotingClassifierëŠ” ë¯¸ì§€ì›)")
                    raise ValueError("VotingClassifierëŠ” SHAP TreeExplainer ë¯¸ì§€ì›")

                logger.info(f"SHAP result type: {type(shap_values_result)}")
                logger.info(f"Expected value type: {type(explainer.expected_value)}")
                logger.info(f"Expected value: {explainer.expected_value}")

                # Part4 ë…¸íŠ¸ë¶ ë°©ì‹: CatBoostëŠ” ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ â†’ [í´ë˜ìŠ¤0, í´ë˜ìŠ¤1]
                if isinstance(shap_values_result, list):
                    # CatBoost: shap_values_result = [array(...), array(...)]
                    # shap_values_result[1] = ë¶€ë„(í´ë˜ìŠ¤ 1)ì— ëŒ€í•œ SHAP ê°’
                    # shap_values_result[1][0] = ì²« ë²ˆì§¸ ìƒ˜í”Œ (shape: (27,))
                    try:
                        shap_values = shap_values_result[1][0]  # numpy ë°°ì—´ (27ê°œ íŠ¹ì„±)
                        logger.info(f"CatBoost SHAP values (í´ë˜ìŠ¤ 1): shape {shap_values.shape}")
                    except IndexError:
                        shap_values = shap_values_result[0][0]
                        logger.warning("í´ë˜ìŠ¤ 1 ì—†ìŒ, í´ë˜ìŠ¤ 0 ì‚¬ìš©")

                    # expected_valueë„ ë¦¬ìŠ¤íŠ¸: [í´ë˜ìŠ¤0 ê¸°ì¤€ê°’, í´ë˜ìŠ¤1 ê¸°ì¤€ê°’]
                    if isinstance(explainer.expected_value, (list, np.ndarray)) and len(explainer.expected_value) > 1:
                        shap_base_value = float(explainer.expected_value[1])  # í´ë˜ìŠ¤ 1 ê¸°ì¤€ê°’
                    else:
                        shap_base_value = float(explainer.expected_value)

                    logger.info(f"SHAP base value (í´ë˜ìŠ¤ 1): {shap_base_value:.4f}")

                else:
                    # ë‹¨ì¼ ë°°ì—´ì¸ ê²½ìš° (ì´ì§„ ë¶„ë¥˜ ë‹¨ì¼ ì¶œë ¥)
                    if len(shap_values_result.shape) > 1:
                         # (samples, features) - ì²« ë²ˆì§¸ ìƒ˜í”Œ ì„ íƒ
                         shap_values = shap_values_result[0]
                    else:
                         # (features,) - ê·¸ëŒ€ë¡œ ì‚¬ìš©
                         shap_values = shap_values_result

                    shap_base_value = float(explainer.expected_value)

                logger.info("âœ“ SHAP ê°’ ê³„ì‚° ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"SHAP ê³„ì‚° ì‹¤íŒ¨: {e}")
                shap_values = None
                shap_base_value = None

            # ê²°ê³¼ ìƒì„±
            from src.utils.helpers import get_risk_level
            risk_level, icon, msg = get_risk_level(bankruptcy_prob)

            # ëª¨ë¸ íƒ€ì… ê²°ì •
            if self.pipeline is not None:
                model_type = f"Pipeline({type(model_for_shap).__name__})"
            elif self.model is not None:
                model_type = type(self.model).__name__
            else:
                model_type = "Heuristic"

            result = {
                'bankruptcy_probability': float(bankruptcy_prob),
                'risk_level': risk_level,
                'risk_icon': icon,
                'risk_message': msg,
                'confidence': float(confidence),
                'features_used': list(X_for_shap.columns) if hasattr(X_for_shap, 'columns') else [],
                'model_info': {
                    'model_type': model_type,
                    'n_features': X_for_shap.shape[1] if hasattr(X_for_shap, 'shape') else 0
                }
            }

            # SHAP ì •ë³´ ì¶”ê°€
            if shap_values is not None:
                result['shap_values'] = shap_values.tolist() if hasattr(shap_values, 'tolist') else shap_values
                result['shap_base_value'] = float(shap_base_value)
                result['feature_names'] = list(X_for_shap.columns) if hasattr(X_for_shap, 'columns') else []

            logger.info(f"ì˜ˆì¸¡ ì™„ë£Œ: ë¶€ë„ í™•ë¥  {bankruptcy_prob:.1%}, ë“±ê¸‰ {risk_level}")

            return result

        except Exception as e:
            logger.error(f"ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}")
            # ì—ëŸ¬ ì‹œ íœ´ë¦¬ìŠ¤í‹± ì˜ˆì¸¡
            return self._heuristic_prediction(features_df)

    def _prepare_features(self, features_df: pd.DataFrame) -> pd.DataFrame:
        """
        ëª¨ë¸ì— ë§ê²Œ íŠ¹ì„± ì¤€ë¹„

        Args:
            features_df: ìƒì„±ëœ íŠ¹ì„± DataFrame

        Returns:
            ëª¨ë¸ ì…ë ¥ìš© DataFrame
        """
        # ëª¨ë¸ì´ ê¸°ëŒ€í•˜ëŠ” íŠ¹ì„± ëª©ë¡ (26ê°œ)
        # Part3 ë…¸íŠ¸ë¶ì—ì„œ 'ì´í•´ê´€ê³„ì_ë¶ˆì‹ ì§€ìˆ˜' ì œê±°ë¨ (ë…¼ë¦¬ì  ì˜¤ë¥˜ ë°©ì§€)
        expected_features = [
            'ìˆœë¶€ì±„ë¹„ìœ¨', 'ìš´ì „ìë³¸', 'ìš´ì „ìë³¸ë¹„ìœ¨', 'ì´ìë¶€ë‹´ë¥ ',
            'ê³µê³µì •ë³´ë¦¬ìŠ¤í¬', 'íŒê´€ë¹„íš¨ìœ¨ì„±', 'ì¬ê³ íšŒì „ìœ¨', 'ìœ ë™ì„±ì••ë°•ì§€ìˆ˜', 'ë§¤ì¶œì´ì´ìµë¥ ',
            'OCF_ëŒ€_ìœ ë™ë¶€ì±„', 'ë¶€ì±„ë ˆë²„ë¦¬ì§€', 'ì¬ê³ ë³´ìœ ì¼ìˆ˜', 'í˜„ê¸ˆì†Œì§„ì¼ìˆ˜', 'ë§¤ì¶œì§‘ì¤‘ë„',
            'ì—°ì²´ì‹¬ê°ë„', 'ì‹ ìš©ë“±ê¸‰ì ìˆ˜', 'ë¶€ì±„ìƒí™˜ë…„ìˆ˜', 'ë§¤ì¶œì±„ê¶Œ_ì´ìƒì§€í‘œ', 'ë§¤ì¶œì±„ê¶ŒíšŒì „ìœ¨',
            'ì´ë°œìƒì•¡', 'í˜„ê¸ˆíë¦„í’ˆì§ˆ', 'ê¸´ê¸‰ìœ ë™ì„±', 'ì¦‰ê°ì§€ê¸‰ëŠ¥ë ¥', 'ìš´ì „ìë³¸_ëŒ€_ìì‚°',
            'ì´ìë³´ìƒë°°ìœ¨', 'í˜„ê¸ˆì°½ì¶œëŠ¥ë ¥'
        ]

        X = features_df.copy()
        
        # 1. íŠ¹ì„± ì´ë¦„ ë§¤í•‘ (ìƒì„±ëœ íŠ¹ì„± -> ëª¨ë¸ ê¸°ëŒ€ íŠ¹ì„±)
        # ë„ë©”ì¸ íŠ¹ì„± ìƒì„± ì‹œ ì´ë¦„ê³¼ ëª¨ë¸ í•™ìŠµ ì‹œ ì‚¬ìš©í•œ ì´ë¦„ì˜ ì°¨ì´ë¥¼ ë³´ì •
        rename_map = {
            'OCFìœ ë™ë¶€ì±„ë¹„ìœ¨': 'OCF_ëŒ€_ìœ ë™ë¶€ì±„',
            'ê¸´ê¸‰ìœ ë™ì„±ë¹„ìœ¨': 'ê¸´ê¸‰ìœ ë™ì„±',
            'ìœ ë™ì„±ìœ„ê¸°ì§€ìˆ˜': 'ìœ ë™ì„±ì••ë°•ì§€ìˆ˜',
            'ì¬ë¬´ë ˆë²„ë¦¬ì§€': 'ë¶€ì±„ë ˆë²„ë¦¬ì§€',
            'ì¬ê³ ìì‚°íšŒì „ì¼ìˆ˜': 'ì¬ê³ ë³´ìœ ì¼ìˆ˜',
            'í˜„ê¸ˆíë¦„ì ì •ì„±': 'í˜„ê¸ˆíë¦„í’ˆì§ˆ',
            'ë‹¹ì¢Œë¹„ìœ¨': 'ì¦‰ê°ì§€ê¸‰ëŠ¥ë ¥',
            'ë‹¨ê¸°ì§€ê¸‰ëŠ¥ë ¥': 'í˜„ê¸ˆì°½ì¶œëŠ¥ë ¥',
        }
        X = X.rename(columns=rename_map)
        
        # ì¤‘ë³µëœ ì»¬ëŸ¼ ì œê±° (ë§¤í•‘ìœ¼ë¡œ ì¸í•´ ì¤‘ë³µ ë°œìƒ ì‹œ ì²« ë²ˆì§¸ ê²ƒ ìœ ì§€)
        X = X.loc[:, ~X.columns.duplicated()]

        # 2. ëˆ„ë½ëœ íŠ¹ì„± ì±„ìš°ê¸° (ê¸°ë³¸ê°’ ì‚¬ìš©)
        # DART APIì—ì„œ ì–»ì„ ìˆ˜ ì—†ëŠ” ì‹ ìš©í‰ê°€ ì •ë³´ëŠ” ì•ˆì „í•œ ê¸°ë³¸ê°’ ì‚¬ìš©
        # ë³´ìˆ˜ì  ê°€ì •: í‰ê· ì ì´ê³  ë¬¸ì œì—†ëŠ” ê¸°ì—…ìœ¼ë¡œ ê°€ì •í•˜ì—¬ ë¶€ë„ ìœ„í—˜ì„ ê³¼ì†Œí‰ê°€í•˜ì§€ ì•Šë„ë¡ í•¨
        defaults = {
            # ì‹ ìš©í‰ê°€ ì •ë³´ (DART API ë¯¸ì œê³µ, ì™¸ë¶€ ì‹ ìš©í‰ê°€ì‚¬ ë°ì´í„° í•„ìš”)
            'ì‹ ìš©ë“±ê¸‰ì ìˆ˜': 5.0,        # BBB ë“±ê¸‰ (ì¤‘ê°„ ë“±ê¸‰, 1~10 ìŠ¤ì¼€ì¼ì—ì„œ 5)
            'ì—°ì²´ì‹¬ê°ë„': 0.0,          # ì—°ì²´ ì—†ìŒ ê°€ì • (0 = ì—°ì²´ ì—†ìŒ, 1 = ì‹¬ê°)
            'ê³µê³µì •ë³´ë¦¬ìŠ¤í¬': 0.0,      # ì„¸ê¸ˆì²´ë‚© ì—†ìŒ ê°€ì • (0 = ì—†ìŒ, 1 = ìˆìŒ)
        }
        
        for feature in expected_features:
            if feature not in X.columns:
                if feature in defaults:
                    val = defaults[feature]
                    # Seriesì¼ ê²½ìš° ê°’ë§Œ ì¶”ì¶œ
                    if isinstance(val, pd.Series):
                        val = val.iloc[0]
                    X[feature] = val
                    logger.warning(f"íŠ¹ì„± '{feature}' ëˆ„ë½ë¨. ê¸°ë³¸ê°’ {val} ì‚¬ìš©")
                else:
                    # ë§¤í•‘ë˜ì§€ ì•Šì€ ë‚˜ë¨¸ì§€ íŠ¹ì„±ì€ 0ìœ¼ë¡œ ì±„ì›€
                    X[feature] = 0.0
                    logger.warning(f"íŠ¹ì„± '{feature}' ëˆ„ë½ë¨. 0.0ìœ¼ë¡œ ì±„ì›€")

        # 3. ìˆœì„œ ë§ì¶”ê¸° ë° ì„ íƒ
        X = X[expected_features]

        # ë²”ì£¼í˜• ë³€ìˆ˜ ì œê±° (ìˆ«ìí˜•ë§Œ) - ì´ë¯¸ ìœ„ì—ì„œ ì„ íƒí–ˆìœ¼ë¯€ë¡œ ë¶ˆí•„ìš”í•  ìˆ˜ ìˆìœ¼ë‚˜ ì•ˆì „ì¥ì¹˜
        X = X.select_dtypes(include=[np.number])

        # NaN/Inf ì œê±°
        X = X.replace([np.inf, -np.inf], 0)
        X = X.fillna(0)

        return X

    def _heuristic_prediction(self, features_df: pd.DataFrame) -> Dict:
        """
        íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ ë¶€ë„ í™•ë¥  ì˜ˆì¸¡ (ëª¨ë¸ ì—†ì„ ë•Œ)

        ì£¼ìš” ì§€í‘œë“¤ì„ ì¡°í•©í•˜ì—¬ ê²½í—˜ì ìœ¼ë¡œ ë¶€ë„ í™•ë¥  ì¶”ì •

        Args:
            features_df: íŠ¹ì„± DataFrame

        Returns:
            ì˜ˆì¸¡ ê²°ê³¼
        """
        logger.info("íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ ì˜ˆì¸¡ ì‹¤í–‰")

        # ì£¼ìš” ìœ„í—˜ ì§€í‘œ ì¶”ì¶œ
        ìœ ë™ì„±ìœ„ê¸° = features_df.get('ìœ ë™ì„±ìœ„ê¸°ì§€ìˆ˜', pd.Series([0.5])).iloc[0]
        ì§€ê¸‰ë¶ˆëŠ¥ìœ„í—˜ = features_df.get('ì§€ê¸‰ë¶ˆëŠ¥ìœ„í—˜ì§€ìˆ˜', pd.Series([0.5])).iloc[0]
        ì¬ë¬´ì¡°ì‘ìœ„í—˜ = features_df.get('ì¬ë¬´ì¡°ì‘ìœ„í—˜ì§€ìˆ˜', pd.Series([0.3])).iloc[0]

        # ì¡°ê¸°ê²½ë³´ì‹ í˜¸
        ê²½ë³´ì‹ í˜¸ìˆ˜ = features_df.get('ì¡°ê¸°ê²½ë³´ì‹ í˜¸ìˆ˜', pd.Series([0])).iloc[0]

        # ì¢…í•© ë¶€ë„ ìœ„í—˜ ìŠ¤ì½”ì–´ (ê°€ì¤‘í‰ê· )
        bankruptcy_prob = (
            0.35 * ìœ ë™ì„±ìœ„ê¸° +
            0.35 * ì§€ê¸‰ë¶ˆëŠ¥ìœ„í—˜ +
            0.20 * ì¬ë¬´ì¡°ì‘ìœ„í—˜ +
            0.10 * min(1.0, ê²½ë³´ì‹ í˜¸ìˆ˜ / 5)
        )

        # 0~1 ë²”ìœ„ë¡œ í´ë¦¬í•‘
        bankruptcy_prob = max(0.0, min(1.0, bankruptcy_prob))

        from src.utils.helpers import get_risk_level
        risk_level, icon, msg = get_risk_level(bankruptcy_prob)

        result = {
            'bankruptcy_probability': float(bankruptcy_prob),
            'risk_level': risk_level,
            'risk_icon': icon,
            'risk_message': msg,
            'confidence': 0.7,  # íœ´ë¦¬ìŠ¤í‹±ì´ë¯€ë¡œ ì‹ ë¢°ë„ ë‚®ìŒ
            'features_used': ['ìœ ë™ì„±ìœ„ê¸°ì§€ìˆ˜', 'ì§€ê¸‰ë¶ˆëŠ¥ìœ„í—˜ì§€ìˆ˜', 'ì¬ë¬´ì¡°ì‘ìœ„í—˜ì§€ìˆ˜', 'ì¡°ê¸°ê²½ë³´ì‹ í˜¸ìˆ˜'],
            'model_info': {
                'model_type': 'Heuristic',
                'n_features': 4,
                'note': 'í•™ìŠµëœ ëª¨ë¸ì´ ì—†ì–´ ê²½í—˜ì  ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ì˜ˆì¸¡í–ˆìŠµë‹ˆë‹¤.'
            }
        }

        logger.info(f"íœ´ë¦¬ìŠ¤í‹± ì˜ˆì¸¡ ì™„ë£Œ: ë¶€ë„ í™•ë¥  {bankruptcy_prob:.1%}")

        return result
        return result

    def _parse_shap_value(self, value) -> float:
        """
        SHAP ê°’ íŒŒì‹± (float, string, list string ë“± ì²˜ë¦¬)
        """
        if value is None:
            return 0.0
            
        if isinstance(value, (float, int, np.number)):
            return float(value)
            
        if isinstance(value, (list, np.ndarray)):
            # ë¦¬ìŠ¤íŠ¸ë‚˜ ë°°ì—´ì¸ ê²½ìš° ì²« ë²ˆì§¸ ìš”ì†Œ ì¬ê·€ ì²˜ë¦¬
            if len(value) > 0:
                return self._parse_shap_value(value[0])
            return 0.0
            
        if isinstance(value, (str, np.str_)):
            import ast
            try:
                # 1. ë‹¨ìˆœ float ë³€í™˜
                return float(value)
            except:
                try:
                    # 2. ë¦¬ìŠ¤íŠ¸ í˜•íƒœ ë¬¸ìì—´ íŒŒì‹± ('[0.123]')
                    parsed = ast.literal_eval(value)
                    if isinstance(parsed, list):
                        return self._parse_shap_value(parsed[0])
                    return float(parsed)
                except:
                    try:
                        # 3. ê´„í˜¸ ì œê±° í›„ ë³€í™˜
                        clean_val = value.replace('[', '').replace(']', '').strip()
                        return float(clean_val)
                    except:
                        logger.warning(f"SHAP ê°’ íŒŒì‹± ì‹¤íŒ¨: {value}")
                        return 0.0
        
        return 0.0
