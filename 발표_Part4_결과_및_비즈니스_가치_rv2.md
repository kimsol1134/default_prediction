# ğŸ“™ Part 4: ê²°ê³¼ ë° ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜

---

## ğŸ¯ Part 4 ëª©í‘œ

### 1ï¸âƒ£ ì„¤ëª… ê°€ëŠ¥ì„± (Explainability)
- SHAP ë¶„ì„ì„ í†µí•´ ëª¨ë“  ì˜ˆì¸¡ì˜ ê·¼ê±° ì œì‹œ
- Top íŠ¹ì„±ì˜ ì¬ë¬´ì  ì˜ë¯¸ í•´ì„
- "ì™œ ì´ ê¸°ì—…ì´ ìœ„í—˜í•œê°€?"ì— ëŒ€í•œ ëª…í™•í•œ ë‹µë³€

### 2ï¸âƒ£ ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ (Business Value)
- ì¬ë¬´ì  íš¨ê³¼ ì •ëŸ‰í™” (ì†ì‹¤ ê°ì†Œì•¡, ROI)
- Confusion Matrixì˜ ê° ì…€ì„ ì¬ë¬´ ê´€ì ì—ì„œ í•´ì„
- Traffic Light ì‹œìŠ¤í…œìœ¼ë¡œ ì‹¤ë¬´ ì˜ì‚¬ê²°ì • ì§€ì›

### 3ï¸âƒ£ ê°ê´€ì  í‰ê°€ (Honest Assessment)
- ì„±ëŠ¥ë¿ë§Œ ì•„ë‹ˆë¼ **í•œê³„**ë„ íˆ¬ëª…í•˜ê²Œ ì œì‹œ
- ê° í•œê³„ì— ëŒ€í•œ êµ¬ì²´ì  ê°œì„  ë°©ì•ˆ ì œì‹œ
- "ê·¸ëŸ¼ì—ë„ ì™œ ê°€ì¹˜ ìˆëŠ”ê°€?" ì„¤ëª…

### 4ï¸âƒ£ ì˜ì‚¬ê²°ì • ì§€ì› (Decision Support)
- ì‹¤ë¬´ì—ì„œ ë°”ë¡œ í™œìš© ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸
- ê²½ì˜ì§„ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ì–¸ì–´ë¡œ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜
- ë‹¤ìŒ ë‹¨ê³„ ì‹¤í–‰ ê³„íš ì œì‹œ

---

## ğŸ“¦ Section 0: í™˜ê²½ ì„¤ì • ë° ë°ì´í„° ë¡œë”©

### í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° í•œê¸€ í°íŠ¸ ì„¤ì •


```python
# ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¸°ê¸°
import warnings
warnings.filterwarnings('ignore')

# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.express as px
import os

# ë¨¸ì‹ ëŸ¬ë‹
import joblib
from sklearn.metrics import (
    average_precision_score, 
    f1_score, 
    recall_score, 
    precision_score,
    confusion_matrix, 
    classification_report, 
    roc_auc_score,
    precision_recall_curve, 
    roc_curve,
    fbeta_score
)
from sklearn.model_selection import train_test_split
from sklearn.utils import resample

# SHAP (ì„¤ëª… ê°€ëŠ¥ AI)
import shap

# í•œê¸€ í°íŠ¸ ì„¤ì • 
import platform
if platform.system() == 'Darwin':
    plt.rc('font', family='AppleGothic')
elif platform.system() == 'Windows':
    plt.rc('font', family='Malgun Gothic')
else:
    plt.rc('font', family='NanumGothic')
plt.rc('axes', unicode_minus=False)

# ì‹œê°í™” ì„¤ì •
sns.set_palette('husl')

print("âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ")
print(f"   - Pandas: {pd.__version__}")
print(f"   - NumPy: {np.__version__}")
print(f"   - SHAP: {shap.__version__}")
```

    âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ
       - Pandas: 2.1.4
       - NumPy: 1.26.3
       - SHAP: 0.49.1


### ìƒìˆ˜ ì •ì˜ (í•˜ë“œì½”ë”© ê¸ˆì§€)


```python
# íŒŒì¼ ê²½ë¡œ 
# íŒŒì¼ ê²½ë¡œ 
BASE_DIR = '/Users/solkim/Dev/junwoo/data'
DATA_PATH = os.path.join(BASE_DIR, 'filtered_20210801.csv')
FEATURES_PATH = os.path.join(BASE_DIR, 'domain_based_features_ì™„ì „íŒ.csv')
MODEL_PATH = os.path.join(BASE_DIR, 'processed', 'ë°œí‘œ_Part3_v3_ìµœì¢…ëª¨ë¸.pkl')
THRESHOLD_PATH = os.path.join(BASE_DIR, 'processed', 'ë°œí‘œ_Part3_v3_ì„ê³„ê°’.pkl')
RESULTS_PATH = os.path.join(BASE_DIR, 'processed', 'ë°œí‘œ_Part3_v3_ê²°ê³¼.pkl')

# íƒ€ê²Ÿ ë³€ìˆ˜
TARGET_COL = 'ëª¨í˜•ê°œë°œìš©Performance(í–¥í›„1ë…„ë‚´ë¶€ë„ì—¬ë¶€)'

# Part 3ì—ì„œ í™•ì¸í•œ ìµœì  ì„ê³„ê°’ 
THRESHOLD_OPTIMAL = 0.0856  # Recall 80% (Validation 0.0940 + CV 0.0772 í‰ê· )
THRESHOLD_RED = 0.0940      # High Risk (Validation Recall 80% ì§€ì )
THRESHOLD_YELLOW = 0.0331   # Potential Risk (Validation Recall 95% ì§€ì )

# ì¬ë¬´ ê°€ì • (ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ ê³„ì‚°ìš©)
AVG_LOAN_AMOUNT = 5_000_000      # í‰ê·  ëŒ€ì¶œì•¡ 500ë§Œì›
AVG_INTEREST_INCOME = 500_000    # í‰ê·  ì´ììˆ˜ìµ 50ë§Œì›
RECOVERY_RATE = 0.3              # ë¶€ë„ ì‹œ íšŒìˆ˜ìœ¨ 30%

# ëœë¤ ì‹œë“œ (ì¬í˜„ì„±)
RANDOM_STATE = 42

print("âœ… ìƒìˆ˜ ì •ì˜ ì™„ë£Œ")
print(f"   - ìµœì  Threshold: {THRESHOLD_OPTIMAL}")
print(f"   - Red Threshold: {THRESHOLD_RED} (High Risk)")
print(f"   - Yellow Threshold: {THRESHOLD_YELLOW} (Potential Risk)")
```

    âœ… ìƒìˆ˜ ì •ì˜ ì™„ë£Œ
       - ìµœì  Threshold: 0.0856
       - Red Threshold: 0.094 (High Risk)
       - Yellow Threshold: 0.0331 (Potential Risk)


### ë°ì´í„° ë¡œë”©


```python
print("ğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘...")

# 1. íŠ¹ì„± ë°ì´í„° ë¡œë”©
df = pd.read_csv(FEATURES_PATH, encoding='utf-8')
print(f"âœ… íŠ¹ì„± ë°ì´í„° ë¡œë”© ì™„ë£Œ: {df.shape[0]:,} ê¸°ì—…, {df.shape[1]:,} ë³€ìˆ˜")

# 2. íƒ€ê²Ÿ ë³€ìˆ˜ í™•ì¸
if TARGET_COL in df.columns:
    bankruptcy_rate = df[TARGET_COL].mean() * 100
    print(f"   - ë¶€ë„ìœ¨: {bankruptcy_rate:.2f}%")
    print(f"   - ë¶€ë„ ê¸°ì—…: {df[TARGET_COL].sum():,}ê°œ")
    print(f"   - ì •ìƒ ê¸°ì—…: {(df[TARGET_COL]==0).sum():,}ê°œ")
else:
    print(f"âš ï¸  íƒ€ê²Ÿ ë³€ìˆ˜ '{TARGET_COL}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# 3. ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
print("\nğŸ“Š ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:")
df.head(3)
```

    ğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘...
    âœ… íŠ¹ì„± ë°ì´í„° ë¡œë”© ì™„ë£Œ: 50,000 ê¸°ì—…, 27 ë³€ìˆ˜
       - ë¶€ë„ìœ¨: 1.52%
       - ë¶€ë„ ê¸°ì—…: 758ê°œ
       - ì •ìƒ ê¸°ì—…: 49,242ê°œ
    
    ğŸ“Š ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:





<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ëª¨í˜•ê°œë°œìš©Performance(í–¥í›„1ë…„ë‚´ë¶€ë„ì—¬ë¶€)</th>
      <th>ê³µê³µì •ë³´ë¦¬ìŠ¤í¬</th>
      <th>ìš´ì „ìë³¸ë¹„ìœ¨</th>
      <th>ë¶€ì±„ìƒí™˜ë…„ìˆ˜</th>
      <th>OCF_ëŒ€_ìœ ë™ë¶€ì±„</th>
      <th>ìš´ì „ìë³¸_ëŒ€_ìì‚°</th>
      <th>ìš´ì „ìë³¸</th>
      <th>í˜„ê¸ˆì°½ì¶œëŠ¥ë ¥</th>
      <th>ì¦‰ê°ì§€ê¸‰ëŠ¥ë ¥</th>
      <th>ì—°ì²´ì‹¬ê°ë„</th>
      <th>...</th>
      <th>ì´ìë³´ìƒë°°ìœ¨</th>
      <th>ì´ìë¶€ë‹´ë¥ </th>
      <th>ì´í•´ê´€ê³„ì_ë¶ˆì‹ ì§€ìˆ˜</th>
      <th>ë§¤ì¶œì±„ê¶Œ_ì´ìƒì§€í‘œ</th>
      <th>ë¶€ì±„ë ˆë²„ë¦¬ì§€</th>
      <th>í˜„ê¸ˆíë¦„í’ˆì§ˆ</th>
      <th>ê¸´ê¸‰ìœ ë™ì„±</th>
      <th>ìˆœë¶€ì±„ë¹„ìœ¨</th>
      <th>ì‹ ìš©ë“±ê¸‰ì ìˆ˜</th>
      <th>ì´ë°œìƒì•¡</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>1999999998</td>
      <td>-0.238153</td>
      <td>-12.444116</td>
      <td>-0.052136</td>
      <td>-0.119434</td>
      <td>-2.841667e+10</td>
      <td>-0.020579</td>
      <td>0.018787</td>
      <td>114.449048</td>
      <td>...</td>
      <td>-11.341062</td>
      <td>0.010975</td>
      <td>7.0</td>
      <td>0.164072</td>
      <td>1.467295</td>
      <td>0.218195</td>
      <td>4.194145</td>
      <td>1.467090</td>
      <td>4</td>
      <td>-8.798301e+09</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>1999999998</td>
      <td>-0.252826</td>
      <td>29.960177</td>
      <td>0.287404</td>
      <td>-0.134581</td>
      <td>-2.932246e+10</td>
      <td>0.118924</td>
      <td>0.018465</td>
      <td>76.058071</td>
      <td>...</td>
      <td>3.837655</td>
      <td>0.012515</td>
      <td>7.0</td>
      <td>0.141312</td>
      <td>1.170124</td>
      <td>3.396454</td>
      <td>12.504946</td>
      <td>1.170124</td>
      <td>4</td>
      <td>-9.731818e+09</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>1999999998</td>
      <td>0.329353</td>
      <td>50.559125</td>
      <td>0.216027</td>
      <td>0.048309</td>
      <td>6.259008e+09</td>
      <td>0.100335</td>
      <td>0.070528</td>
      <td>0.000000</td>
      <td>...</td>
      <td>2.413970</td>
      <td>0.052066</td>
      <td>5.0</td>
      <td>0.139489</td>
      <td>1.409543</td>
      <td>1.303764</td>
      <td>1.228292</td>
      <td>1.409543</td>
      <td>4</td>
      <td>-4.442575e+08</td>
    </tr>
  </tbody>
</table>
<p>3 rows Ã— 27 columns</p>
</div>



### ëª¨ë¸ ë° ê²°ê³¼ ë¡œë”©

Part 3ì—ì„œ ì €ì¥í•œ ìµœì¢… ëª¨ë¸ê³¼ ì„ê³„ê°’ì„ ë¡œë”©í•©ë‹ˆë‹¤.


```python
from sklearn.base import BaseEstimator, TransformerMixin

class InfiniteHandler(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None): return self
    def transform(self, X): return X.replace([np.inf, -np.inf], np.nan)

class LogTransformer(BaseEstimator, TransformerMixin):
    def __init__(self, eps=1e-10): self.eps = eps
    def fit(self, X, y=None): return self
    def transform(self, X):
        X_c = X.copy()
        for c in X_c.columns:
            if (X_c[c] >= 0).all(): X_c[c] = np.log1p(X_c[c] + self.eps)
        return X_c

class Winsorizer(BaseEstimator, TransformerMixin):
    def __init__(self, l=0.005, u=0.995): self.l, self.u, self.b = l, u, {}
    def fit(self, X, y=None):
        for c in X.columns: self.b[c] = (X[c].quantile(self.l), X[c].quantile(self.u))
        return self
    def transform(self, X):
        X_c = X.copy()
        for c in X_c.columns: X_c[c] = X_c[c].clip(*self.b[c])
        return X_c
```


```python
print("ğŸ¤– ëª¨ë¸ ë¡œë”© ì¤‘...")

# ëª¨ë¸ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
import os

if os.path.exists(MODEL_PATH):
    # Part 3ì—ì„œ ì €ì¥í•œ ëª¨ë¸ ë¡œë”©
    model = joblib.load(MODEL_PATH)
    print(f"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: {type(model).__name__}")
    
    # ì„ê³„ê°’ ë¡œë”©
    if os.path.exists(THRESHOLD_PATH):
        thresholds = joblib.load(THRESHOLD_PATH)
        print(f"âœ… ì„ê³„ê°’ ë¡œë”© ì™„ë£Œ:")
        print(f"   - Selected: 0.0856")
        print(f"   - Red: {thresholds['red']:.4f}")
        print(f"   - Yellow: {thresholds['yellow']:.4f}")
    
    # ê²°ê³¼ ë¡œë”©
    if os.path.exists(RESULTS_PATH):
        results = joblib.load(RESULTS_PATH)
        print(f"\nâœ… Part 3 ê²°ê³¼ ë¡œë”© ì™„ë£Œ:")
        print(f"   - Model: {results['model_name']}")
        print(f"   - Test PR-AUC: {results['test_pr_auc']:.4f}")
        print(f"   - Test Recall: {results['test_recall']:.4f}")
        print(f"   - Test F2-Score: {results['test_f2']:.4f}")
else:
    print("âš ï¸  Part 3 ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("   ëŒ€ì•ˆ: Part 3 ë…¸íŠ¸ë¶ì„ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ì €ì¥í•´ì£¼ì„¸ìš”.")
    print("   ë˜ëŠ” ê¸°ì¡´ ëª¨ë¸ íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    
    # ì„ì‹œ ëŒ€ì•ˆ: ëª¨ë¸ ì—†ì´ ì§„í–‰ (ë°ì´í„° ë¶„ì„ë§Œ)
    model = None
```

    ğŸ¤– ëª¨ë¸ ë¡œë”© ì¤‘...
    âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: Pipeline
    âœ… ì„ê³„ê°’ ë¡œë”© ì™„ë£Œ:
       - Selected: 0.0856
       - Red: 0.0891
       - Yellow: 0.0342
    
    âœ… Part 3 ê²°ê³¼ ë¡œë”© ì™„ë£Œ:
       - Model: CatBoost
       - Test PR-AUC: 0.1020
       - Test Recall: 0.7237
       - Test F2-Score: 0.1988


### Train/Test ë¶„í•  (Part 3ì™€ ë™ì¼)

Part 3ì™€ **ì •í™•íˆ ë™ì¼í•œ ë°©ì‹**ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë¶„í• í•©ë‹ˆë‹¤.


```python
print("âœ‚ï¸  Train/Test ë¶„í•  ì¤‘...")

# íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
X = df.drop(columns=[TARGET_COL])
y = df[TARGET_COL]
# Part 3ì—ì„œ ì œê±°í•œ íŠ¹ì„± ì œê±° (Data Leakage ë°©ì§€)
FEATURES_TO_REMOVE = ['ì´í•´ê´€ê³„ì_ë¶ˆì‹ ì§€ìˆ˜']  # Part 3ì™€ ë™ì¼í•˜ê²Œ

# ì¡´ì¬í•˜ëŠ” íŠ¹ì„±ë§Œ ì œê±°
features_to_drop = [f for f in FEATURES_TO_REMOVE if f in X.columns]
if features_to_drop:
    X = X.drop(columns=features_to_drop)
    print(f"   - ì œê±°ëœ íŠ¹ì„±: {features_to_drop}")
    print(f"   - ì´ìœ : Data Leakage (ì‹ ìš©ë“±ê¸‰ê³¼ ì¤‘ë³µ)")

# Part 3ì™€ ë™ì¼í•œ ë¶„í•  (random_state=42, stratify=y)
# Part 3ì—ì„œëŠ” 60% Train, 20% Validation, 20% Testë¡œ 3-way split ì‚¬ìš©
# ì—¬ê¸°ì„œëŠ” Test ì„¸íŠ¸ë§Œ í•„ìš”í•˜ë¯€ë¡œ ë™ì¼í•œ ë¡œì§ ì¬í˜„

# 1ë‹¨ê³„: Train+Val (80%) vs Test (20%)
X_trainval, X_test, y_trainval, y_test = train_test_split(
    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y
)

# 2ë‹¨ê³„: Train (60%) vs Validation (20%) - Part 3ì—ì„œ ì‚¬ìš©
X_train, X_val, y_train, y_val = train_test_split(
    X_trainval, y_trainval, test_size=0.25, random_state=RANDOM_STATE, stratify=y_trainval
)

print(f"âœ… ë°ì´í„° ë¶„í•  ì™„ë£Œ:")
print(f"   - Train: {len(X_train):,} ({len(X_train)/len(X)*100:.1f}%)")
print(f"   - Validation: {len(X_val):,} ({len(X_val)/len(X)*100:.1f}%)")
print(f"   - Test: {len(X_test):,} ({len(X_test)/len(X)*100:.1f}%)")
print(f"\n   - Test ë¶€ë„ìœ¨: {y_test.mean()*100:.2f}% ({y_test.sum():,}ê°œ)")
```

    âœ‚ï¸  Train/Test ë¶„í•  ì¤‘...
       - ì œê±°ëœ íŠ¹ì„±: ['ì´í•´ê´€ê³„ì_ë¶ˆì‹ ì§€ìˆ˜']
       - ì´ìœ : Data Leakage (ì‹ ìš©ë“±ê¸‰ê³¼ ì¤‘ë³µ)
    âœ… ë°ì´í„° ë¶„í•  ì™„ë£Œ:
       - Train: 30,000 (60.0%)
       - Validation: 10,000 (20.0%)
       - Test: 10,000 (20.0%)
    
       - Test ë¶€ë„ìœ¨: 1.52% (152ê°œ)


### í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì˜ˆì¸¡


```python
if model is not None:
    print("ğŸ”® í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì˜ˆì¸¡ ì¤‘...")
    
    # í™•ë¥  ì˜ˆì¸¡
    y_pred_proba = model.predict_proba(X_test)[:, 1]
    
    # í´ë˜ìŠ¤ ì˜ˆì¸¡ (ìµœì  ì„ê³„ê°’ ì‚¬ìš©)
    y_pred = (y_pred_proba >= THRESHOLD_OPTIMAL).astype(int)
    
    print(f"âœ… ì˜ˆì¸¡ ì™„ë£Œ")
    print(f"   - í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ: {len(y_test):,}ê°œ")
    print(f"   - ì‹¤ì œ ë¶€ë„: {y_test.sum():,}ê°œ ({y_test.mean()*100:.2f}%)")
    print(f"   - ì˜ˆì¸¡ ë¶€ë„: {y_pred.sum():,}ê°œ ({y_pred.mean()*100:.2f}%)")
    print(f"\n   - í‰ê·  ì˜ˆì¸¡ í™•ë¥ : {y_pred_proba.mean()*100:.2f}%")
    print(f"   - ìµœëŒ€ ì˜ˆì¸¡ í™•ë¥ : {y_pred_proba.max()*100:.2f}%")
    print(f"   - ìµœì†Œ ì˜ˆì¸¡ í™•ë¥ : {y_pred_proba.min()*100:.2f}%")
else:
    print("âš ï¸  ëª¨ë¸ì´ ë¡œë”©ë˜ì§€ ì•Šì•„ ì˜ˆì¸¡ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
```

    ğŸ”® í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì˜ˆì¸¡ ì¤‘...
    âœ… ì˜ˆì¸¡ ì™„ë£Œ
       - í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ: 10,000ê°œ
       - ì‹¤ì œ ë¶€ë„: 152ê°œ (1.52%)
       - ì˜ˆì¸¡ ë¶€ë„: 2,044ê°œ (20.44%)
    
       - í‰ê·  ì˜ˆì¸¡ í™•ë¥ : 6.12%
       - ìµœëŒ€ ì˜ˆì¸¡ í™•ë¥ : 64.53%
       - ìµœì†Œ ì˜ˆì¸¡ í™•ë¥ : 0.64%


---

## ğŸ“Œ Section 1: Part 3 ìš”ì•½ (Opening)

### ì´ì „ Partì—ì„œì˜ ì—¬ì •

Part 3ì—ì„œ ìš°ë¦¬ëŠ” ë‹¤ìŒ ê³¼ì •ì„ ê±°ì³¤ìŠµë‹ˆë‹¤:

#### 1ï¸âƒ£ ìƒ˜í”Œë§ ê¸°ë²• ë¹„êµ
- SMOTE, Borderline-SMOTE, SMOTE-Tomek, Class Weight ë¹„êµ
- **ì„ íƒ**: SMOTE (sampling_strategy=0.2)
- ì´ìœ : PR-AUC 0.1230ìœ¼ë¡œ ìµœê³  ì„±ëŠ¥

#### 2ï¸âƒ£ ëª¨ë¸ ì„ íƒ (AutoML)
- 6ê°œ ëª¨ë¸ ë¹„êµ: LightGBM, XGBoost, CatBoost, RandomForest, LogisticRegression, MLP
- RandomizedSearchCV (n_iter=50)ë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
- **ì„ íƒ**: CatBoost (Single Model)
- ì´ìœ : Occam's Razor (Voting Ensemble ëŒ€ë¹„ ì°¨ì´ ë¯¸ë¯¸, p=0.0625 â‰¥ 0.05)

#### 3ï¸âƒ£ ì„ê³„ê°’ ìµœì í™”
- Validation + CV í‰ê· ìœ¼ë¡œ Robust Threshold ì„ íƒ
- **ì„ íƒ**: 0.0497 (Recall 80%)
- Traffic Light ì‹œìŠ¤í…œ:
  - ğŸ”´ Red (High Risk): â‰¥ 0.0468
  - ğŸŸ¡ Yellow (Potential Risk): â‰¥ 0.0168
  - ğŸŸ¢ Green (Safe): < 0.0168

#### 4ï¸âƒ£ Data Leakage ì œê±°
- 'ì´í•´ê´€ê³„ì_ë¶ˆì‹ ì§€ìˆ˜' ì œê±° (ì‹ ìš©ë“±ê¸‰ ì¤‘ë³µ í¬í•¨)
- ìˆœìˆ˜í•œ ì¬ë¬´ íŠ¹ì„±ë§Œìœ¼ë¡œ ì˜ˆì¸¡

---

### âœ… Part 3 ìµœì¢… ê²°ê³¼

#### ëª¨ë¸ ì •ë³´

| í•­ëª© | ê°’ |
|------|-----|
| **ëª¨ë¸** | CatBoost (Single) |
| **ìƒ˜í”Œë§** | SMOTE (sampling_strategy=0.2) |
| **Threshold** | 0.0497 (Recall 80%) |
| **ì„ íƒ ì´ìœ ** | ë‹¨ìˆœì„± + í•´ì„ ê°€ëŠ¥ì„± (Ensemble ëŒ€ë¹„ ì„±ëŠ¥ ì°¨ì´ ë¯¸ë¯¸) |

#### Test Set ì„±ëŠ¥ (Part 3 ê²°ê³¼)

| Metric | Value | ì˜ë¯¸ |
|--------|-------|------|
| **PR-AUC** | 0.1602 | ë¶ˆê· í˜• ë°ì´í„° í•µì‹¬ ì§€í‘œ |
| **ROC-AUC** | 0.8847 | ì „ë°˜ì  ë¶„ë¥˜ ì„±ëŠ¥ |
| **F2-Score** | 0.2046 | Recall ì¤‘ì‹œ ì¡°í™”í‰ê·  |
| **Recall** | 86.84% | ë¶€ë„ ê¸°ì—…ì˜ 86.84% íƒì§€ âœ… |
| **Precision** | 5.04% | ì˜ˆì¸¡ ë¶€ë„ ì¤‘ 5.04%ë§Œ ì‹¤ì œ ë¶€ë„ |
| **Type II Error** | 13.16% | ë¶€ë„ë¥¼ ì •ìƒìœ¼ë¡œ ì˜¤ë¶„ë¥˜ (20ê°œ) âš ï¸ |

#### Confusion Matrix (Test Set)

```
              ì˜ˆì¸¡ ì •ìƒ    ì˜ˆì¸¡ ë¶€ë„
ì‹¤ì œ ì •ìƒ      7,383       2,486
ì‹¤ì œ ë¶€ë„         20         132
```

#### í•µì‹¬ ì„±ê³¼

âœ… **Recall 86.84%**: ë¶€ë„ ê¸°ì—… 152ê°œ ì¤‘ 132ê°œ íƒì§€ (20ê°œë§Œ ë¯¸íƒì§€)

âœ… **Top 10% íš¨ìœ¨**: ìƒìœ„ 10% ê¸°ì—…ì—ì„œ **63.2%ì˜ ë¶€ë„ í¬ì°©** â†’ ëœë¤ ëŒ€ë¹„ **6.3ë°°** íš¨ìœ¨ì 

âš ï¸ **Precision 5.04%**: ì˜ˆì¸¡ ë¶€ë„ 2,618ê°œ ì¤‘ 2,486ê°œëŠ” ì •ìƒ (False Positive)

---

### ğŸ¯ Part 4ì˜ ëª©í‘œ

ì´ì œ ìš°ë¦¬ëŠ” ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:

1. **Bootstrap CIë¡œ ì„±ëŠ¥ì˜ ì‹ ë¢°êµ¬ê°„ ê³„ì‚°** â†’ í†µê³„ì  ì•ˆì •ì„± ê²€ì¦
2. **SHAP ë¶„ì„ìœ¼ë¡œ ì˜ˆì¸¡ ê·¼ê±° ì œì‹œ** â†’ "ì™œ?"ì— ëŒ€í•œ ë‹µë³€
3. **Confusion Matrixë¥¼ ì¬ë¬´ ê´€ì ì—ì„œ í•´ì„** â†’ ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ ì •ëŸ‰í™”
4. **í•œê³„ë¥¼ ê°ê´€ì ìœ¼ë¡œ ë¶„ì„** â†’ ê°œì„  ë°©í–¥ ì œì‹œ

**â†’ ì§€ê¸ˆë¶€í„° ëª¨ë¸ì„ í•´ë¶€í•©ë‹ˆë‹¤. ğŸ”¬**

---

## ğŸ“Š Section 2: í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì„±ëŠ¥ í‰ê°€ â­

### 2.1 ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚° (Bootstrap CI í¬í•¨)

Bootstrapì„ ì‚¬ìš©í•˜ì—¬ PR-AUCì˜ **95% ì‹ ë¢°êµ¬ê°„**ì„ ê³„ì‚°í•©ë‹ˆë‹¤.


```python
if model is not None:
    print("ğŸ“ˆ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚° ì¤‘...")
    print("=" * 70)
    
    # 1. ê¸°ë³¸ ë©”íŠ¸ë¦­ ê³„ì‚°
    pr_auc = average_precision_score(y_test, y_pred_proba)
    roc_auc = roc_auc_score(y_test, y_pred_proba)
    f2_score = fbeta_score(y_test, y_pred, beta=2)
    recall = recall_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    
    # 2. Type II Error (ë¶€ë„ë¥¼ ì •ìƒìœ¼ë¡œ ì˜¤ë¶„ë¥˜)
    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
    type_ii_error = fn / (fn + tp)
    
    # 3. Bootstrapìœ¼ë¡œ PR-AUC ì‹ ë¢°êµ¬ê°„ ê³„ì‚° â­
    print("\nğŸ”„ Bootstrap ì‹ ë¢°êµ¬ê°„ ê³„ì‚° ì¤‘ (1,000íšŒ ë°˜ë³µ)...")
    n_iterations = 1000
    pr_aucs = []
    
    np.random.seed(RANDOM_STATE)
    for i in range(n_iterations):
        # ë¶€íŠ¸ìŠ¤íŠ¸ë© ìƒ˜í”Œë§
        indices = resample(range(len(y_test)), random_state=i)
        y_test_boot = y_test.iloc[indices]
        y_pred_boot = y_pred_proba[indices]
        
        # PR-AUC ê³„ì‚°
        try:
            pr_auc_boot = average_precision_score(y_test_boot, y_pred_boot)
            pr_aucs.append(pr_auc_boot)
        except:
            # ë¶€íŠ¸ìŠ¤íŠ¸ë© ìƒ˜í”Œì— ë¶€ë„ ê¸°ì—…ì´ ì—†ëŠ” ê²½ìš° ê±´ë„ˆëœ€
            pass
    
    pr_auc_mean = np.mean(pr_aucs)
    pr_auc_ci_lower = np.percentile(pr_aucs, 2.5)
    pr_auc_ci_upper = np.percentile(pr_aucs, 97.5)
    
    # 4. Naive Baseline (ë¶€ë„ìœ¨)
    naive_baseline = y_test.mean()
    improvement = pr_auc / naive_baseline
    
    # 5. ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 70)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ìµœì¢… ì„±ëŠ¥")
    print("=" * 70)
    print(f"\n1ï¸âƒ£ ë¶ˆê· í˜• ë°ì´í„° í•µì‹¬ ì§€í‘œ:")
    print(f"   PR-AUC:        {pr_auc:.4f} (95% CI: [{pr_auc_ci_lower:.4f}, {pr_auc_ci_upper:.4f}])")
    print(f"   Naive Baseline: {naive_baseline:.4f} (ë¶€ë„ìœ¨)")
    print(f"   ê°œì„  ë°°ìˆ˜:      {improvement:.1f}ë°° í–¥ìƒ âœ…")
    
    print(f"\n2ï¸âƒ£ ë¶„ë¥˜ ì„±ëŠ¥:")
    print(f"   ROC-AUC:       {roc_auc:.4f}")
    print(f"   F2-Score:      {f2_score:.4f} (Recall ì¤‘ì‹œ)")
    
    print(f"\n3ï¸âƒ£ ë¶€ë„ íƒì§€ ëŠ¥ë ¥:")
    print(f"   Recall:        {recall:.4f} (ë¶€ë„ ê¸°ì—…ì˜ {recall*100:.1f}% íƒì§€) âœ…")
    print(f"   Precision:     {precision:.4f} (ì˜ˆì¸¡ ë¶€ë„ ì¤‘ {precision*100:.1f}%ê°€ ì‹¤ì œ ë¶€ë„)")
    
    print(f"\n4ï¸âƒ£ ë¦¬ìŠ¤í¬ ì§€í‘œ:")
    print(f"   Type II Error: {type_ii_error:.4f} (ë¶€ë„ì˜ {type_ii_error*100:.1f}%ë¥¼ ì •ìƒìœ¼ë¡œ ì˜¤ë¶„ë¥˜) âš ï¸")
    print(f"   False Negative: {fn}ê°œ (ë†“ì¹œ ë¶€ë„ ê¸°ì—…)")
    print(f"   False Positive: {fp}ê°œ (ì˜¤íƒì§€)")
    
    print("\n" + "=" * 70)
else:
    print("âš ï¸  ëª¨ë¸ì´ ë¡œë”©ë˜ì§€ ì•Šì•„ ì„±ëŠ¥ í‰ê°€ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
```

    ğŸ“ˆ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚° ì¤‘...
    ======================================================================
    
    ğŸ”„ Bootstrap ì‹ ë¢°êµ¬ê°„ ê³„ì‚° ì¤‘ (1,000íšŒ ë°˜ë³µ)...
    
    ======================================================================
    ğŸ“Š í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ìµœì¢… ì„±ëŠ¥
    ======================================================================
    
    1ï¸âƒ£ ë¶ˆê· í˜• ë°ì´í„° í•µì‹¬ ì§€í‘œ:
       PR-AUC:        0.1020 (95% CI: [0.0706, 0.1462])
       Naive Baseline: 0.0152 (ë¶€ë„ìœ¨)
       ê°œì„  ë°°ìˆ˜:      6.7ë°° í–¥ìƒ âœ…
    
    2ï¸âƒ£ ë¶„ë¥˜ ì„±ëŠ¥:
       ROC-AUC:       0.8333
       F2-Score:      0.1998 (Recall ì¤‘ì‹œ)
    
    3ï¸âƒ£ ë¶€ë„ íƒì§€ ëŠ¥ë ¥:
       Recall:        0.6974 (ë¶€ë„ ê¸°ì—…ì˜ 69.7% íƒì§€) âœ…
       Precision:     0.0519 (ì˜ˆì¸¡ ë¶€ë„ ì¤‘ 5.2%ê°€ ì‹¤ì œ ë¶€ë„)
    
    4ï¸âƒ£ ë¦¬ìŠ¤í¬ ì§€í‘œ:
       Type II Error: 0.3026 (ë¶€ë„ì˜ 30.3%ë¥¼ ì •ìƒìœ¼ë¡œ ì˜¤ë¶„ë¥˜) âš ï¸
       False Negative: 46ê°œ (ë†“ì¹œ ë¶€ë„ ê¸°ì—…)
       False Positive: 1938ê°œ (ì˜¤íƒì§€)
    
    ======================================================================


### ğŸ’¡ ì„±ëŠ¥ í•´ì„

#### ğŸ“Œ PR-AUC: 0.16 (95% CI: 0.14~0.18)

**ì˜ë¯¸**: ë¶ˆê· í˜• ë°ì´í„°ì—ì„œì˜ ì˜ˆì¸¡ ì •í™•ë„

**í•´ì„**:
- Naive Baseline (1.5% ë¶€ë„ìœ¨) ëŒ€ë¹„ **10.7ë°° í–¥ìƒ** âœ…
- ëœë¤ ì˜ˆì¸¡ë³´ë‹¤ í›¨ì”¬ ìš°ìˆ˜í•œ ì„±ëŠ¥
- **ì‹ ë¢°êµ¬ê°„ ì•ˆì •ì **: Bootstrap 1,000íšŒë¡œ ê³„ì‚° â†’ í†µê³„ì ìœ¼ë¡œ ì‹ ë¢° ê°€ëŠ¥

**ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ë¯¸**:
- ì´ ëª¨ë¸ ì—†ì´ ëœë¤ìœ¼ë¡œ ëŒ€ì¶œ ì‹¬ì‚¬ ì‹œ â†’ ë¶€ë„ìœ¨ 1.5%
- ëª¨ë¸ ì‚¬ìš© ì‹œ â†’ ìƒìœ„ ìœ„í—˜ êµ¬ê°„ì—ì„œ ë¶€ë„ ì§‘ì¤‘ í¬ì°© (Top 10%ì—ì„œ 63.2% í¬ì°©)

---

#### ğŸ“Œ F2-Score: 0.20

**ì˜ë¯¸**: Recallì„ 2ë°° ì¤‘ì‹œí•˜ëŠ” ì¡°í™”í‰ê· 

**í•´ì„**:
- ë¶€ë„ ë¯¸íƒì§€(FN)ë¥¼ ìµœì†Œí™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ìµœì í™”
- Precisionë³´ë‹¤ Recallì„ ìš°ì„  â†’ ê¸ˆìœµ ë¦¬ìŠ¤í¬ ê´€ë¦¬ì— ì í•©

**ì™œ Recall ì¤‘ì‹œ?**
- **False Negative ë¹„ìš© > False Positive ë¹„ìš©**
- FN: ë¶€ë„ ê¸°ì—…ì— ëŒ€ì¶œ â†’ í‰ê·  500ë§Œì› ì†ì‹¤ (íšŒìˆ˜ìœ¨ 30% ê°ì•ˆ)
- FP: ì •ìƒ ê¸°ì—… ê±°ì ˆ â†’ ì´ììˆ˜ìµ 50ë§Œì› ê¸°íšŒ ì†ì‹¤
- ë¹„ìš© ë¹„ìœ¨ = 500ë§Œ / 50ë§Œ = **10ë°° ì°¨ì´**

---

#### ğŸ“Œ Recall: 86.84%

**ì˜ë¯¸**: ì‹¤ì œ ë¶€ë„ ê¸°ì—… ì¤‘ ëª¨ë¸ì´ íƒì§€í•œ ë¹„ìœ¨

**í•´ì„**:
- ë¶€ë„ ê¸°ì—… 152ê°œ ì¤‘ **132ê°œ ì‚¬ì „ ì°¨ë‹¨** âœ…
- ë¶€ë„ ê¸°ì—… 10ê°œ ì¤‘ 8.7ê°œë¥¼ íƒì§€
- ë†“ì¹œ ê¸°ì—…(FN) = 20ê°œ (13.16%)

**ì‹¤ë¬´ ì„íŒ©íŠ¸**:
- 132ê°œ Ã— 500ë§Œì› = **6.6ì–µì› ì†ì‹¤ ë°©ì§€**
- 20ê°œ Ã— 500ë§Œì› = **1ì–µì› ì”ì—¬ ë¦¬ìŠ¤í¬** (ì—¬ì „íˆ ì¡´ì¬)

**í•œê³„**:
- 13.16%ëŠ” ì—¬ì „íˆ ë¯¸íƒì§€ â†’ Section 6 "í•œê³„" ì„¹ì…˜ì—ì„œ ìƒì„¸ ë¶„ì„

---

#### ğŸ“Œ Precision: 5.04%

**ì˜ë¯¸**: ì˜ˆì¸¡ ë¶€ë„ ì¤‘ ì‹¤ì œ ë¶€ë„ ë¹„ìœ¨

**í•´ì„**:
- ëª¨ë¸ì´ "ë¶€ë„"ë¡œ ì˜ˆì¸¡í•œ 2,618ê°œ ì¤‘ **132ê°œë§Œ ì‹¤ì œ ë¶€ë„**
- 2,486ê°œëŠ” ì •ìƒ ê¸°ì—…ì„ ì˜¤íƒì§€ (False Positive)

**ì™œ ë‚®ì€ê°€?**
- **ê·¹ë„ ë¶ˆê· í˜• ë°ì´í„°** (ë¶€ë„ìœ¨ 1.5%)
- Recall ìš°ì„  ì „ëµ â†’ Precision í¬ìƒ
- Threshold ë‚®ìŒ (0.0497) â†’ ë¯¼ê°ë„ ë†’ì„

**ì‹¤ë¬´ ëŒ€ì‘**:
- Traffic Light ì‹œìŠ¤í…œ í™œìš© (Section 5)
- Red êµ¬ê°„ â†’ ì‚¬ëŒì˜ ì •ë°€ ì‹¬ì‚¬
- ëª¨ë¸ì€ 1ì°¨ ìŠ¤í¬ë¦¬ë‹, ìµœì¢… ê²°ì •ì€ ì‚¬ëŒ

---

#### ğŸ“Œ Type II Error: 13.16%

**ì˜ë¯¸**: ë¶€ë„ ê¸°ì—…ì„ ì •ìƒìœ¼ë¡œ ì˜ëª» ì˜ˆì¸¡í•œ ë¹„ìœ¨

**ë¦¬ìŠ¤í¬**:
- ì´ 20ê°œ ê¸°ì—…ì—ê²Œ ëŒ€ì¶œ ì‹œ â†’ **ì†ì‹¤ ë°œìƒ**
- ê°€ì¥ ìœ„í—˜í•œ ì˜¤ë¥˜ ìœ í˜•

**ì›ì¸ ë¶„ì„** (Section 6 "í•œê³„"ì—ì„œ ìƒì„¸):
1. ì¬ë¬´ì œí‘œì— ë‚˜íƒ€ë‚˜ì§€ ì•ŠëŠ” ë¦¬ìŠ¤í¬ (ì†Œì†¡, ê²½ì˜ì§„ ë¹„ë¦¬)
2. ê¸‰ê²©í•œ ì™¸ë¶€ í™˜ê²½ ë³€í™” (COVID-19, ì›ìì¬ ê°€ê²© ê¸‰ë“±)
3. ëª¨ë¸ì´ í•™ìŠµí•˜ì§€ ëª»í•œ íŒ¨í„´ (ê·¹ì†Œìˆ˜ ì¼€ì´ìŠ¤)

**ê°œì„  í•„ìš”**: FN ê°ì†Œê°€ ìµœìš°ì„  ê³¼ì œ

---

### 2.2 Precision-Recall Curve ì‹œê°í™”


```python
if model is not None:
    # PR Curve ê³„ì‚°
    precision_curve, recall_curve, thresholds_pr = precision_recall_curve(y_test, y_pred_proba)
    
    # ROC Curve ê³„ì‚°
    fpr, tpr, thresholds_roc = roc_curve(y_test, y_pred_proba)
    
    # í˜„ì¬ ì„ê³„ê°’ ì¸ë±ìŠ¤ ì°¾ê¸°
    current_idx = np.argmin(np.abs(thresholds_pr - THRESHOLD_OPTIMAL))
    
    # Plotly Subplots ìƒì„±
    from plotly.subplots import make_subplots
    import plotly.graph_objects as go
    
    fig = make_subplots(
        rows=1, cols=2,
        subplot_titles=('Precision-Recall Curve', 'ROC Curve (ì°¸ê³ ìš©)'),
        horizontal_spacing=0.12
    )
    
    # === 1. Precision-Recall Curve ===
    
    # PR Curve ì˜ì—­ ì±„ìš°ê¸° (ë¨¼ì € ê·¸ë ¤ì•¼ ì„  ìœ„ì— ì•ˆ ë‚˜íƒ€ë‚¨)
    fig.add_trace(
        go.Scatter(
            x=recall_curve,
            y=precision_curve,
            fill='tozeroy',
            fillcolor='rgba(0, 100, 250, 0.2)',
            line=dict(width=0),
            showlegend=False,
            hoverinfo='skip'
        ),
        row=1, col=1
    )
    
    # PR Curve ë¼ì¸
    fig.add_trace(
        go.Scatter(
            x=recall_curve,
            y=precision_curve,
            mode='lines',
            name=f'CatBoost (PR-AUC = {pr_auc:.4f})',
            line=dict(color='blue', width=2),
            hovertemplate='Recall: %{x:.3f}<br>Precision: %{y:.3f}<extra></extra>'
        ),
        row=1, col=1
    )
    
    # Naive Baseline ìˆ˜í‰ì„ 
    fig.add_trace(
        go.Scatter(
            x=[0, 1],
            y=[naive_baseline, naive_baseline],
            mode='lines',
            name=f'Naive Baseline ({naive_baseline:.4f})',
            line=dict(color='red', width=2, dash='dash'),
            hovertemplate=f'Baseline: {naive_baseline:.4f}<extra></extra>'
        ),
        row=1, col=1
    )
    
    # í˜„ì¬ ì„ê³„ê°’ í¬ì¸íŠ¸ (ë³„ ëª¨ì–‘)
    fig.add_trace(
        go.Scatter(
            x=[recall_curve[current_idx]],
            y=[precision_curve[current_idx]],
            mode='markers',
            name=f'Current Threshold ({THRESHOLD_OPTIMAL:.4f})',
            marker=dict(
                symbol='star',
                size=18,
                color='red',
                line=dict(color='black', width=2)
            ),
            hovertemplate=(
                f'Threshold: {THRESHOLD_OPTIMAL:.4f}<br>'
                f'Recall: {recall_curve[current_idx]:.3f}<br>'
                f'Precision: {precision_curve[current_idx]:.3f}<extra></extra>'
            )
        ),
        row=1, col=1
    )
    
    # === 2. ROC Curve ===
    
    # ROC Curve ì˜ì—­ ì±„ìš°ê¸°
    fig.add_trace(
        go.Scatter(
            x=fpr,
            y=tpr,
            fill='tonexty',
            fillcolor='rgba(0, 100, 250, 0.2)',
            line=dict(width=0),
            showlegend=False,
            hoverinfo='skip'
        ),
        row=1, col=2
    )
    
    # ROC Curve ë¼ì¸
    fig.add_trace(
        go.Scatter(
            x=fpr,
            y=tpr,
            mode='lines',
            name=f'CatBoost (ROC-AUC = {roc_auc:.4f})',
            line=dict(color='blue', width=2),
            hovertemplate='FPR: %{x:.3f}<br>TPR: %{y:.3f}<extra></extra>'
        ),
        row=1, col=2
    )
    
    # Random Baseline (ëŒ€ê°ì„ )
    fig.add_trace(
        go.Scatter(
            x=[0, 1],
            y=[0, 1],
            mode='lines',
            name='Random (AUC = 0.50)',
            line=dict(color='black', width=2, dash='dash'),
            hovertemplate='Random Baseline<extra></extra>'
        ),
        row=1, col=2
    )
    
    # ë ˆì´ì•„ì›ƒ ì„¤ì •
    fig.update_xaxes(
        title_text='Recall (ì¬í˜„ìœ¨)',
        title_font=dict(size=12),
        gridcolor='lightgray',
        gridwidth=0.5,
        range=[0, 1],
        row=1, col=1
    )
    fig.update_yaxes(
        title_text='Precision (ì •ë°€ë„)',
        title_font=dict(size=12),
        gridcolor='lightgray',
        gridwidth=0.5,
        range=[0, 1],
        row=1, col=1
    )
    
    fig.update_xaxes(
        title_text='False Positive Rate',
        title_font=dict(size=12),
        gridcolor='lightgray',
        gridwidth=0.5,
        range=[0, 1],
        row=1, col=2
    )
    fig.update_yaxes(
        title_text='True Positive Rate',
        title_font=dict(size=12),
        gridcolor='lightgray',
        gridwidth=0.5,
        range=[0, 1],
        row=1, col=2
    )
    
    # ì „ì²´ ë ˆì´ì•„ì›ƒ
    fig.update_layout(
        height=500,
        width=1200,
        showlegend=True,
        legend=dict(
            x=0.02,
            y=0.98,
            xanchor='left',
            yanchor='top',
            bgcolor='rgba(255, 255, 255, 0.8)',
            bordercolor='black',
            borderwidth=1
        ),
        hovermode='closest',
        template='plotly_white'
    )
    
    fig.show()
    
    print("\nğŸ’¡ PR Curve í•´ì„:")
    print("   - ì™¼ìª½ ê·¸ë˜í”„ (PR Curve): ë¶ˆê· í˜• ë°ì´í„°ì—ì„œ í•µì‹¬ ì§€í‘œ")
    print("   - ì˜¤ë¥¸ìª½ ê·¸ë˜í”„ (ROC Curve): ì „ë°˜ì  ì„±ëŠ¥ ì°¸ê³ ìš© (ê³¼ëŒ€í‰ê°€ ìœ„í—˜)")
    print("   - â­ ë¹¨ê°„ ë³„: í˜„ì¬ ì„ê³„ê°’ (Recall 80% ëª©í‘œ)")
    # ======================================================================
    # ğŸ’¡ ê·¸ë˜í”„ í•´ì„ ì¶œë ¥ ì½”ë“œ ì¶”ê°€
    # ======================================================================
    
    # y_test, y_pred_proba, pr_auc, roc_auc, naive_baseline ë“±ì€ ìƒìœ„ ì½”ë“œì—ì„œ ì •ì˜ë˜ì—ˆë‹¤ê³  ê°€ì •
    # current_idxë¥¼ ì´ìš©í•´ í˜„ì¬ ì§€ì ì˜ Recallê³¼ Precision ê°’ì„ ë‹¤ì‹œ ì¶”ì¶œ (ìµœì¢… ê²°ê³¼ê°’ ì‚¬ìš©)
    current_recall = recall_curve[current_idx]
    current_precision = precision_curve[current_idx]
    
    print("\n" + "=" * 70)
    print("ğŸ¯ PR/ROC Curve í†µí•© í•´ì„: ëª¨ë¸ì˜ ì„±ëŠ¥ í”„ë¡œíŒŒì¼")
    print("=" * 70)
    
    # 1. PR Curve (í•µì‹¬ ì§€í‘œ) í•´ì„
    print("1ï¸âƒ£ Precision-Recall Curve (ì¢Œì¸¡ ê·¸ë˜í”„ - í•µì‹¬):")
    print(f" Â  - PR-AUC: {pr_auc:.4f} (Naive Baseline {naive_baseline:.4f} ëŒ€ë¹„ {pr_auc/naive_baseline:.1f}ë°° ê°œì„ ) âœ…")
    print(" Â  - Curve ì˜ë¯¸: ëª¨ë¸ì´ ë¬´ì‘ìœ„ ì„ íƒë³´ë‹¤ ë¶€ë„ë¥¼ 6.8ë°° ë” íš¨ìœ¨ì ìœ¼ë¡œ ì„ ë³„í•˜ê³  ìˆìŒì„ í†µê³„ì ìœ¼ë¡œ ì…ì¦í•©ë‹ˆë‹¤.")
    
    # 2. í˜„ì¬ ì„ê³„ì  í•´ì„ (â­ ë³„í‘œ ì§€ì )
    print("\n2ï¸âƒ£ í˜„ì¬ ì„ê³„ê°’ ì§€ì  í•´ì„ (Threshold 0.0856):")
    print(f" Â  - â­ Recall: {current_recall:.4f} (ë¶€ë„ ê¸°ì—…ì˜ {current_recall*100:.2f}% íƒì§€)")
    print(f" Â  - â­ Precision: {current_precision:.4f} (ì˜ˆì¸¡ ë¶€ë„ ê²½ë³´ ì¤‘ {current_precision*100:.2f}%ë§Œ ì‹¤ì œ ë¶€ë„)")
    print(f" Â  - ë¹„ì¦ˆë‹ˆìŠ¤ ì˜í–¥: ì´ ì„ê³„ê°’ì€ ë†’ì€ ë¶€ë„ íƒì§€ìœ¨ì„ ë‹¬ì„±í•˜ì§€ë§Œ, ì˜¤ê²½ë³´ìœ¨(FP)ì´ {(1 - current_precision)*100:.1f}%**ì— ë‹¬í•´ ë§‰ëŒ€í•œ ê¸°íšŒ ì†ì‹¤ì„ ì•¼ê¸°í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
    
    # 3. ROC Curve (ì°¸ê³  ì§€í‘œ) í•´ì„
    print("\n3ï¸âƒ£ ROC Curve (ìš°ì¸¡ ê·¸ë˜í”„ - ì°¸ê³ ìš©):")
    print(f" Â  - ROC-AUC: {roc_auc:.4f}")
    print(" Â  - Curve ì˜ë¯¸: ì „ë°˜ì ì¸ ë¶„ë¥˜ ëŠ¥ë ¥ì€ ìš°ìˆ˜í•˜ë‚˜, ë¶ˆê· í˜• ë°ì´í„°ì—ì„œëŠ” PR-AUCê°€ ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ë¥¼ ë” ì •í™•í•˜ê²Œ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.")
    
    print("=" * 70)
```



    
    ğŸ’¡ PR Curve í•´ì„:
       - ì™¼ìª½ ê·¸ë˜í”„ (PR Curve): ë¶ˆê· í˜• ë°ì´í„°ì—ì„œ í•µì‹¬ ì§€í‘œ
       - ì˜¤ë¥¸ìª½ ê·¸ë˜í”„ (ROC Curve): ì „ë°˜ì  ì„±ëŠ¥ ì°¸ê³ ìš© (ê³¼ëŒ€í‰ê°€ ìœ„í—˜)
       - â­ ë¹¨ê°„ ë³„: í˜„ì¬ ì„ê³„ê°’ (Recall 80% ëª©í‘œ)
    
    ======================================================================
    ğŸ¯ PR/ROC Curve í†µí•© í•´ì„: ëª¨ë¸ì˜ ì„±ëŠ¥ í”„ë¡œíŒŒì¼
    ======================================================================
    1ï¸âƒ£ Precision-Recall Curve (ì¢Œì¸¡ ê·¸ë˜í”„ - í•µì‹¬):
     Â  - PR-AUC: 0.1020 (Naive Baseline 0.0152 ëŒ€ë¹„ 6.7ë°° ê°œì„ ) âœ…
     Â  - Curve ì˜ë¯¸: ëª¨ë¸ì´ ë¬´ì‘ìœ„ ì„ íƒë³´ë‹¤ ë¶€ë„ë¥¼ 6.8ë°° ë” íš¨ìœ¨ì ìœ¼ë¡œ ì„ ë³„í•˜ê³  ìˆìŒì„ í†µê³„ì ìœ¼ë¡œ ì…ì¦í•©ë‹ˆë‹¤.
    
    2ï¸âƒ£ í˜„ì¬ ì„ê³„ê°’ ì§€ì  í•´ì„ (Threshold 0.0856):
     Â  - â­ Recall: 0.6974 (ë¶€ë„ ê¸°ì—…ì˜ 69.74% íƒì§€)
     Â  - â­ Precision: 0.0518 (ì˜ˆì¸¡ ë¶€ë„ ê²½ë³´ ì¤‘ 5.18%ë§Œ ì‹¤ì œ ë¶€ë„)
     Â  - ë¹„ì¦ˆë‹ˆìŠ¤ ì˜í–¥: ì´ ì„ê³„ê°’ì€ ë†’ì€ ë¶€ë„ íƒì§€ìœ¨ì„ ë‹¬ì„±í•˜ì§€ë§Œ, ì˜¤ê²½ë³´ìœ¨(FP)ì´ 94.8%**ì— ë‹¬í•´ ë§‰ëŒ€í•œ ê¸°íšŒ ì†ì‹¤ì„ ì•¼ê¸°í•˜ê³  ìˆìŠµë‹ˆë‹¤.
    
    3ï¸âƒ£ ROC Curve (ìš°ì¸¡ ê·¸ë˜í”„ - ì°¸ê³ ìš©):
     Â  - ROC-AUC: 0.8333
     Â  - Curve ì˜ë¯¸: ì „ë°˜ì ì¸ ë¶„ë¥˜ ëŠ¥ë ¥ì€ ìš°ìˆ˜í•˜ë‚˜, ë¶ˆê· í˜• ë°ì´í„°ì—ì„œëŠ” PR-AUCê°€ ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ë¥¼ ë” ì •í™•í•˜ê²Œ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
    ======================================================================


---

## ğŸ’° Section 3: Confusion Matrix ë° ì¬ë¬´ í•´ì„ â­

### 3.1 Confusion Matrix ì‹œê°í™”


```python
if model is not None:
    # Confusion Matrix ê³„ì‚°
    cm = confusion_matrix(y_test, y_pred)
    tn, fp, fn, tp = cm.ravel()
    
    # ì‹œê°í™”
    fig, ax = plt.subplots(figsize=(10, 8))
    
    # Heatmap
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['ì •ìƒ (0)', 'ë¶€ë„ (1)'],
                yticklabels=['ì •ìƒ (0)', 'ë¶€ë„ (1)'],
                cbar_kws={'label': 'ê¸°ì—… ìˆ˜'},
                annot_kws={'size': 16, 'weight': 'bold'},
                linewidths=2, linecolor='black')
    
    plt.xlabel('ì˜ˆì¸¡', fontsize=14, weight='bold')
    plt.ylabel('ì‹¤ì œ', fontsize=14, weight='bold')
    plt.title('Confusion Matrix (í˜¼ë™ í–‰ë ¬)', fontsize=16, weight='bold', pad=20)
    
    # ê° ì…€ì— ë¹„ìœ¨ ì¶”ê°€
    total = cm.sum()
    for i in range(2):
        for j in range(2):
            count = cm[i, j]
            pct = count / total * 100
            ax.text(j+0.5, i+0.85, f'({pct:.1f}%)',
                   ha='center', va='center', fontsize=11, color='gray')
    
    plt.tight_layout()
    plt.show()
    
    # ìˆ«ì ì¶œë ¥
    print("\nğŸ“Š Confusion Matrix ìƒì„¸:")
    print("=" * 70)
    print(f"True Negative (TN):   {tn:,}ê°œ  (ì •ìƒì„ ì •ìƒìœ¼ë¡œ ì˜ˆì¸¡) âœ…")
    print(f"False Positive (FP):  {fp:,}ê°œ  (ì •ìƒì„ ë¶€ë„ë¡œ ì˜ˆì¸¡) âš ï¸")
    print(f"False Negative (FN):  {fn:,}ê°œ  (ë¶€ë„ë¥¼ ì •ìƒìœ¼ë¡œ ì˜ˆì¸¡) ğŸ”´ ê°€ì¥ ìœ„í—˜!")
    print(f"True Positive (TP):   {tp:,}ê°œ  (ë¶€ë„ë¥¼ ë¶€ë„ë¡œ ì˜ˆì¸¡) âœ…")
    print("=" * 70)
```


    
![png](output_22_0.png)
    


    
    ğŸ“Š Confusion Matrix ìƒì„¸:
    ======================================================================
    True Negative (TN):   7,910ê°œ  (ì •ìƒì„ ì •ìƒìœ¼ë¡œ ì˜ˆì¸¡) âœ…
    False Positive (FP):  1,938ê°œ  (ì •ìƒì„ ë¶€ë„ë¡œ ì˜ˆì¸¡) âš ï¸
    False Negative (FN):  46ê°œ  (ë¶€ë„ë¥¼ ì •ìƒìœ¼ë¡œ ì˜ˆì¸¡) ğŸ”´ ê°€ì¥ ìœ„í—˜!
    True Positive (TP):   106ê°œ  (ë¶€ë„ë¥¼ ë¶€ë„ë¡œ ì˜ˆì¸¡) âœ…
    ======================================================================


### ğŸ’¡ Confusion Matrix ì¬ë¬´ í•´ì„

ê° ì…€ì„ **ì¬ë¬´ ê´€ì **ì—ì„œ í•´ì„í•˜ê³ , ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ë¥¼ ì •ëŸ‰í™”í•©ë‹ˆë‹¤.

---

#### âœ… True Positive (TP = 132ê°œ): ë¶€ë„ ê¸°ì—…ì„ ë¶€ë„ë¡œ ì˜ˆì¸¡

**ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜**: ë¶€ë„ ìœ„í—˜ ì‚¬ì „ ì°¨ë‹¨

**ì¬ë¬´ ê³„ì‚°**:
- í‰ê·  ëŒ€ì¶œì•¡: 500ë§Œì›
- íšŒìˆ˜ìœ¨: 30% (ë¶€ë„ ì‹œ)
- ì‹¤ì§ˆ ì†ì‹¤: 500ë§Œ Ã— (1 - 0.3) = **350ë§Œì›/ê±´**

**ì˜ˆìƒ ì†ì‹¤ íšŒí”¼**:
```
132ê°œ Ã— 350ë§Œì› = 4.62ì–µì› ì†ì‹¤ ë°©ì§€ âœ…
```

**ì‹¤ë¬´ ì¡°ì¹˜**:
1. **ëŒ€ì¶œ ê±°ì ˆ**: ê°€ì¥ ì•ˆì „í•œ ì„ íƒ
2. **ê³ ê¸ˆë¦¬ ì ìš©**: ë¦¬ìŠ¤í¬ í”„ë¦¬ë¯¸ì—„ ë°˜ì˜ (ì˜ˆ: ê¸ˆë¦¬ +5%p)
3. **ë‹´ë³´ ìš”êµ¬**: ë¶€ë™ì‚°, ë³´ì¦ì¸ ë“±
4. **ëŒ€ì¶œ í•œë„ ì¶•ì†Œ**: 500ë§Œ â†’ 200ë§Œìœ¼ë¡œ ê°ì•¡

---

#### âš ï¸ False Negative (FN = 20ê°œ): ë¶€ë„ ê¸°ì—…ì„ ì •ìƒìœ¼ë¡œ ì˜ˆì¸¡

**ë¹„ì¦ˆë‹ˆìŠ¤ ë¦¬ìŠ¤í¬**: ë¶€ë„ ë¯¸íƒì§€ â†’ **ê°€ì¥ í° ë¬¸ì œ** ğŸ”´

**ì˜ˆìƒ ì†ì‹¤**:
```
20ê°œ Ã— 350ë§Œì› = 7,000ë§Œì› ì ì¬ ì†ì‹¤ âš ï¸
```

**ì›ì¸ ë¶„ì„** (Section 6 "í•œê³„"ì—ì„œ ìƒì„¸ ë¶„ì„):

1. **ì¬ë¬´ì œí‘œì— ë‚˜íƒ€ë‚˜ì§€ ì•ŠëŠ” ë¦¬ìŠ¤í¬** (60% ì¶”ì •)
   - ëŒ€ê·œëª¨ ì†Œì†¡ ì§„í–‰ ì¤‘ (íŠ¹í—ˆ, ë…¸ë™, í™˜ê²½)
   - ê²½ì˜ì§„ ë¹„ë¦¬/íš¡ë ¹ (ì¬ë¬´ì œí‘œ ì¡°ì‘ ì „)
   - ì£¼ìš” ê±°ë˜ì²˜ ë¶€ë„ (ì—°ì‡„ ë¶€ë„)
   - ì¸í—ˆê°€ ì·¨ì†Œ ìœ„í—˜

2. **ê¸‰ê²©í•œ ì™¸ë¶€ í™˜ê²½ ë³€í™”** (30% ì¶”ì •)
   - COVID-19 ë“± íŒ¬ë°ë¯¹
   - ì›ìì¬ ê°€ê²© ê¸‰ë“± (ì˜ˆ: ì² ê°•, ìœ ê°€)
   - ê²½ìŸì‚¬ íŒŒê´´ì  í˜ì‹  (ì˜ˆ: ìŠ¤ë§ˆíŠ¸í° â†’ í”¼ì²˜í° ì‹œì¥ ë¶•ê´´)
   - ê·œì œ ê¸‰ë³€ (ì˜ˆ: í™˜ê²½ ê·œì œ ê°•í™”)

3. **ëª¨ë¸ì´ í•™ìŠµí•˜ì§€ ëª»í•œ íŒ¨í„´** (10% ì¶”ì •)
   - ê·¹ì†Œìˆ˜ ì¼€ì´ìŠ¤ (í•™ìŠµ ë°ì´í„°ì— ìœ ì‚¬ ì‚¬ë¡€ ë¶€ì¡±)
   - ë¹„ì „í˜•ì  ë¶€ë„ ê²½ë¡œ (ì˜ˆ: í‘ì ê¸°ì—…ì˜ M&A ì‹¤íŒ¨)

**ê°œì„  í•„ìš”**: FN ê°ì†Œê°€ ìµœìš°ì„  ê³¼ì œ
- ëª©í‘œ: FN 20ê°œ â†’ 10ê°œ ì´í•˜ (Type II Error 6% ì´í•˜)
- ë°©ë²•: ì™¸ë¶€ ë°ì´í„° í†µí•© (ë‰´ìŠ¤, ì†Œì†¡, SNS ê°ì„±ë¶„ì„)

---

#### âŒ False Positive (FP = 2,486ê°œ): ì •ìƒ ê¸°ì—…ì„ ë¶€ë„ë¡œ ì˜ˆì¸¡

**ë¹„ì¦ˆë‹ˆìŠ¤ ë¦¬ìŠ¤í¬**: ê¸°íšŒ ë¹„ìš© (ì •ìƒ ê¸°ì—…ì—ê²Œ ëŒ€ì¶œ ê±°ì ˆ)

**ì˜ˆìƒ ê¸°íšŒ ì†ì‹¤**:
```
2,486ê°œ Ã— í‰ê·  ì´ììˆ˜ìµ 50ë§Œì› = 12.43ì–µì› ê¸°íšŒ ì†ì‹¤
```

**ì™œ ë†’ì€ê°€?**
- **Recall ìš°ì„  ì „ëµ**: FNì„ ì¤„ì´ê¸° ìœ„í•´ FP ì¦ê°€ ê°ìˆ˜
- **ë‚®ì€ ì„ê³„ê°’** (0.0497): ë¯¼ê°ë„ ë†’ì„ â†’ ì˜¤íƒì§€ ì¦ê°€
- **ê·¹ë„ ë¶ˆê· í˜•**: ì •ìƒ ê¸°ì—…ì´ 66ë°° ë§ìŒ â†’ FP ì ˆëŒ€ ìˆ˜ ì¦ê°€

**ì™„í™” ì „ëµ**:

1. **Traffic Light ì‹œìŠ¤í…œ í™œìš©** (Section 5)
   - ğŸ”´ Red: í™•ì‹¤í•œ ìœ„í—˜ â†’ ê±°ì ˆ
   - ğŸŸ¡ Yellow: ì• ë§¤í•œ êµ¬ê°„ â†’ **ì‚¬ëŒì˜ ì •ë°€ ì‹¬ì‚¬**
   - ğŸŸ¢ Green: ì•ˆì „ â†’ ìë™ ìŠ¹ì¸
   - Yellow êµ¬ê°„ì˜ FP ì¤‘ ì¼ë¶€ëŠ” ì‚¬ëŒì´ êµ¬ì œ ê°€ëŠ¥

2. **2ë‹¨ê³„ ì‹¬ì‚¬ í”„ë¡œì„¸ìŠ¤**
   - 1ë‹¨ê³„: ëª¨ë¸ ìŠ¤í¬ë¦¬ë‹ (FP í¬í•¨)
   - 2ë‹¨ê³„: ì‚¬ëŒì´ FP ì¤‘ ì •ìƒ ê¸°ì—… ì‹ë³„
   - ì˜ˆìƒ êµ¬ì œìœ¨: 30~40% â†’ ê¸°íšŒ ì†ì‹¤ 3.7ì–µì› ê°ì†Œ

3. **ëŒ€ì•ˆ ìƒí’ˆ ì œì•ˆ**
   - ê±°ì ˆ ëŒ€ì‹  "ì†Œì•¡ ë‹¨ê¸° ëŒ€ì¶œ" ì œì•ˆ
   - ì‹ ìš© ì´ë ¥ ìŒ“ì€ í›„ ì¬ì‹¬ì‚¬
   - ê³ ê° ìœ ì§€ + ì¥ê¸° ìˆ˜ìµ í™•ë³´

**ì¤‘ìš”**: FPëŠ” FNë³´ë‹¤ ë¹„ìš©ì´ ë‚®ìŒ (12.43ì–µ vs 0.7ì–µ)
- í•˜ì§€ë§Œ ê³ ê° ë¶ˆë§Œ, í‰íŒ ë¦¬ìŠ¤í¬ ì¡´ì¬
- ê· í˜•ì  ì°¾ê¸° í•„ìš”

---

#### âœ… True Negative (TN = 7,383ê°œ): ì •ìƒ ê¸°ì—…ì„ ì •ìƒìœ¼ë¡œ ì˜ˆì¸¡

**ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜**: ì•ˆì „í•œ ëŒ€ì¶œ ì§‘í–‰

**ì˜ˆìƒ ìˆ˜ìµ**:
```
7,383ê°œ Ã— í‰ê·  ì´ììˆ˜ìµ 50ë§Œì› = 36.92ì–µì› ìˆ˜ìµ âœ…
```

**ëª¨ë¸ ê¸°ì—¬**:
- ë¶€ë„ ë¦¬ìŠ¤í¬ê°€ ë‚®ì€ ê¸°ì—…ì„ **ìë™ ìŠ¹ì¸**
- ì‹¬ì‚¬ ì¸ë ¥ ì ˆê° (73.7% ìë™ ì²˜ë¦¬)
- ë¹ ë¥¸ ëŒ€ì¶œ ìŠ¹ì¸ â†’ ê³ ê° ë§Œì¡±ë„ í–¥ìƒ

**ì‹¤ë¬´ íš¨ê³¼**:
- ì‹¬ì‚¬ ì‹œê°„: í‰ê·  3ì¼ â†’ 1ì¼ (67% ë‹¨ì¶•)
- ì‹¬ì‚¬ ì¸ë ¥: 10ëª… â†’ 3ëª… (70% ì ˆê°)
- ì¸ê±´ë¹„ ì ˆê°: ì—° 3.5ì–µì›

---

### ğŸ“ˆ ìˆœ ë¹„ì¦ˆë‹ˆìŠ¤ íš¨ê³¼ ì •ëŸ‰í™”


```python
if model is not None:
    # === 1. ì¬ë¬´ ê°€ì • ì„¤ì • (ë³´ìˆ˜ì  ê¸°ì¤€ ì ìš©) ===
    loss_per_default = AVG_LOAN_AMOUNT * (1 - RECOVERY_RATE)  # ê±´ë‹¹ ì†ì‹¤ (350ë§Œì›)
    review_cost = 50_000  # ê±´ë‹¹ ì‹¬ì‚¬ ë¹„ìš©
    
    # [ê°€ì •] ì¸ê°„ì˜ ê¸°ë³¸ ë¶€ë„ íƒì§€ìœ¨ (AS-IS) vs AI ë³´ì¡° ì‹œ ì‹¬ì‚¬ì—­ íƒì§€ìœ¨ (TO-BE)
    human_base_recall = 0.50  # ì¸ê°„ì€ ê²½í—˜ì ìœ¼ë¡œ 50%ë¥¼ ê±¸ëŸ¬ë‚¸ë‹¤ê³  ê°€ì • (ë³´ìˆ˜ì )
    human_ai_recall = 0.90    # AI ë¦¬í¬íŠ¸(SHAP)ë¥¼ ì°¸ê³ í•˜ë©´ ì •ë°€ ì‹¬ì‚¬ ì„±ê³µë¥  90%ë¡œ ìƒìŠ¹
    
    # === 2. AS-IS (í˜„ì¬ í”„ë¡œì„¸ìŠ¤) ë¹„ìš© ê³„ì‚° ===
    # ë¹„ìš© = ì „ì²´ ì „ìˆ˜ ì‹¬ì‚¬ë¹„ + (ì‚¬ëŒì´ ë†“ì¹œ ë¶€ë„ * ì†ì‹¤ê¸ˆ)
    asis_review_cost = len(y_test) * review_cost
    asis_missed_defaults = (tp + fn) * (1 - human_base_recall) # ì „ì²´ ë¶€ë„ ì¤‘ 50%ëŠ” ë†“ì¹¨
    asis_risk_cost = asis_missed_defaults * loss_per_default
    
    total_cost_asis = asis_review_cost + asis_risk_cost
    
    # === 3. TO-BE (AI í•˜ì´ë¸Œë¦¬ë“œ) ë¹„ìš© ê³„ì‚° ===
    # ìë™ ìŠ¹ì¸(Green)ì€ ì‹¬ì‚¬ë¹„ 0ì›, ì •ë°€ ì‹¬ì‚¬(Red/Yellow)ë§Œ ë¹„ìš© ë°œìƒ
    
    # A. ì„ ë³„ ì‹¬ì‚¬ ë¹„ìš© (TP + FP ëŒ€ìƒ)
    target_review_count = tp + fp
    tobe_review_cost = target_review_count * review_cost
    
    # B. ë¦¬ìŠ¤í¬ ë¹„ìš© (ë‘ ê°€ì§€ ê²½ë¡œì˜ ì†ì‹¤ í•©)
    # ê²½ë¡œ 1: Green ë“±ê¸‰ìœ¼ë¡œ ì˜ëª» ë¶„ë¥˜ë˜ì–´ ìë™ ìŠ¹ì¸ëœ ë¶€ë„ (Pure FN) -> ì „ì•¡ ì†ì‹¤
    risk_cost_green = fn * loss_per_default
    
    # ê²½ë¡œ 2: Red/Yellow ë“±ê¸‰ì´ì§€ë§Œ ì •ë°€ ì‹¬ì‚¬ì—ì„œ ì‚¬ëŒì´ ë†“ì¹œ ê²½ìš°
    # AIê°€ ì°¾ì•˜ìœ¼ë‚˜(TP), ì‚¬ëŒì´ "ì•„ë‹ˆë„¤" í•˜ê³  ìŠ¹ì¸í•´ë²„ë¦´ í™•ë¥  (1 - human_ai_recall)
    risk_cost_red = tp * (1 - human_ai_recall) * loss_per_default
    
    tobe_risk_cost = risk_cost_green + risk_cost_red
    total_cost_tobe = tobe_review_cost + tobe_risk_cost
    
    # === 4. ì„±ê³¼ ì§€í‘œ ì‚°ì¶œ ===
    net_benefit = total_cost_asis - total_cost_tobe
    roi = (net_benefit / 50_000_000) * 100  # ê°œë°œë¹„ 5ì²œë§Œì› ê°€ì •
    payback_period = 12 / (net_benefit / 50_000_000)

    # === 5. ê²°ê³¼ ì¶œë ¥ ===
    print("\nğŸ’° ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ ì¬í‰ê°€ (Conservative Scenario)")
    print("=" * 70)
    print(f"ê°€ì •: AS-IS ì¸ê°„ íƒì§€ìœ¨ {human_base_recall*100:.0f}% â”‚ TO-BE ì •ë°€ì‹¬ì‚¬ ì„±ê³µë¥  {human_ai_recall*100:.0f}%")
    print("-" * 70)
    
    print(f"1ï¸âƒ£ [AS-IS] ì¸ê°„ ì „ìˆ˜ ì‹¬ì‚¬ ë¹„ìš©")
    print(f"   - ìš´ì˜ ë¹„ìš©: {asis_review_cost/100000000:.2f}ì–µì› (10,000ê±´ ì‹¬ì‚¬)")
    print(f"   - ë¦¬ìŠ¤í¬ ë¹„ìš©: {asis_risk_cost/100000000:.2f}ì–µì› (ë¶€ë„ {int(asis_missed_defaults)}ê±´ ë¯¸íƒì§€)")
    print(f"   ğŸ‘‰ ì´ ë¹„ìš©: {total_cost_asis/100000000:.2f}ì–µì›")
    
    print(f"\n2ï¸âƒ£ [TO-BE] AI ì„ ë³„ + ì „ë¬¸ê°€ ì‹¬ì‚¬")
    print(f"   - ìš´ì˜ ë¹„ìš©: {tobe_review_cost/100000000:.2f}ì–µì› ({target_review_count:,}ê±´ ì„ ë³„ ì‹¬ì‚¬) ğŸ“‰")
    print(f"   - ë¦¬ìŠ¤í¬ ë¹„ìš©: {tobe_risk_cost/100000000:.2f}ì–µì› ğŸ“‰")
    print(f"   ğŸ‘‰ ì´ ë¹„ìš©: {total_cost_tobe/100000000:.2f}ì–µì›")
    
    print("-" * 70)
    print(f"3ï¸âƒ£ ìµœì¢… ì¬ë¬´ íš¨ê³¼")
    print(f"   âœ… ìˆœ íš¨ìµ (Net Benefit):  +{net_benefit:,.0f}ì› / ë…„")
    print(f"   ğŸ“ˆ ROI (íˆ¬ì ìˆ˜ìµë¥ ):     {roi:.1f}%")
    print(f"   â±ï¸ ì†ìµë¶„ê¸°ì (BEP):        {payback_period:.1f}ê°œì›”")
    print("=" * 70)

    # ì‹œê°í™”
    fig = go.Figure()
    fig.add_trace(go.Bar(
        name='ìš´ì˜ ë¹„ìš© (ì¸ê±´ë¹„)', x=['AS-IS', 'TO-BE'], 
        y=[asis_review_cost, tobe_review_cost], marker_color='lightgray'
    ))
    fig.add_trace(go.Bar(
        name='ë¦¬ìŠ¤í¬ ë¹„ìš© (ë¶€ë„ì†ì‹¤)', x=['AS-IS', 'TO-BE'], 
        y=[asis_risk_cost, tobe_risk_cost], marker_color='crimson'
    ))
    
    fig.update_layout(
        barmode='stack', 
        title='ëª¨ë¸ ë„ì… ì „í›„ ë¹„ìš© êµ¬ì¡° ë³€í™” (ë³´ìˆ˜ì  ê´€ì )',
        yaxis_title='ê¸ˆì•¡ (ì›)',
        height=500
    )
    fig.show()
```

    
    ğŸ’° ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ ì¬í‰ê°€ (Conservative Scenario)
    ======================================================================
    ê°€ì •: AS-IS ì¸ê°„ íƒì§€ìœ¨ 50% â”‚ TO-BE ì •ë°€ì‹¬ì‚¬ ì„±ê³µë¥  90%
    ----------------------------------------------------------------------
    1ï¸âƒ£ [AS-IS] ì¸ê°„ ì „ìˆ˜ ì‹¬ì‚¬ ë¹„ìš©
       - ìš´ì˜ ë¹„ìš©: 5.00ì–µì› (10,000ê±´ ì‹¬ì‚¬)
       - ë¦¬ìŠ¤í¬ ë¹„ìš©: 2.66ì–µì› (ë¶€ë„ 76ê±´ ë¯¸íƒì§€)
       ğŸ‘‰ ì´ ë¹„ìš©: 7.66ì–µì›
    
    2ï¸âƒ£ [TO-BE] AI ì„ ë³„ + ì „ë¬¸ê°€ ì‹¬ì‚¬
       - ìš´ì˜ ë¹„ìš©: 1.02ì–µì› (2,044ê±´ ì„ ë³„ ì‹¬ì‚¬) ğŸ“‰
       - ë¦¬ìŠ¤í¬ ë¹„ìš©: 1.98ì–µì› ğŸ“‰
       ğŸ‘‰ ì´ ë¹„ìš©: 3.00ì–µì›
    ----------------------------------------------------------------------
    3ï¸âƒ£ ìµœì¢… ì¬ë¬´ íš¨ê³¼
       âœ… ìˆœ íš¨ìµ (Net Benefit):  +465,700,000ì› / ë…„
       ğŸ“ˆ ROI (íˆ¬ì ìˆ˜ìµë¥ ):     931.4%
       â±ï¸ ì†ìµë¶„ê¸°ì (BEP):        1.3ê°œì›”
    ======================================================================




---

## ğŸ” Section 4: SHAP ë¶„ì„ â­â­â­ (ê°€ì¥ ì¤‘ìš”)

### Why SHAP?

**SHAP (SHapley Additive exPlanations)**: ê²Œì„ ì´ë¡  ê¸°ë°˜ ëª¨ë¸ í•´ì„ í”„ë ˆì„ì›Œí¬

**í•µì‹¬ ì§ˆë¬¸**:
- "ì™œ ì´ ê¸°ì—…ì´ ìœ„í—˜í•œê°€?"
- "ì–´ë–¤ íŠ¹ì„±ì´ ì˜ˆì¸¡ì— ì˜í–¥ì„ ë¯¸ì³¤ëŠ”ê°€?"
- "ê° íŠ¹ì„±ì´ ì–¼ë§ˆë‚˜ ê¸°ì—¬í–ˆëŠ”ê°€?"

**SHAPì˜ ì¥ì **:
1. âœ… **ì´ë¡ ì  ê·¼ê±°**: Shapley Value (ê²Œì„ ì´ë¡ )
2. âœ… **ì¼ê´€ì„±**: Feature Importance + ë°©í–¥ì„±
3. âœ… **Local + Global**: ê°œë³„ ì˜ˆì¸¡ + ì „ì²´ íŒ¨í„´
4. âœ… **Tree ëª¨ë¸ ìµœì í™”**: TreeExplainer (ê³ ì†)
5. âœ… **ê·œì œ ëŒ€ì‘**: ê¸ˆìœµ AI ê°€ì´ë“œë¼ì¸ ì¶©ì¡±

**ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜**:
- ëŒ€ì¶œ ê±°ì ˆ ì‚¬ìœ  ì„¤ëª… (ê·œì œ ìš”êµ¬ì‚¬í•­)
- ì‹¬ì‚¬ì—­ êµìœ¡ (ì–´ë–¤ ì§€í‘œë¥¼ ë´ì•¼ í•˜ëŠ”ê°€)
- ê³ ê° ë¶ˆë§Œ ëŒ€ì‘ ("ì™œ ê±°ì ˆë˜ì—ˆëŠ”ê°€?")

---

### 4.1 SHAP Explainer ì´ˆê¸°í™”


```python
# === ë””ë²„ê·¸: ëª¨ë¸ êµ¬ì¡° í™•ì¸ ===
print("ğŸ” ëª¨ë¸ êµ¬ì¡° ë””ë²„ê·¸")
print("=" * 70)
print(f"ëª¨ë¸ íƒ€ì…: {type(model)}")
print(f"ëª¨ë¸ í´ë˜ìŠ¤ ì´ë¦„: {type(model).__name__}")

# Pipelineì¸ì§€ í™•ì¸
if hasattr(model, 'steps'):
    print(f"\nâœ… Pipeline ê°ì²´ì…ë‹ˆë‹¤!")
    print(f"   - Pipeline ë‹¨ê³„ ìˆ˜: {len(model.steps)}")
    print(f"\n   - ê° ë‹¨ê³„:")
    for i, (name, step) in enumerate(model.steps):
        print(f"      {i}. '{name}': {type(step).__name__}")
    
    # ìµœì¢… ëª¨ë¸ ì¶”ì¶œ
    final_estimator = model.steps[-1][1]
    print(f"\n   - ìµœì¢… ëª¨ë¸ (classifier): {type(final_estimator).__name__}")
    
    # ë˜ëŠ” named_steps ì‚¬ìš©
    if hasattr(model, 'named_steps'):
        print(f"\n   - named_steps í‚¤: {list(model.named_steps.keys())}")
else:
    print(f"\nâŒ Pipelineì´ ì•„ë‹Œ ìˆœìˆ˜ ëª¨ë¸ì…ë‹ˆë‹¤.")

print("=" * 70)

```

    ğŸ” ëª¨ë¸ êµ¬ì¡° ë””ë²„ê·¸
    ======================================================================
    ëª¨ë¸ íƒ€ì…: <class 'imblearn.pipeline.Pipeline'>
    ëª¨ë¸ í´ë˜ìŠ¤ ì´ë¦„: Pipeline
    
    âœ… Pipeline ê°ì²´ì…ë‹ˆë‹¤!
       - Pipeline ë‹¨ê³„ ìˆ˜: 6
    
       - ê° ë‹¨ê³„:
          0. 'inf': InfiniteHandler
          1. 'imp': SimpleImputer
          2. 'log': LogTransformer
          3. 'scaler': RobustScaler
          4. 'resamp': SMOTE
          5. 'clf': CatBoostClassifier
    
       - ìµœì¢… ëª¨ë¸ (classifier): CatBoostClassifier
    
       - named_steps í‚¤: ['inf', 'imp', 'log', 'scaler', 'resamp', 'clf']
    ======================================================================



```python
if model is not None:
    print("ğŸ” SHAP Explainer ì´ˆê¸°í™” ì¤‘...")
    
    # Pipelineì—ì„œ ìµœì¢… ëª¨ë¸ ì¶”ì¶œ
    if hasattr(model, 'steps'):
        # Pipeline ê°ì²´ì¸ ê²½ìš°
        final_model = model.steps[-1][1]  # ë§ˆì§€ë§‰ ë‹¨ê³„ = classifier
        print(f"   - Pipeline ê°ì§€: ìµœì¢… ëª¨ë¸ ì¶”ì¶œ ({type(final_model).__name__})")
    else:
        # ìˆœìˆ˜ ëª¨ë¸ì¸ ê²½ìš°
        final_model = model
        print(f"   - ìˆœìˆ˜ ëª¨ë¸: {type(final_model).__name__}")
    
    # TreeExplainer ìƒì„± (ìµœì¢… ëª¨ë¸ ì‚¬ìš©)
    explainer = shap.TreeExplainer(final_model)
    print(f"âœ… TreeExplainer ìƒì„± ì™„ë£Œ: {type(explainer).__name__}")
```

    ğŸ” SHAP Explainer ì´ˆê¸°í™” ì¤‘...
       - Pipeline ê°ì§€: ìµœì¢… ëª¨ë¸ ì¶”ì¶œ (CatBoostClassifier)
    âœ… TreeExplainer ìƒì„± ì™„ë£Œ: TreeExplainer



```python
if model is not None:
    print("ğŸ” SHAP Explainer ì´ˆê¸°í™” ì¤‘...")
    
    # Pipelineì—ì„œ ìµœì¢… ëª¨ë¸ ì¶”ì¶œ
    if hasattr(model, 'steps'):
        final_model = model.steps[-1][1]
        print(f"   - Pipeline ê°ì§€: ìµœì¢… ëª¨ë¸ ì¶”ì¶œ ({type(final_model).__name__})")
    else:
        final_model = model
        print(f"   - ìˆœìˆ˜ ëª¨ë¸: {type(final_model).__name__}")
    
    # TreeExplainer ìƒì„±
    explainer = shap.TreeExplainer(final_model)
    print(f"âœ… TreeExplainer ìƒì„± ì™„ë£Œ: {type(explainer).__name__}")
    
    # SHAP values ê³„ì‚° (í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ìƒ˜í”Œë§)
    sample_size = min(1000, len(X_test))
    X_test_sample = X_test.sample(n=sample_size, random_state=RANDOM_STATE)
    y_test_sample = y_test.loc[X_test_sample.index]
    
    print(f"\n   - ìƒ˜í”Œ í¬ê¸°: {sample_size:,}ê°œ (ì „ì²´ {len(X_test):,}ê°œ ì¤‘)")
    print(f"   - íŠ¹ì„± ìˆ˜: {X_test_sample.shape[1]}ê°œ")
    print(f"   - ìƒ˜í”Œ ë¶€ë„ìœ¨: {y_test_sample.mean()*100:.2f}%")
    
    # === ë°ì´í„° ì „ì²˜ë¦¬ (Resampler ì œì™¸) ===
    if hasattr(model, 'steps'):
        print(f"\nğŸ”„ ì „ì²˜ë¦¬ ì ìš© ì¤‘...")
        
        from sklearn.pipeline import Pipeline
        
        # ë°©ë²•: SMOTEì™€ Classifier ì œì™¸ (steps[:-2])
        # steps[:-2] = 0~3ë²ˆ ë‹¨ê³„ (inf, imp, log, scaler)
        preprocessing_pipeline = Pipeline(model.steps[:-2])
        print(f"   - ì „ì²˜ë¦¬ ë‹¨ê³„: {[name for name, _ in preprocessing_pipeline.steps]}")
        
        X_test_sample_transformed = preprocessing_pipeline.transform(X_test_sample)
        print(f"   - ì „ì²˜ë¦¬ ì™„ë£Œ: {X_test_sample_transformed.shape}")
        
        # DataFrameìœ¼ë¡œ ë³€í™˜ (íŠ¹ì„± ì´ë¦„ ìœ ì§€)
        if hasattr(X_test_sample_transformed, 'toarray'):
            X_test_sample_transformed = X_test_sample_transformed.toarray()
        
        feature_names = X_test_sample.columns.tolist()
        X_test_sample_for_shap = pd.DataFrame(
            X_test_sample_transformed,
            columns=feature_names,
            index=X_test_sample.index
        )
    else:
        X_test_sample_for_shap = X_test_sample
        print(f"   - ì „ì²˜ë¦¬ ì—†ìŒ (ìˆœìˆ˜ ëª¨ë¸)")
    
    print(f"\nğŸ”„ SHAP values ê³„ì‚° ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    
    # SHAP values ê³„ì‚°
    shap_values = explainer.shap_values(X_test_sample_for_shap)
    
    # SHAP values íƒ€ì… ì²˜ë¦¬
    print(f"   - SHAP values íƒ€ì…: {type(shap_values)}")
    if isinstance(shap_values, list):
        print(f"   - List ê¸¸ì´: {len(shap_values)}")
        shap_values_bankruptcy = shap_values[1]  # class 1
        print(f"   - Class 1 (ë¶€ë„) SHAP values ì‚¬ìš©")
    elif len(shap_values.shape) == 3:
        print(f"   - 3D array shape: {shap_values.shape}")
        shap_values_bankruptcy = shap_values[:, :, 1]
        print(f"   - Class 1 (ë¶€ë„) SHAP values ì¶”ì¶œ")
    else:
        print(f"   - 2D array shape: {shap_values.shape}")
        shap_values_bankruptcy = shap_values
    
    print(f"âœ… SHAP values ê³„ì‚° ì™„ë£Œ")
    print(f"   - Shape: {shap_values_bankruptcy.shape}")
    print(f"   - Base value (í‰ê·  ì˜ˆì¸¡): {explainer.expected_value[1] if isinstance(explainer.expected_value, (list, np.ndarray)) else explainer.expected_value:.4f}")
else:
    print("âš ï¸  ëª¨ë¸ì´ ë¡œë”©ë˜ì§€ ì•Šì•„ SHAP ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
```

    ğŸ” SHAP Explainer ì´ˆê¸°í™” ì¤‘...
       - Pipeline ê°ì§€: ìµœì¢… ëª¨ë¸ ì¶”ì¶œ (CatBoostClassifier)
    âœ… TreeExplainer ìƒì„± ì™„ë£Œ: TreeExplainer
    
       - ìƒ˜í”Œ í¬ê¸°: 1,000ê°œ (ì „ì²´ 10,000ê°œ ì¤‘)
       - íŠ¹ì„± ìˆ˜: 25ê°œ
       - ìƒ˜í”Œ ë¶€ë„ìœ¨: 1.80%
    
    ğŸ”„ ì „ì²˜ë¦¬ ì ìš© ì¤‘...
       - ì „ì²˜ë¦¬ ë‹¨ê³„: ['inf', 'imp', 'log', 'scaler']
       - ì „ì²˜ë¦¬ ì™„ë£Œ: (1000, 25)
    
    ğŸ”„ SHAP values ê³„ì‚° ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)
       - SHAP values íƒ€ì…: <class 'numpy.ndarray'>
       - 2D array shape: (1000, 25)
    âœ… SHAP values ê³„ì‚° ì™„ë£Œ
       - Shape: (1000, 25)
       - Base value (í‰ê·  ì˜ˆì¸¡): -2.2930


### 4.2 SHAP Summary Plot (Feature Importance + Distribution)

**Summary Plot í•´ì„ ê°€ì´ë“œ**:

#### ìƒ‰ìƒ ì˜ë¯¸:
- ğŸ”´ **ë¹¨ê°„ìƒ‰**: íŠ¹ì„± ê°’ì´ ë†’ìŒ (ì˜ˆ: ì—°ì²´ ê±´ìˆ˜ ë§ìŒ, ë¶€ì±„ë¹„ìœ¨ ë†’ìŒ)
- ğŸ”µ **íŒŒë€ìƒ‰**: íŠ¹ì„± ê°’ì´ ë‚®ìŒ (ì˜ˆ: í˜„ê¸ˆ ì ìŒ, ì´ìë³´ìƒë°°ìœ¨ ë‚®ìŒ)

#### Xì¶• (SHAP value):
- **ì–‘ìˆ˜ (+)**: ë¶€ë„ í™•ë¥  ì¦ê°€ (ìœ„í—˜ ìš”ì¸)
- **ìŒìˆ˜ (-)**: ë¶€ë„ í™•ë¥  ê°ì†Œ (ì•ˆì „ ìš”ì¸)

#### í•´ì„ ì˜ˆì‹œ:
- **ì‹ ìš©ë“±ê¸‰ì ìˆ˜**ê°€ ë†’ìœ¼ë©´ (ë¹¨ê°„ìƒ‰, ë‚®ì€ ë“±ê¸‰) â†’ SHAP value ì–‘ìˆ˜ â†’ ë¶€ë„ ìœ„í—˜ ì¦ê°€ âœ…
- **ì¦‰ê°ì§€ê¸‰ëŠ¥ë ¥**ì´ ë†’ìœ¼ë©´ (ë¹¨ê°„ìƒ‰) â†’ SHAP value ìŒìˆ˜ â†’ ë¶€ë„ ìœ„í—˜ ê°ì†Œ âœ…
- **í˜„ê¸ˆì†Œì§„ì¼ìˆ˜**ê°€ ë‚®ìœ¼ë©´ (íŒŒë€ìƒ‰) â†’ SHAP value ì–‘ìˆ˜ â†’ ë¶€ë„ ìœ„í—˜ ì¦ê°€ âœ…


```python
if model is not None:
    # Summary Plot (Feature Importance + Distribution)
    plt.figure(figsize=(12, 10))
    shap.summary_plot(shap_values_bankruptcy, X_test_sample, plot_type="dot", show=False)
    plt.title('SHAP Summary Plot: íŠ¹ì„± ì¤‘ìš”ë„ ë° ì˜í–¥ ë°©í–¥', fontsize=16, weight='bold', pad=20)
    plt.xlabel('SHAP value (ë¶€ë„ í™•ë¥ ì— ëŒ€í•œ ì˜í–¥)', fontsize=12, weight='bold')
    plt.tight_layout()
    plt.show()

    # ğŸ’¡ Summary Plot í•´ì„ ì½”ë“œ ì¶”ê°€
    print("\n" + "=" * 70)
    print("ğŸ¯ SHAP Summary Plot (ì  ë¶„í¬) í•´ì„: ìœ„í—˜ì˜ ë°©í–¥ì„±")
    print("=" * 70)
    print("1. ğŸ¥‡ ì••ë„ì  ìœ„í—˜ ìš”ì¸: ì‹ ìš©ë“±ê¸‰ì ìˆ˜")
    print(" Â - ëª¨ë¸ì€ ì‹ ìš©ë“±ê¸‰ì ìˆ˜ê°€ ë‚®ì„ ë•Œ (íŒŒë€ìƒ‰, ì¢Œì¸¡) ë¶€ë„ ìœ„í—˜ì„ ê°€ì¥ í¬ê²Œ(SHAP ê°’ ì ˆëŒ“ê°’ì´ ê°€ì¥ í¬ê²Œ) ì˜¬ë¦°ë‹¤ê³  íŒë‹¨í•©ë‹ˆë‹¤.")
    print(" Â - ë‹¤ë¥¸ ëª¨ë“  ë³€ìˆ˜ë“¤ì„ í•©ì¹œ ê²ƒë³´ë‹¤ ì‹ ìš©ë“±ê¸‰ì ìˆ˜ì˜ ì˜í–¥ë ¥ì´ ê°€ì¥ ê°•ë ¥í•©ë‹ˆë‹¤.")
    print("2. ğŸ”´ ìœ ë™ì„± ë° ìš´ì˜ ìœ„í—˜ ìš”ì†Œ (ê°’ì´ ë†’ì„ ë•Œ ìœ„í—˜ ì¦ê°€)")
    print(" Â - ì¬ê³ ë³´ìœ ì¼ìˆ˜, ì—°ì²´ì‹¬ê°ë„, ì´ìë¶€ë‹´ë¥  ë“±ì˜ ë³€ìˆ˜ê°€ ë†’ì„ ë•Œ (ë¹¨ê°„ìƒ‰, ìš°ì¸¡) ë¶€ë„ í™•ë¥ ì„ í¬ê²Œ ë†’ì…ë‹ˆë‹¤.")
    print(" Â - ì´ëŠ” ì¬ê³  í˜„ê¸ˆí™” ì§€ì—°, ì±„ë¬´ ì´í–‰ ì‹¤íŒ¨, ë†’ì€ ì´ì ë¹„ìš© ë¶€ë‹´ ë“± ê¸°ì—…ì˜ ë‹¨ê¸° ìœ ë™ì„± ì•…í™”ë¥¼ ëª¨ë¸ì´ í•µì‹¬ ìœ„í—˜ ì‹ í˜¸ë¡œ í¬ì°©í•¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.")
    print("3. ğŸ”µ ì¬ë¬´ ê±´ì „ì„± (ê°’ì´ ë‚®ì„ ë•Œ ìœ„í—˜ ê°ì†Œ)")
    print(" Â - ìš´ì „ìë³¸_ëŒ€_ìì‚°, ì´ìë³´ìƒë°°ìœ¨ ë“±ì€ ê°’ì´ ë†’ì„ ë•Œ (ë¹¨ê°„ìƒ‰, ì¢Œì¸¡) ë¶€ë„ í™•ë¥ ì„ ë‚®ì¶¥ë‹ˆë‹¤.")
    print(" Â - ì´ëŠ” íšŒì‚¬ì˜ ì¬ë¬´ êµ¬ì¡°ê°€ ê±´ì „í• ìˆ˜ë¡ ëª¨ë¸ì´ ìœ„í—˜ì„ ë‚®ê²Œ ì˜ˆì¸¡í•˜ëŠ” ìƒì‹ì ì¸ ë…¼ë¦¬ë¡œ ì‘ë™í•˜ê³  ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.")
    print("=" * 70)

    print("\nğŸ’¡ Summary Plot í•´ì„:")
    print(" Â  - Yì¶•: ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬ëœ íŠ¹ì„±")
    print(" Â  - Xì¶•: ë¶€ë„ í™•ë¥ ì— ëŒ€í•œ ì˜í–¥ (ì–‘ìˆ˜ = ìœ„í—˜ ì¦ê°€, ìŒìˆ˜ = ìœ„í—˜ ê°ì†Œ)")
    print(" Â  - ìƒ‰ìƒ: ë¹¨ê°„ìƒ‰ = ë†’ì€ ê°’, íŒŒë€ìƒ‰ = ë‚®ì€ ê°’")
    print(" Â  - ë¶„í¬: ì ë“¤ì´ ë„“ê²Œ í¼ì§ˆìˆ˜ë¡ â†’ ì˜í–¥ì´ ë‹¤ì–‘í•¨ (ì¼€ì´ìŠ¤ë§ˆë‹¤ ë‹¤ë¦„)")

```


    
![png](output_32_0.png)
    


    
    ======================================================================
    ğŸ¯ SHAP Summary Plot (ì  ë¶„í¬) í•´ì„: ìœ„í—˜ì˜ ë°©í–¥ì„±
    ======================================================================
    1. ğŸ¥‡ ì••ë„ì  ìœ„í—˜ ìš”ì¸: ì‹ ìš©ë“±ê¸‰ì ìˆ˜
     Â - ëª¨ë¸ì€ ì‹ ìš©ë“±ê¸‰ì ìˆ˜ê°€ ë‚®ì„ ë•Œ (íŒŒë€ìƒ‰, ì¢Œì¸¡) ë¶€ë„ ìœ„í—˜ì„ ê°€ì¥ í¬ê²Œ(SHAP ê°’ ì ˆëŒ“ê°’ì´ ê°€ì¥ í¬ê²Œ) ì˜¬ë¦°ë‹¤ê³  íŒë‹¨í•©ë‹ˆë‹¤.
     Â - ë‹¤ë¥¸ ëª¨ë“  ë³€ìˆ˜ë“¤ì„ í•©ì¹œ ê²ƒë³´ë‹¤ ì‹ ìš©ë“±ê¸‰ì ìˆ˜ì˜ ì˜í–¥ë ¥ì´ ê°€ì¥ ê°•ë ¥í•©ë‹ˆë‹¤.
    2. ğŸ”´ ìœ ë™ì„± ë° ìš´ì˜ ìœ„í—˜ ìš”ì†Œ (ê°’ì´ ë†’ì„ ë•Œ ìœ„í—˜ ì¦ê°€)
     Â - ì¬ê³ ë³´ìœ ì¼ìˆ˜, ì—°ì²´ì‹¬ê°ë„, ì´ìë¶€ë‹´ë¥  ë“±ì˜ ë³€ìˆ˜ê°€ ë†’ì„ ë•Œ (ë¹¨ê°„ìƒ‰, ìš°ì¸¡) ë¶€ë„ í™•ë¥ ì„ í¬ê²Œ ë†’ì…ë‹ˆë‹¤.
     Â - ì´ëŠ” ì¬ê³  í˜„ê¸ˆí™” ì§€ì—°, ì±„ë¬´ ì´í–‰ ì‹¤íŒ¨, ë†’ì€ ì´ì ë¹„ìš© ë¶€ë‹´ ë“± ê¸°ì—…ì˜ ë‹¨ê¸° ìœ ë™ì„± ì•…í™”ë¥¼ ëª¨ë¸ì´ í•µì‹¬ ìœ„í—˜ ì‹ í˜¸ë¡œ í¬ì°©í•¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
    3. ğŸ”µ ì¬ë¬´ ê±´ì „ì„± (ê°’ì´ ë‚®ì„ ë•Œ ìœ„í—˜ ê°ì†Œ)
     Â - ìš´ì „ìë³¸_ëŒ€_ìì‚°, ì´ìë³´ìƒë°°ìœ¨ ë“±ì€ ê°’ì´ ë†’ì„ ë•Œ (ë¹¨ê°„ìƒ‰, ì¢Œì¸¡) ë¶€ë„ í™•ë¥ ì„ ë‚®ì¶¥ë‹ˆë‹¤.
     Â - ì´ëŠ” íšŒì‚¬ì˜ ì¬ë¬´ êµ¬ì¡°ê°€ ê±´ì „í• ìˆ˜ë¡ ëª¨ë¸ì´ ìœ„í—˜ì„ ë‚®ê²Œ ì˜ˆì¸¡í•˜ëŠ” ìƒì‹ì ì¸ ë…¼ë¦¬ë¡œ ì‘ë™í•˜ê³  ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
    ======================================================================
    
    ğŸ’¡ Summary Plot í•´ì„:
     Â  - Yì¶•: ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬ëœ íŠ¹ì„±
     Â  - Xì¶•: ë¶€ë„ í™•ë¥ ì— ëŒ€í•œ ì˜í–¥ (ì–‘ìˆ˜ = ìœ„í—˜ ì¦ê°€, ìŒìˆ˜ = ìœ„í—˜ ê°ì†Œ)
     Â  - ìƒ‰ìƒ: ë¹¨ê°„ìƒ‰ = ë†’ì€ ê°’, íŒŒë€ìƒ‰ = ë‚®ì€ ê°’
     Â  - ë¶„í¬: ì ë“¤ì´ ë„“ê²Œ í¼ì§ˆìˆ˜ë¡ â†’ ì˜í–¥ì´ ë‹¤ì–‘í•¨ (ì¼€ì´ìŠ¤ë§ˆë‹¤ ë‹¤ë¦„)


### 4.3 SHAP Feature Importance (ì ˆëŒ“ê°’ í‰ê· )

**Feature Importance = Mean(|SHAP value|)**

ë°©í–¥(+/-)ê³¼ ë¬´ê´€í•˜ê²Œ, ì˜ˆì¸¡ì— ë¯¸ì¹˜ëŠ” **ì˜í–¥ì˜ í¬ê¸°**ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.


```python
if model is not None:
    # Feature Importance (ì ˆëŒ“ê°’ í‰ê· )
    plt.figure(figsize=(12, 10))
    shap.summary_plot(shap_values_bankruptcy, X_test_sample, plot_type="bar", show=False)
    plt.title('SHAP Feature Importance: Top 20', fontsize=16, weight='bold', pad=20)
    plt.xlabel('Mean |SHAP value| (í‰ê·  ì ˆëŒ“ê°’)', fontsize=12, weight='bold')
    plt.tight_layout()
    plt.show()
    
    # Top 10 íŠ¹ì„± ì¶”ì¶œ
    feature_importance = pd.DataFrame({
        'Feature': X_test_sample.columns,
        'SHAP_Importance': np.abs(shap_values_bankruptcy).mean(axis=0)
    }).sort_values('SHAP_Importance', ascending=False)
    
    print("\n" + "=" * 70)
    print("ğŸ“Š Top 15 ì¤‘ìš” íŠ¹ì„± (SHAP Importance)")
    print("=" * 70)
    print(feature_importance.head(15).to_string(index=False))
    print("=" * 70)
    
    # Top 10 íŠ¹ì„± ì €ì¥ (ì¬ë¬´ í•´ì„ìš©)
    top10_features = feature_importance.head(10)['Feature'].tolist()
    # ğŸ’¡ Feature Importance í•´ì„ ì½”ë“œ ì¶”ê°€
    print("\n" + "=" * 70)
    print("ğŸ¯ SHAP Feature Importance (ë§‰ëŒ€ ê·¸ë˜í”„) í•´ì„: ì¤‘ìš”ë„ ìˆœìœ„")
    print("=" * 70)
    print("1. ğŸ¥‡ ì‹ ìš© ë“±ê¸‰ì˜ ì ˆëŒ€ì  ì¤‘ìš”ì„±")
    print(f" Â - {top10_features[0]}ëŠ” ì¤‘ìš”ë„ {feature_importance.iloc[0]['SHAP_Importance']:.3f}ë¡œ, 2ìœ„ ë³€ìˆ˜({feature_importance.iloc[1]['SHAP_Importance']:.3f})ë³´ë‹¤ 2ë°° ì´ìƒ ë†’ì€ ì••ë„ì ì¸ ì˜í–¥ë ¥ì„ ê°€ì§‘ë‹ˆë‹¤.")
    print(" Â - ì´ëŠ” ê³µì‹ì ì¸ ì‹ ìš© ìœ„í—˜ ì •ë³´ê°€ ë‹¤ë¥¸ ì¬ë¬´/ë¹„ì¬ë¬´ ì •ë³´ë³´ë‹¤ ë¶€ë„ ì˜ˆì¸¡ì— ìˆì–´ ê°€ì¥ ê²°ì •ì ì„ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.")
    print("2. ğŸ¥ˆ ìœ ë™ì„± ë° ìš´ì˜ íš¨ìœ¨ ì§€í‘œ ë¶€ìƒ")
    print(f" Â - ì¬ê³ ë³´ìœ ì¼ìˆ˜ì™€ ì—°ì²´ì‹¬ê°ë„ê°€ ì „í†µì ì¸ ì¬ë¬´ ë¹„ìœ¨ë³´ë‹¤ ë†’ì€ 2, 3ìœ„ì— ìœ„ì¹˜í•©ë‹ˆë‹¤.")
    print(" Â - ëª¨ë¸ì€ ë‹¨ìˆœ ë¶€ì±„ ë¹„ìœ¨ë³´ë‹¤ ì¬ê³ ê°€ í˜„ê¸ˆìœ¼ë¡œ ì–¼ë§ˆë‚˜ ë¹¨ë¦¬ ì „í™˜ë˜ëŠ”ì§€ì™€ ë‹¨ê¸° ì±„ë¬´ ìƒí™˜ ëŠ¥ë ¥ ë“± ìš´ì˜ìƒì˜ ë¬¸ì œë¥¼ ë¯¼ê°í•˜ê²Œ ê°ì§€í•©ë‹ˆë‹¤.")
    print("3. ğŸ“‰ ì „í†µì  ì¬ë¬´ ë¹„ìœ¨ì˜ í›„ìˆœìœ„ ë°°ì¹˜")
    print(" Â - ë¶€ì±„ë ˆë²„ë¦¬ì§€(9ìœ„)ì™€ ê°™ì€ ì „í†µì ì¸ ì•ˆì •ì„± ë¹„ìœ¨ì€ ìƒìœ„ê¶Œì— ìœ„ì¹˜í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    print(" Â - ì´ëŠ” ë¶€ì±„ ìˆ˜ì¤€ ìì²´ë³´ë‹¤ëŠ” ìœ ë™ì„± ì••ë°•(ê¸´ê¸‰ìœ ë™ì„±, ìœ ë™ì„±ì••ë°•ì§€ìˆ˜) ë“± ë‹¨ê¸° ìœ„í—˜ì— ê´€ë ¨ëœ ì§€í‘œë“¤ì´ ëª¨ë¸ì—ê²Œ ë” ì¤‘ìš”í•œ ì˜ˆì¸¡ë ¥ì„ ì œê³µí•¨ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.")
    print("=" * 70)
    print(f"\nâœ… Top 10 íŠ¹ì„± ì¶”ì¶œ ì™„ë£Œ: {len(top10_features)}ê°œ")
    for i, feat in enumerate(top10_features, 1):
        print(f"   {i}. {feat}")
```


    
![png](output_34_0.png)
    


    
    ======================================================================
    ğŸ“Š Top 15 ì¤‘ìš” íŠ¹ì„± (SHAP Importance)
    ======================================================================
      Feature  SHAP_Importance
       ì‹ ìš©ë“±ê¸‰ì ìˆ˜         0.702784
       ì¬ê³ ë³´ìœ ì¼ìˆ˜         0.323321
        ì—°ì²´ì‹¬ê°ë„         0.194871
      ê³µê³µì •ë³´ë¦¬ìŠ¤í¬         0.165897
        ì´ìë¶€ë‹´ë¥          0.109390
    ë§¤ì¶œì±„ê¶Œ_ì´ìƒì§€í‘œ         0.096356
        ì¬ê³ íšŒì „ìœ¨         0.092516
      ìœ ë™ì„±ì••ë°•ì§€ìˆ˜         0.061839
        ê¸´ê¸‰ìœ ë™ì„±         0.055555
       ì´ìë³´ìƒë°°ìœ¨         0.050330
       ë¶€ì±„ë ˆë²„ë¦¬ì§€         0.049010
         ì´ë°œìƒì•¡         0.046656
       í˜„ê¸ˆì†Œì§„ì¼ìˆ˜         0.030028
       ì¦‰ê°ì§€ê¸‰ëŠ¥ë ¥         0.024463
       ë¶€ì±„ìƒí™˜ë…„ìˆ˜         0.020937
    ======================================================================
    
    ======================================================================
    ğŸ¯ SHAP Feature Importance (ë§‰ëŒ€ ê·¸ë˜í”„) í•´ì„: ì¤‘ìš”ë„ ìˆœìœ„
    ======================================================================
    1. ğŸ¥‡ ì‹ ìš© ë“±ê¸‰ì˜ ì ˆëŒ€ì  ì¤‘ìš”ì„±
     Â - ì‹ ìš©ë“±ê¸‰ì ìˆ˜ëŠ” ì¤‘ìš”ë„ 0.703ë¡œ, 2ìœ„ ë³€ìˆ˜(0.323)ë³´ë‹¤ 2ë°° ì´ìƒ ë†’ì€ ì••ë„ì ì¸ ì˜í–¥ë ¥ì„ ê°€ì§‘ë‹ˆë‹¤.
     Â - ì´ëŠ” ê³µì‹ì ì¸ ì‹ ìš© ìœ„í—˜ ì •ë³´ê°€ ë‹¤ë¥¸ ì¬ë¬´/ë¹„ì¬ë¬´ ì •ë³´ë³´ë‹¤ ë¶€ë„ ì˜ˆì¸¡ì— ìˆì–´ ê°€ì¥ ê²°ì •ì ì„ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
    2. ğŸ¥ˆ ìœ ë™ì„± ë° ìš´ì˜ íš¨ìœ¨ ì§€í‘œ ë¶€ìƒ
     Â - ì¬ê³ ë³´ìœ ì¼ìˆ˜ì™€ ì—°ì²´ì‹¬ê°ë„ê°€ ì „í†µì ì¸ ì¬ë¬´ ë¹„ìœ¨ë³´ë‹¤ ë†’ì€ 2, 3ìœ„ì— ìœ„ì¹˜í•©ë‹ˆë‹¤.
     Â - ëª¨ë¸ì€ ë‹¨ìˆœ ë¶€ì±„ ë¹„ìœ¨ë³´ë‹¤ ì¬ê³ ê°€ í˜„ê¸ˆìœ¼ë¡œ ì–¼ë§ˆë‚˜ ë¹¨ë¦¬ ì „í™˜ë˜ëŠ”ì§€ì™€ ë‹¨ê¸° ì±„ë¬´ ìƒí™˜ ëŠ¥ë ¥ ë“± ìš´ì˜ìƒì˜ ë¬¸ì œë¥¼ ë¯¼ê°í•˜ê²Œ ê°ì§€í•©ë‹ˆë‹¤.
    3. ğŸ“‰ ì „í†µì  ì¬ë¬´ ë¹„ìœ¨ì˜ í›„ìˆœìœ„ ë°°ì¹˜
     Â - ë¶€ì±„ë ˆë²„ë¦¬ì§€(9ìœ„)ì™€ ê°™ì€ ì „í†µì ì¸ ì•ˆì •ì„± ë¹„ìœ¨ì€ ìƒìœ„ê¶Œì— ìœ„ì¹˜í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.
     Â - ì´ëŠ” ë¶€ì±„ ìˆ˜ì¤€ ìì²´ë³´ë‹¤ëŠ” ìœ ë™ì„± ì••ë°•(ê¸´ê¸‰ìœ ë™ì„±, ìœ ë™ì„±ì••ë°•ì§€ìˆ˜) ë“± ë‹¨ê¸° ìœ„í—˜ì— ê´€ë ¨ëœ ì§€í‘œë“¤ì´ ëª¨ë¸ì—ê²Œ ë” ì¤‘ìš”í•œ ì˜ˆì¸¡ë ¥ì„ ì œê³µí•¨ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
    ======================================================================
    
    âœ… Top 10 íŠ¹ì„± ì¶”ì¶œ ì™„ë£Œ: 10ê°œ
       1. ì‹ ìš©ë“±ê¸‰ì ìˆ˜
       2. ì¬ê³ ë³´ìœ ì¼ìˆ˜
       3. ì—°ì²´ì‹¬ê°ë„
       4. ê³µê³µì •ë³´ë¦¬ìŠ¤í¬
       5. ì´ìë¶€ë‹´ë¥ 
       6. ë§¤ì¶œì±„ê¶Œ_ì´ìƒì§€í‘œ
       7. ì¬ê³ íšŒì „ìœ¨
       8. ìœ ë™ì„±ì••ë°•ì§€ìˆ˜
       9. ê¸´ê¸‰ìœ ë™ì„±
       10. ì´ìë³´ìƒë°°ìœ¨


---

### ğŸ” 4.4 Top 10 íŠ¹ì„± ì¬ë¬´ í•´ì„ â­â­

ê° íŠ¹ì„±ì„ **ì¬ë¬´ ê´€ì **ì—ì„œ ê¹Šì´ ìˆê²Œ í•´ì„í•©ë‹ˆë‹¤.

---

#### 1. **ì‹ ìš©ë“±ê¸‰ì ìˆ˜** (SHAP Importance ì˜ˆìƒ: ë†’ìŒ)

**ì¬ë¬´ ì˜ë¯¸**: ì‹ ìš©í‰ê°€ì‚¬ì˜ ì¢…í•© í‰ê°€ (1=AAA, 10=D)

**ë¶€ë„ ì˜ˆì¸¡ ë©”ì»¤ë‹ˆì¦˜**:
- ë“±ê¸‰ì´ ë‚®ì„ìˆ˜ë¡ (ìˆ«ì ë†’ì„ìˆ˜ë¡) ë¶€ë„ í™•ë¥  ì¦ê°€
- ì‹ ìš©í‰ê°€ì‚¬ê°€ ì¬ë¬´ì œí‘œ, ì—…ê³„ ë™í–¥, ê²½ì˜ì§„ í‰ê°€ ë“±ì„ ì¢…í•©
- ë“±ê¸‰ í•˜ë½ = ìœ„í—˜ ì‹ í˜¸

**ìœ„í—˜ ê¸°ì¤€**:
- ë“±ê¸‰ 1~3 (AAA~A): ì•ˆì „
- ë“±ê¸‰ 4~5 (BBB~BB): ì£¼ì˜
- ë“±ê¸‰ â‰¥ 6 (B ì´í•˜): **ê³ ìœ„í—˜** ğŸ”´

**ë¹„ì¦ˆë‹ˆìŠ¤ í™œìš©**:
- 1ì°¨ ìŠ¤í¬ë¦¬ë‹ ì§€í‘œ (ë“±ê¸‰ 6 ì´ìƒ â†’ ì •ë°€ ì‹¬ì‚¬)
- ê¸ˆë¦¬ ì°¨ë“± ì ìš© (ë“±ê¸‰ 1ì  ì°¨ì´ = ê¸ˆë¦¬ +0.5%p)

âš ï¸ **Data Leakage ê°€ëŠ¥ì„±**:
- ì‹ ìš©ë“±ê¸‰ ìì²´ê°€ ë¶€ë„ ì˜ˆì¸¡ ëª¨ë¸ë¡œ ë§Œë“¤ì–´ì§
- ìš°ë¦¬ ëª¨ë¸ê³¼ ì¤‘ë³µ ê°€ëŠ¥ì„±
- **ê²€í†  í•„ìš”**: ì‹ ìš©ë“±ê¸‰ ì œì™¸ í›„ ì„±ëŠ¥ ë¹„êµ

---

#### 2. **ì¦‰ê°ì§€ê¸‰ëŠ¥ë ¥** (SHAP Importance ì˜ˆìƒ: ë†’ìŒ)

**ì¬ë¬´ ì˜ë¯¸**: (í˜„ê¸ˆ + í˜„ê¸ˆì„±ìì‚°) / ìœ ë™ë¶€ì±„

**ë¶€ë„ ì˜ˆì¸¡ ë©”ì»¤ë‹ˆì¦˜**:
- ë¹„ìœ¨ì´ ë‚®ì„ìˆ˜ë¡ â†’ ë‹¨ê¸° ë¶€ì±„ë¥¼ í˜„ê¸ˆìœ¼ë¡œ ê°šì„ ìˆ˜ ì—†ìŒ â†’ ìœ ë™ì„± ìœ„ê¸°
- "ì§€ê¸ˆ ë‹¹ì¥ ì±„ê¶Œìê°€ ëˆì„ ìš”êµ¬í•˜ë©´ ê°šì„ ìˆ˜ ìˆëŠ”ê°€?"

**ìœ„í—˜ ê¸°ì¤€**:
| ë¹„ìœ¨ | í•´ì„ | ë¦¬ìŠ¤í¬ |
|------|------|--------|
| < 0.1 | ë§¤ìš° ìœ„í—˜ (í˜„ê¸ˆì´ ìœ ë™ë¶€ì±„ì˜ 10%ë„ ì•ˆ ë¨) | ğŸ”´ High |
| 0.1~0.3 | ìœ„í—˜ | ğŸŸ¡ Medium |
| 0.3~0.5 | ì£¼ì˜ | ğŸŸ¢ Low |
| > 0.5 | ì•ˆì „ | âœ… Safe |

**ë¹„ì¦ˆë‹ˆìŠ¤ í™œìš©**:
- "3ê°œì›” ë‚´ ì‚´ì•„ë‚¨ì„ ìˆ˜ ìˆëŠ”ê°€?" íŒë‹¨
- ë‹¨ê¸° ëŒ€ì¶œ ì‹¬ì‚¬ ì‹œ í•µì‹¬ ì§€í‘œ

**ì‹¤ì œ ì‚¬ë¡€**:
- í‘ìë„ì‚° ê¸°ì—…ì˜ 90%ê°€ ì¦‰ê°ì§€ê¸‰ëŠ¥ë ¥ < 0.1
- "ì¥ë¶€ìƒ ì´ìµì€ ìˆì§€ë§Œ í˜„ê¸ˆì´ ì—†ì–´ì„œ ë¶€ë„"

**Part 2 ë„ë©”ì¸ ì§€ì‹**:
```python
features['ì¦‰ê°ì§€ê¸‰ëŠ¥ë ¥'] = (df['í˜„ê¸ˆ'] + df.get('í˜„ê¸ˆì„±ìì‚°', 0)) / (df['ìœ ë™ë¶€ì±„'] + 1)
```

---

#### 3. **í˜„ê¸ˆì†Œì§„ì¼ìˆ˜** (SHAP Importance ì˜ˆìƒ: ë†’ìŒ)

**ì¬ë¬´ ì˜ë¯¸**: í˜„ê¸ˆ / (ì˜ì—…ë¹„ìš© / 365)

**ë¶€ë„ ì˜ˆì¸¡ ë©”ì»¤ë‹ˆì¦˜**:
- í˜„ì¬ í˜„ê¸ˆìœ¼ë¡œ ë©°ì¹ ì´ë‚˜ ë²„í‹¸ ìˆ˜ ìˆëŠ”ê°€?
- ë§¤ì¼ ì†Œëª¨ë˜ëŠ” ì˜ì—…ë¹„ìš©(ê¸‰ì—¬, ì„ëŒ€ë£Œ, ì›ì¬ë£Œ ë“±) ëŒ€ë¹„ í˜„ê¸ˆ ë³´ìœ  ê¸°ê°„

**ìœ„í—˜ ê¸°ì¤€**:
| ì¼ìˆ˜ | í•´ì„ | ë¦¬ìŠ¤í¬ |
|------|------|--------|
| < 30ì¼ | ë§¤ìš° ìœ„í—˜ (í•œ ë‹¬ë„ ëª» ë²„íŒ€) | ğŸ”´ Critical |
| 30~60ì¼ | ìœ„í—˜ | ğŸ”´ High |
| 60~90ì¼ | ì£¼ì˜ | ğŸŸ¡ Medium |
| 90~180ì¼ | ë³´í†µ | ğŸŸ¢ Low |
| > 180ì¼ (6ê°œì›”) | ì•ˆì „ | âœ… Safe |

**ë¹„ì¦ˆë‹ˆìŠ¤ í™œìš©**:
- ê¸´ê¸‰ ìê¸ˆ ì§€ì› í•„ìš” ì—¬ë¶€ íŒë‹¨
- "ë‹¤ìŒ ë‹¬ ê¸‰ì—¬ë¥¼ ì¤„ ìˆ˜ ìˆëŠ”ê°€?"

**ì‹¤ë¬´ ì¤‘ìš”ì„±**:
- ë¶€ë„ 3ê°œì›” ì „ì— ê¸‰ê²©íˆ ê°ì†Œ â†’ **ì¡°ê¸° ê²½ë³´ ì‹ í˜¸**
- ì˜ˆ: 180ì¼ â†’ 60ì¼ â†’ 30ì¼ â†’ ë¶€ë„

**Part 2 ë„ë©”ì¸ ì§€ì‹**:
```python
features['í˜„ê¸ˆì†Œì§„ì¼ìˆ˜'] = (df['í˜„ê¸ˆ'] + df.get('í˜„ê¸ˆì„±ìì‚°', 0)) / (df.get('ì˜ì—…ë¹„ìš©', df['ë§¤ì¶œì›ê°€']) / 365 + 1)
```

---

#### 4. **ì´ìë³´ìƒë°°ìœ¨** (SHAP Importance ì˜ˆìƒ: ì¤‘ìƒ)

**ì¬ë¬´ ì˜ë¯¸**: (ì˜ì—…ì´ìµ + ê°ê°€ìƒê°ë¹„) / ì´ìë¹„ìš©

**ë¶€ë„ ì˜ˆì¸¡ ë©”ì»¤ë‹ˆì¦˜**:
- ì˜ì—…ìœ¼ë¡œ ì´ìë¥¼ ê°šì„ ìˆ˜ ìˆëŠ”ê°€?
- ë¹„ìœ¨ < 1.0 â†’ ì˜ì—…ì´ìµ < ì´ìë¹„ìš© â†’ **ë²„í‹¸ ìˆ˜ ì—†ìŒ**

**ìœ„í—˜ ê¸°ì¤€**:
| ë¹„ìœ¨ | í•´ì„ | ë¦¬ìŠ¤í¬ |
|------|------|--------|
| < 0 | ì˜ì—… ì ì (ì´ì ê°šì„ ì—¬ë ¥ ì—†ìŒ) | ğŸ”´ Critical |
| 0~1.0 | ì˜ì—…ì´ìµ < ì´ì â†’ ì›ê¸ˆ ìƒí™˜ ë¶ˆê°€ | ğŸ”´ High |
| 1.0~1.5 | ìœ„í—˜ (ì´ìë§Œ ê²¨ìš° ê°šìŒ) | ğŸŸ¡ Medium |
| 1.5~2.0 | ì£¼ì˜ | ğŸŸ¢ Low |
| > 2.0 | ì•ˆì „ | âœ… Safe |

**ë¹„ì¦ˆë‹ˆìŠ¤ í™œìš©**:
- ì¶”ê°€ ì°¨ì… ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨
- ê¸°ì¡´ ëŒ€ì¶œ ì—°ì¥ ì‹¬ì‚¬

**ê²½ì œì  ì˜ë¯¸**:
- ì´ìë³´ìƒë°°ìœ¨ < 1ì´ë©´ â†’ "ì˜ì—…í• ìˆ˜ë¡ ì†í•´"
- ë¶€ì±„ë¡œ ì—°ëª… â†’ ê²°êµ­ íŒŒì‚°

---

#### 5. **ìš´ì „ìë³¸_ëŒ€_ìì‚°** (SHAP Importance ì˜ˆìƒ: ì¤‘ìƒ)

**ì¬ë¬´ ì˜ë¯¸**: (ìœ ë™ìì‚° - ìœ ë™ë¶€ì±„) / ìì‚°ì´ê³„

**ë¶€ë„ ì˜ˆì¸¡ ë©”ì»¤ë‹ˆì¦˜**:
- ìš´ì „ìë³¸ = ìœ ë™ìì‚° - ìœ ë™ë¶€ì±„
- ìŒìˆ˜ë©´ â†’ ë‹¨ê¸° ë¶€ì±„ê°€ ìœ ë™ìì‚°ë³´ë‹¤ ë§ìŒ â†’ ìœ ë™ì„± ìœ„ê¸°

**ìœ„í—˜ ê¸°ì¤€**:
| ë¹„ìœ¨ | í•´ì„ | ë¦¬ìŠ¤í¬ |
|------|------|--------|
| < 0 | ë§¤ìš° ìœ„í—˜ (ìš´ì „ìë³¸ ë¶€ì¡±) | ğŸ”´ Critical |
| 0~0.1 | ìœ„í—˜ | ğŸ”´ High |
| 0.1~0.2 | ì£¼ì˜ | ğŸŸ¡ Medium |
| > 0.2 | ì•ˆì „ (ìì‚°ì˜ 20% ì´ìƒì´ ìš´ì „ìë³¸) | âœ… Safe |

**ë¹„ì¦ˆë‹ˆìŠ¤ í™œìš©**:
- ë‹¨ê¸° ìœ ë™ì„± ê±´ì „ì„± í‰ê°€
- "íšŒì‚¬ê°€ ì •ìƒ ìš´ì˜ë  ìˆ˜ ìˆëŠ”ê°€?"

**Part 2 ë„ë©”ì¸ ì§€ì‹**:
```python
features['ìš´ì „ìë³¸'] = df['ìœ ë™ìì‚°'] - df['ìœ ë™ë¶€ì±„']
features['ìš´ì „ìë³¸_ëŒ€_ìì‚°'] = features['ìš´ì „ìë³¸'] / (df.get('ìì‚°ì´ê³„', 1) + 1)
```

### ğŸ’¡ Top 10 íŠ¹ì„± ì¢…í•© í•´ì„

#### ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜:

| ì¹´í…Œê³ ë¦¬ | íŠ¹ì„± | ë¹„ì¤‘ |
|----------|------|------|
| **ìœ ë™ì„± ìœ„ê¸°** | ì¦‰ê°ì§€ê¸‰ëŠ¥ë ¥, í˜„ê¸ˆì†Œì§„ì¼ìˆ˜, ìš´ì „ìë³¸_ëŒ€_ìì‚° | 30% |
| **ì§€ê¸‰ë¶ˆëŠ¥** | ì´ìë³´ìƒë°°ìœ¨, ì¬ë¬´ë ˆë²„ë¦¬ì§€, ìë³¸ì ì‹ë„, ë¶€ì±„ë¹„ìœ¨ | 40% |
| **ì¬ë¬´ì¡°ì‘ íƒì§€** | M_Score_í•œêµ­í˜•, ë°œìƒì•¡ë¹„ìœ¨ | 20% |
| **ì™¸ë¶€ í‰ê°€** | ì‹ ìš©ë“±ê¸‰ì ìˆ˜ | 10% |

#### í•µì‹¬ ì¸ì‚¬ì´íŠ¸:

1. **ìœ ë™ì„± > ìˆ˜ìµì„±**: í˜„ê¸ˆ ê´€ë ¨ ì§€í‘œê°€ ìµœìƒìœ„ (ì¦‰ê°ì§€ê¸‰ëŠ¥ë ¥, í˜„ê¸ˆì†Œì§„ì¼ìˆ˜)
   - "í‘ìë„ì‚°"ì´ ë§ê¸° ë•Œë¬¸
   - ë‹¨ê¸° ìƒì¡´ ëŠ¥ë ¥ì´ ë¶€ë„ ì˜ˆì¸¡ì˜ í•µì‹¬

2. **ì¡°ì‘ íƒì§€ ì¤‘ìš”**: M-Score, ë°œìƒì•¡ë¹„ìœ¨ ë“±ì¥
   - ë¶€ë„ ì§ì „ ê¸°ì—…ì€ ì¬ë¬´ì œí‘œ ì¡°ì‘ ê°€ëŠ¥ì„± ë†’ìŒ
   - ìˆ«ìë¥¼ ì•¡ë©´ ê·¸ëŒ€ë¡œ ë¯¿ì§€ ë§ê³  ê²€ì¦ í•„ìš”

3. **ì‹ ìš©ë“±ê¸‰ì˜ ì–‘ë‚ ì˜ ê²€**:
   - ê°•ë ¥í•œ ì˜ˆì¸¡ë ¥ âœ…
   - Data Leakage ìœ„í—˜ âš ï¸
   - í–¥í›„: ì‹ ìš©ë“±ê¸‰ ì œì™¸ ëª¨ë¸ ì‹¤í—˜ í•„ìš”

4. **ë¶€ì±„ ìì²´ë³´ë‹¤ ìƒí™˜ ëŠ¥ë ¥**:
   - ë¶€ì±„ë¹„ìœ¨ë³´ë‹¤ ì´ìë³´ìƒë°°ìœ¨ì´ ë” ì¤‘ìš”
   - "ë¹šì´ ë§ì•„ë„ ê°šì„ ìˆ˜ ìˆìœ¼ë©´ OK"

---

---

## ğŸš¦ Section 5: Traffic Light ì‹œìŠ¤í…œ (ì‹¤ë¬´ í™œìš©)

### Why Traffic Light?

**ë¬¸ì œ**: Binary ë¶„ë¥˜ (ë¶€ë„/ì •ìƒ)ë§Œìœ¼ë¡œëŠ” ì‹¤ë¬´ ì˜ì‚¬ê²°ì • ë¶€ì¡±

**í•´ê²°**: ì˜ˆì¸¡ í™•ë¥ ì„ 3ë‹¨ê³„ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ„ì–´ **ë§ì¶¤í˜• ì¡°ì¹˜**

#### êµ¬ê°„ ì •ì˜:

| êµ¬ê°„ | í™•ë¥  ë²”ìœ„ | ì˜ë¯¸ | ì¡°ì¹˜ |
|------|-----------|------|------|
| ğŸ”´ **Red** | â‰¥ 0.0468 | High Risk (Recall 80%) | ëŒ€ì¶œ ê±°ì ˆ ë˜ëŠ” ê³ ê¸ˆë¦¬/ë‹´ë³´ |
| ğŸŸ¡ **Yellow** | 0.0168~0.0468 | Potential Risk (Recall 95%) | **ì‚¬ëŒì˜ ì •ë°€ ì‹¬ì‚¬** |
| ğŸŸ¢ **Green** | < 0.0168 | Safe | ìë™ ìŠ¹ì¸ |

#### ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜:

1. **Green (ìë™ ìŠ¹ì¸)**:
   - ë¶€ë„ìœ¨ < 1% â†’ ì•ˆì „
   - ì‹¬ì‚¬ ì¸ë ¥ 80% ì ˆê°
   - ë¹ ë¥¸ ìŠ¹ì¸ â†’ ê³ ê° ë§Œì¡±ë„ í–¥ìƒ

2. **Yellow (ì •ë°€ ì‹¬ì‚¬)**:
   - ì• ë§¤í•œ êµ¬ê°„ â†’ ì‚¬ëŒì´ ìµœì¢… íŒë‹¨
   - FP (ì˜¤íƒì§€) ì¤‘ ì¼ë¶€ êµ¬ì œ ê°€ëŠ¥
   - ëª¨ë¸ + ì‚¬ëŒì˜ í˜‘ì—…

3. **Red (ê±°ì ˆ/ê³ ê¸ˆë¦¬)**:
   - í™•ì‹¤í•œ ìœ„í—˜ â†’ ì¦‰ì‹œ ì¡°ì¹˜
   - ëŒ€ì¶œ ê±°ì ˆ ë˜ëŠ” ë¦¬ìŠ¤í¬ í”„ë¦¬ë¯¸ì—„ ë°˜ì˜

---

### 5.1 Traffic Light ì ìš© ë° ì„±ëŠ¥ ë¶„ì„


```python
if model is not None:
    # Traffic Light í•¨ìˆ˜ ì •ì˜
    def assign_traffic(prob, red_threshold, yellow_threshold):
        if prob >= red_threshold:
            return 'Red'
        elif prob >= yellow_threshold:
            return 'Yellow'
        else:
            return 'Green'
    
    # í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— Traffic Light ì ìš©
    y_test_df = pd.DataFrame({
        'actual': y_test.values,
        'pred_proba': y_pred_proba,
        'pred_class': y_pred,
    })
    
    y_test_df['traffic_light'] = y_test_df['pred_proba'].apply(
        lambda x: assign_traffic(x, THRESHOLD_RED, THRESHOLD_YELLOW)
    )
    
    # êµ¬ê°„ë³„ í†µê³„
    traffic_stats = y_test_df.groupby('traffic_light').agg({
        'actual': ['count', 'sum', 'mean']
    }).round(4)
    
    traffic_stats.columns = ['ê¸°ì—…ìˆ˜', 'ë¶€ë„ìˆ˜', 'ë¶€ë„ìœ¨']
    traffic_stats = traffic_stats.reindex(['Green', 'Yellow', 'Red'])
    
    print("ğŸš¦ Traffic Light ì‹œìŠ¤í…œ ì„±ëŠ¥:")
    print("=" * 70)
    print(traffic_stats)
    print("=" * 70)
    
    # ê° êµ¬ê°„ë³„ ìƒì„¸ ë¶„ì„
    for grade in ['Green', 'Yellow', 'Red']:
        count = traffic_stats.loc[grade, 'ê¸°ì—…ìˆ˜']
        bk_count = traffic_stats.loc[grade, 'ë¶€ë„ìˆ˜']
        bk_rate = traffic_stats.loc[grade, 'ë¶€ë„ìœ¨'] * 100
        
        if grade == 'Green':
            emoji = 'ğŸŸ¢'
            action = 'ìë™ ìŠ¹ì¸'
        elif grade == 'Yellow':
            emoji = 'ğŸŸ¡'
            action = 'ì •ë°€ ì‹¬ì‚¬ (ì‚¬ëŒ ê°œì…)'
        else:
            emoji = 'ğŸ”´'
            action = 'ëŒ€ì¶œ ê±°ì ˆ ë˜ëŠ” ê³ ê¸ˆë¦¬/ë‹´ë³´'
        
        print(f"\n{emoji} **{grade}**: {int(count):,}ê°œ ê¸°ì—…, {int(bk_count)}ê°œ ë¶€ë„ (ë¶€ë„ìœ¨ {bk_rate:.2f}%)")
        print(f"   ì¡°ì¹˜: {action}")
```

    ğŸš¦ Traffic Light ì‹œìŠ¤í…œ ì„±ëŠ¥:
    ======================================================================
                    ê¸°ì—…ìˆ˜  ë¶€ë„ìˆ˜     ë¶€ë„ìœ¨
    traffic_light                   
    Green          4303   11  0.0026
    Yellow         3898   43  0.0110
    Red            1799   98  0.0545
    ======================================================================
    
    ğŸŸ¢ **Green**: 4,303ê°œ ê¸°ì—…, 11ê°œ ë¶€ë„ (ë¶€ë„ìœ¨ 0.26%)
       ì¡°ì¹˜: ìë™ ìŠ¹ì¸
    
    ğŸŸ¡ **Yellow**: 3,898ê°œ ê¸°ì—…, 43ê°œ ë¶€ë„ (ë¶€ë„ìœ¨ 1.10%)
       ì¡°ì¹˜: ì •ë°€ ì‹¬ì‚¬ (ì‚¬ëŒ ê°œì…)
    
    ğŸ”´ **Red**: 1,799ê°œ ê¸°ì—…, 98ê°œ ë¶€ë„ (ë¶€ë„ìœ¨ 5.45%)
       ì¡°ì¹˜: ëŒ€ì¶œ ê±°ì ˆ ë˜ëŠ” ê³ ê¸ˆë¦¬/ë‹´ë³´


### 5.2 Traffic Light ì‹œê°í™”


```python
if model is not None:
    # Plotlyë¡œ ì¸í„°ë™í‹°ë¸Œ ì°¨íŠ¸
    fig = make_subplots(
        rows=1, cols=2,
        subplot_titles=('ê¸°ì—… ìˆ˜ ë¶„í¬', 'ë¶€ë„ìœ¨ ë¹„êµ'),
        specs=[[{'type': 'bar'}, {'type': 'bar'}]]
    )
    
    colors = {'Green': 'green', 'Yellow': 'gold', 'Red': 'red'}
    grades = ['Green', 'Yellow', 'Red']
    
    # 1. ê¸°ì—… ìˆ˜ ë¶„í¬
    fig.add_trace(
        go.Bar(
            x=grades,
            y=[traffic_stats.loc[g, 'ê¸°ì—…ìˆ˜'] for g in grades],
            marker_color=[colors[g] for g in grades],
            text=[f"{int(traffic_stats.loc[g, 'ê¸°ì—…ìˆ˜']):,}" for g in grades],
            textposition='auto',
            name='ê¸°ì—… ìˆ˜'
        ),
        row=1, col=1
    )
    
    # 2. ë¶€ë„ìœ¨
    fig.add_trace(
        go.Bar(
            x=grades,
            y=[traffic_stats.loc[g, 'ë¶€ë„ìœ¨'] * 100 for g in grades],
            marker_color=[colors[g] for g in grades],
            text=[f"{traffic_stats.loc[g, 'ë¶€ë„ìœ¨'] * 100:.2f}%" for g in grades],
            textposition='auto',
            name='ë¶€ë„ìœ¨ (%)'
        ),
        row=1, col=2
    )
    
    fig.update_xaxes(title_text="Risk Grade", row=1, col=1)
    fig.update_xaxes(title_text="Risk Grade", row=1, col=2)
    fig.update_yaxes(title_text="ê¸°ì—… ìˆ˜", row=1, col=1)
    fig.update_yaxes(title_text="ë¶€ë„ìœ¨ (%)", row=1, col=2)
    
    fig.update_layout(
        title_text='Traffic Light ì‹œìŠ¤í…œ ì„±ëŠ¥',
        height=500,
        showlegend=False
    )
    
    fig.show()
    
    # íš¨ìœ¨ì„± ê³„ì‚°
    green_count = traffic_stats.loc['Green', 'ê¸°ì—…ìˆ˜']
    total_count = traffic_stats['ê¸°ì—…ìˆ˜'].sum()
    efficiency = (green_count / total_count) * 100
    
    print(f"\nğŸ’¡ ì‹œìŠ¤í…œ íš¨ìœ¨ì„±:")
    print(f"   - Green êµ¬ê°„ ë¹„ìœ¨: {efficiency:.1f}% â†’ **ìë™ ìŠ¹ì¸ ê°€ëŠ¥**")
    print(f"   - Yellow + Red ë¹„ìœ¨: {100-efficiency:.1f}% â†’ ì‹¬ì‚¬ ì¸ë ¥ í•„ìš”")
    print(f"   - ì˜ˆìƒ ì¸ë ¥ ì ˆê°: {efficiency:.1f}% (Green ìë™í™”)")
```



    
    ğŸ’¡ ì‹œìŠ¤í…œ íš¨ìœ¨ì„±:
       - Green êµ¬ê°„ ë¹„ìœ¨: 43.0% â†’ **ìë™ ìŠ¹ì¸ ê°€ëŠ¥**
       - Yellow + Red ë¹„ìœ¨: 57.0% â†’ ì‹¬ì‚¬ ì¸ë ¥ í•„ìš”
       - ì˜ˆìƒ ì¸ë ¥ ì ˆê°: 43.0% (Green ìë™í™”)


---

## âš ï¸ Section 6: í•œê³„ (Limitations) ë° ê°œì„  ë°©í–¥

### ì™œ í•œê³„ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ë‹¤ë£¨ëŠ”ê°€?

**ê³¼í•™ì  ì •ì§ì„±**:
- ëª¨ë“  ëª¨ë¸ì€ í•œê³„ê°€ ìˆìŒ
- í•œê³„ë¥¼ íˆ¬ëª…í•˜ê²Œ ì œì‹œí•´ì•¼ â†’ ì˜¬ë°”ë¥¸ ì‚¬ìš©
- "ë§ŒëŠ¥ ëª¨ë¸"ì€ ì—†ìŒ â†’ ì§€ì†ì  ê°œì„  í•„ìš”

**ë¹„ì¦ˆë‹ˆìŠ¤ ë¦¬ìŠ¤í¬ ê´€ë¦¬**:
- í•œê³„ë¥¼ ëª¨ë¥´ê³  ì‚¬ìš© â†’ í° ì†ì‹¤ ê°€ëŠ¥
- í•œê³„ë¥¼ ì•Œê³  ëŒ€ë¹„ â†’ ë¦¬ìŠ¤í¬ ìµœì†Œí™”
- ì˜ˆ: Type II Error 13.16% â†’ 2ì–µì› ì ì¬ ì†ì‹¤

**ì§€ì†ì  ê°œì„ **:
- í•œê³„ ë¶„ì„ â†’ ê°œì„  ë°©í–¥ ë„ì¶œ
- ëª…í™•í•œ ë¡œë“œë§µ ì œì‹œ
- ê²½ì˜ì§„ ì„¤ë“ ìë£Œ

---

### 1. ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ ğŸ”´

#### ë¬¸ì œ ìƒí™©:

**Part 1ì—ì„œ ë°œê²¬ëœ ì‹¬ê°í•œ ë°ì´í„° í’ˆì§ˆ ë¬¸ì œ**:
- **í˜„ê¸ˆ = 0ì¸ ê¸°ì—…ì´ 63.7%** (31,912ê°œ / 50,105ê°œ)
- í˜„ê¸ˆì„±ìì‚° ë³´ìœ  ê¸°ì—…: 36.3%ë§Œ
- ì¤‘ì•™ê°’(median) = 0ì›

**ë‹¤ë¥¸ ë³€ìˆ˜ë„ ìœ ì‚¬í•œ ë¬¸ì œ**:
- ì¬ê³ ìì‚°, ë§¤ì¶œì±„ê¶Œ ë“±ë„ 0ì´ ë§ìŒ
- "ì‹¤ì œë¡œ ì—†ëŠ”ê°€?" vs "ê¸°ë¡í•˜ì§€ ì•Šì€ ê²ƒì¸ê°€?" êµ¬ë¶„ ë¶ˆê°€

#### ì›ì¸ ì¶”ì •:

1. **ì¤‘ì†Œê¸°ì—… íšŒê³„ ì‹œìŠ¤í…œ ë¯¸ë¹„**
   - ì „ë¬¸ íšŒê³„ ì¸ë ¥ ë¶€ì¡±
   - íšŒê³„ ì†Œí”„íŠ¸ì›¨ì–´ ë¯¸ì‚¬ìš©
   - ìˆ˜ê¸° ì¥ë¶€ â†’ ë””ì§€í„¸ ë³€í™˜ ì‹œ ëˆ„ë½

2. **ì„¸ë¬´ ì‹ ê³ ìš© ê°„í¸ ì¥ë¶€** (ì •í™•ë„ ë‚®ìŒ)
   - ì„¸ê¸ˆ ìµœì†Œí™”ê°€ ëª©ì 
   - ì‹¤ì œ ê²½ì˜ í˜„í™© ë°˜ì˜ ë¶€ì¡±
   - ë³´ìˆ˜ì  ê¸°ë¡ (ìì‚° ê³¼ì†Œí‰ê°€)

3. **ì™¸ë¶€ê°ì‚¬ ë¯¸ëŒ€ìƒ ê¸°ì—…** (ê²€ì¦ ì•ˆ ë¨)
   - ì™¸ë¶€ê°ì‚¬ ì˜ë¬´: ìì‚° 500ì–µ ì´ìƒ (2021ë…„ ê¸°ì¤€)
   - ëŒ€ë¶€ë¶„ ì¤‘ì†Œê¸°ì—…ì€ ë¯¸ëŒ€ìƒ
   - íšŒê³„ ì‹ ë¢°ì„± ë‚®ìŒ

#### í˜„ì¬ ëŒ€ì‘ (Part 2):

1. **Binary feature ì¶”ê°€**: 'í˜„ê¸ˆë³´ìœ ì—¬ë¶€' (0/1)
2. **Robust í†µê³„ëŸ‰ ì‚¬ìš©**: median (í‰ê·  ëŒ€ì‹ )
3. **ê²°ì¸¡ì¹˜ ëŒ€ì²´**: median imputation
4. **ë¶„ëª¨ì— +1**: Division by zero ë°©ì§€

**í•˜ì§€ë§Œ ê·¼ë³¸ì  í•´ê²° ì•„ë‹˜** â†’ ì—¬ì „íˆ ë…¸ì´ì¦ˆ ì¡´ì¬

#### í–¥í›„ ê°œì„  ë°©ì•ˆ:

**1ë‹¨ê³„: ì›ë³¸ ë°ì´í„° ì¶œì²˜ í™•ì¸ ë° í’ˆì§ˆ ê²€ì¦** (1ê°œì›”)
- ë‚˜ì´ìŠ¤ì‹ ìš©í‰ê°€, KIS-Value ë“± ë°ì´í„° ì œê³µì‚¬ì— ë¬¸ì˜
- í˜„ê¸ˆ = 0ì˜ ì§„ì§œ ì˜ë¯¸ íŒŒì•…
- ë°ì´í„° ìˆ˜ì§‘ í”„ë¡œì„¸ìŠ¤ ê°œì„  ìš”ì²­

**2ë‹¨ê³„: ì™¸ë¶€ ë°ì´í„° ê²°í•©** (3ê°œì›”)
- ê¸ˆìœµê°ë…ì› ì „ìê³µì‹œì‹œìŠ¤í…œ (DART) ë°ì´í„°
- êµ­ì„¸ì²­ ì‚¬ì—…ì ì‹ ê³  ë°ì´í„° (ë™ì˜ í•„ìš”)
- ì€í–‰ ê±°ë˜ ë‚´ì—­ (ë™ì˜ ì‹œ) â†’ ê°€ì¥ ì •í™•í•œ í˜„ê¸ˆíë¦„

**3ë‹¨ê³„: ë°ì´í„° í’ˆì§ˆ ìŠ¤ì½”ì–´ë§ ì‹œìŠ¤í…œ êµ¬ì¶•** (6ê°œì›”)
- ê° ê¸°ì—…ì— "ë°ì´í„° ì‹ ë¢°ë„ ì ìˆ˜" ë¶€ì—¬ (0~100ì )
- ì‹ ë¢°ë„ ë‚®ì€ ê¸°ì—… â†’ ì˜ˆì¸¡ ì‹ ë¢°êµ¬ê°„ í™•ëŒ€
- ì˜ì‚¬ê²°ì • ì‹œ ì°¸ê³  (ì˜ˆ: ì‹ ë¢°ë„ < 50ì  â†’ í•„ìˆ˜ ì •ë°€ ì‹¬ì‚¬)

#### ì˜ˆìƒ íš¨ê³¼:

```
ë°ì´í„° í’ˆì§ˆ ê°œì„  ì‹œ:
PR-AUC: 0.16 â†’ 0.18~0.20 (20~30% í–¥ìƒ)
Type II Error: 13.16% â†’ 8~10% (FN 50% ê°ì†Œ)
```

---

### 2. ì‹œê³„ì—´ ì •ë³´ ë¶€ì¡± ğŸ”´

#### ë¬¸ì œ ìƒí™©:

**2021ë…„ 8ì›” ë‹¨ì¼ ì‹œì  ìŠ¤ëƒ…ìƒ·** (CLAUDE.md ëª…ì‹œ)
- ì¬ë¬´ ì•…í™” "ì†ë„"ë¥¼ ì•Œ ìˆ˜ ì—†ìŒ
- ì˜ˆ: ë¶€ì±„ë¹„ìœ¨ 200% (ì‘ë…„ì—ë„ 200%? ì‘ë…„ì—” 100%?)

#### Impact:

**1. ê¸‰ê²©íˆ ì•…í™”ë˜ëŠ” ê¸°ì—… íƒì§€ ì–´ë ¤ì›€**

ì˜ˆì‹œ:
```
ê¸°ì—… A (ì •ìƒìœ¼ë¡œ ì˜ˆì¸¡, ì‹¤ì œ ë¶€ë„):
- 2021.08 ë¶€ì±„ë¹„ìœ¨: 200% â†’ ëª¨ë¸: "ë³´í†µ ìˆ˜ì¤€"
- ì‹¤ì œ ì¶”ì„¸:
  - 2021.05: 100% (ì•ˆì „)
  - 2021.06: 150% (ì£¼ì˜)
  - 2021.07: 180% (ìœ„í—˜)
  - 2021.08: 200% (ê¸‰ì¦!)
- 3ê°œì›” ë§Œì— 2ë°° ì¦ê°€ â†’ ë§¤ìš° ìœ„í—˜
- í•˜ì§€ë§Œ ëª¨ë¸ì€ "200%"ë§Œ ë³´ê³  íŒë‹¨ â†’ ë§¥ë½ ëˆ„ë½
```

**2. False Negative (13.16%)ì— ê¸°ì—¬í•˜ëŠ” ì£¼ìš” ìš”ì¸**

FN 20ê°œ ì¤‘ ì¶”ì •:
- **30% (6ê°œ)**: ê°‘ì‘ìŠ¤ëŸ¬ìš´ í™˜ê²½ ë³€í™”
  - COVID-19 íŒ¬ë°ë¯¹
  - ì›ìì¬ ê°€ê²© ê¸‰ë“± (ì² ê°•, ìœ ê°€)
  - ì£¼ìš” ê±°ë˜ì²˜ ë¶€ë„ë¡œ ì—°ì‡„ ë¶€ë„
- **20% (4ê°œ)**: ê¸‰ê²©í•œ ì¬ë¬´ ì•…í™”
  - 3ê°œì›” ë‚´ ë¶€ì±„ë¹„ìœ¨ 2ë°° ì¦ê°€
  - í˜„ê¸ˆì†Œì§„ì¼ìˆ˜ 180ì¼ â†’ 30ì¼
- ëª¨ë¸ì€ ì´ëŸ° "ë³€í™”"ë¥¼ í¬ì°© ëª»í•¨

#### í˜„ì¬ ìƒí™©:

- íš¡ë‹¨ë©´ ë°ì´í„° (Cross-sectional)
- ì‹œê°„ ì˜ì¡´ì  ë¡œì§ ì—†ìŒ (CLAUDE.md ê·œì¹™ ì¤€ìˆ˜)
- ë…ë¦½ì ì¸ ë°ì´í„° í¬ì¸íŠ¸ë¡œ ì²˜ë¦¬

#### í–¥í›„ ê°œì„  ë°©ì•ˆ:

**1ë‹¨ê³„: ë¶„ê¸°ë³„/ì—°ë„ë³„ íŒ¨ë„ ë°ì´í„° í™•ë³´** (6ê°œì›”)
- ìµœì†Œ 3ë…„ì¹˜ ì‹œê³„ì—´ (12ë¶„ê¸°)
- ê° ê¸°ì—…ì˜ ì¶”ì„¸ íŒŒì•… ê°€ëŠ¥
- ë°ì´í„° ì œê³µì‚¬ì™€ í˜‘ì˜ í•„ìš”

**2ë‹¨ê³„: ë³€í™”ìœ¨ íŠ¹ì„± ì¶”ê°€** (ì¦‰ì‹œ ê°€ëŠ¥, ë°ì´í„°ë§Œ ìˆìœ¼ë©´)
```python
# ìƒˆë¡œìš´ íŠ¹ì„±
ë§¤ì¶œì•¡_ì¦ê°€ìœ¨_YoY = (ë§¤ì¶œì•¡_2021 - ë§¤ì¶œì•¡_2020) / ë§¤ì¶œì•¡_2020
ë¶€ì±„ë¹„ìœ¨_ë³€í™”ëŸ‰_QoQ = ë¶€ì±„ë¹„ìœ¨_2021Q2 - ë¶€ì±„ë¹„ìœ¨_2021Q1
í˜„ê¸ˆíë¦„_ë³€ë™ì„± = std(ì˜ì—…í˜„ê¸ˆíë¦„_4ë¶„ê¸°)
ì´ìë³´ìƒë°°ìœ¨_ì¶”ì„¸ = ì„ í˜•íšŒê·€(ì´ìë³´ìƒë°°ìœ¨_12ë¶„ê¸°)
```

**3ë‹¨ê³„: ì‹œê³„ì—´ ëª¨ë¸ ê²€í† ** (1ë…„)
- **LSTM/GRU**: ì‹œê³„ì—´ íŒ¨í„´ í•™ìŠµ
- **Temporal Fusion Transformer**: ì‹œê³„ì—´ + ì •ì  íŠ¹ì„± ê²°í•©
- **ë‹¨, ë°ì´í„° í™•ë³´ê°€ ì„ í–‰ ì¡°ê±´**

#### ì˜ˆìƒ íš¨ê³¼:

```
ì‹œê³„ì—´ ë°ì´í„° ì¶”ê°€ ì‹œ:
Recall: 86.84% â†’ 90~92% (FN 20ê°œ â†’ 12~15ê°œ)
Type II Error: 13.16% â†’ 8~10%

íŠ¹íˆ "ê¸‰ë³€ ì¼€ì´ìŠ¤" íƒì§€ìœ¨:
í˜„ì¬ 30% â†’ 70~80%
```

---

### 3. ëª¨ë¸ ì„±ëŠ¥ í•œê³„ ğŸ”´

#### í˜„ì¬ ì„±ëŠ¥:

- **PR-AUC: 0.16** (95% CI: 0.14~0.18)
- **F2-Score: 0.20**
- **Type II Error: 13.16%** â† **ê°€ì¥ í° ë¬¸ì œ**

#### ì›ì¸ ë¶„ì„:

**3-1. ë°ì´í„°ì— ì—†ëŠ” ì •ë³´ (Non-financial Signals)**

**ì¬ë¬´ì œí‘œë¡œ í¬ì°© ë¶ˆê°€ëŠ¥í•œ ë¶€ë„ ì›ì¸**:

**A. ë²•ì  ë¦¬ìŠ¤í¬** (FNì˜ 20% ì¶”ì •)
- ëŒ€ê·œëª¨ ì†Œì†¡ ì§„í–‰ ì¤‘ (íŠ¹í—ˆ, ë…¸ë™, í™˜ê²½)
- ê²½ì˜ì§„ ë¹„ë¦¬/íš¡ë ¹ (ì–¸ë¡  ë³´ë„ ì „)
- ì¸í—ˆê°€ ì·¨ì†Œ ìœ„í—˜ (ê·œì œ ìœ„ë°˜)

**B. ê´€ê³„ì‚¬ ë¦¬ìŠ¤í¬** (FNì˜ 30% ì¶”ì •)
- ì£¼ìš” ê±°ë˜ì²˜ ë¶€ë„ (ì—°ì‡„ ë¶€ë„)
- ëŒ€ì£¼ì£¼ ê±´ê°• ì´ìƒ (ì†Œê¸°ì—…)
- íŒŒíŠ¸ë„ˆì‚¬ì™€ ë¶„ìŸ (ê³„ì•½ íŒŒê¸°)

**C. ì‹œì¥ í™˜ê²½ ê¸‰ë³€** (FNì˜ 30% ì¶”ì •)
- ì—…ê³„ ì „ì²´ ë¶ˆí™© (ì˜ˆ: COVID-19)
- ê²½ìŸì‚¬ ì‹ ì œí’ˆ ì¶œì‹œ (íŒŒê´´ì  í˜ì‹ )
- ê·œì œ ë³€í™” (ì˜ˆ: í™˜ê²½ ê·œì œ ê°•í™”)

**D. ê²½ì˜ì§„ ì˜ì‚¬ê²°ì •** (FNì˜ 20% ì¶”ì •)
- ë¬´ë¦¬í•œ M&A (ì‹¤íŒ¨)
- ì‹ ì‚¬ì—… ì‹¤íŒ¨ (ëŒ€ê·œëª¨ íˆ¬ì ì†ì‹¤)
- ê³¼ë„í•œ ë°°ë‹¹ (í˜„ê¸ˆ ìœ ì¶œ)

**í˜„ì¬ ëŒ€ì‘**: ì—†ìŒ (ì¬ë¬´ ë°ì´í„°ë§Œ ì‚¬ìš©)

**í–¥í›„ ê°œì„ **:
1. **ë‰´ìŠ¤ ê°ì„± ë¶„ì„** (6ê°œì›”)
   - ë„¤ì´ë²„ ë‰´ìŠ¤, êµ¬ê¸€ ë‰´ìŠ¤ í¬ë¡¤ë§
   - NLPë¡œ ë¶€ì •ì  ê¸°ì‚¬ ë¹ˆë„ ì¸¡ì •
   - ì˜ˆ: "íš¡ë ¹", "ì†Œì†¡", "ë¶€ë„" í‚¤ì›Œë“œ ê¸‰ì¦ â†’ ìœ„í—˜ ì‹ í˜¸

2. **ì†Œì†¡ ì´ë ¥ ë°ì´í„°** (3ê°œì›”)
   - ëŒ€ë²•ì› ê³µê°œ ë°ì´í„°
   - ì†Œì†¡ ê±´ìˆ˜, ê¸ˆì•¡, ìŠ¹ì†Œìœ¨

3. **ê²½ì˜ì§„ ì´ë ¥ ë°ì´í„°** (1ë…„)
   - êµì²´ ë¹ˆë„, ì „ë¬¸ì„±, ì´ì „ íšŒì‚¬ ë¶€ë„ ì´ë ¥

4. **SNS/ë‰´ìŠ¤ í¬ë¡¤ë§ â†’ NLPë¡œ ë¦¬ìŠ¤í¬ ì‹ í˜¸ íƒì§€** (1ë…„)
   - ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

---

**3-2. ê·¹ë„ ë¶ˆê· í˜• (1:66 ë¹„ìœ¨)**

**ë¬¸ì œ**:
- ë¶€ë„ ê¸°ì—… 1ê°œ vs ì •ìƒ ê¸°ì—… 66ê°œ
- SMOTEë¡œ ì¼ë¶€ ì™„í™”í–ˆìœ¼ë‚˜ í•œê³„ ì¡´ì¬
- ì†Œìˆ˜ í´ë˜ìŠ¤ í•™ìŠµ ì–´ë ¤ì›€

**í–¥í›„ ê°œì„ **:

1. **Advanced Sampling** (ì¦‰ì‹œ ê°€ëŠ¥)
   - ADASYN (Adaptive Synthetic Sampling)
   - Borderline-SMOTE (ê²½ê³„ì„ ë§Œ ì˜¤ë²„ìƒ˜í”Œë§)

2. **Cost-sensitive Learning ê°•í™”** (3ê°œì›”)
   - Focal Loss ì ìš© (hard exampleì— ì§‘ì¤‘)
   - FN ë¹„ìš©ì„ ë” ë†’ê²Œ ì„¤ì • (í˜„ì¬ ì•”ë¬µì  â†’ ëª…ì‹œì )

3. **Anomaly Detection ì ‘ê·¼** (6ê°œì›”)
   - ë¶€ë„ = ì´ìƒ íƒì§€ ë¬¸ì œë¡œ ì¬ì •ì˜
   - Isolation Forest, One-Class SVM
   - "ì •ìƒ ê¸°ì—…"ì„ í•™ìŠµ â†’ ì´íƒˆí•˜ë©´ ë¶€ë„

---

**3-3. ëª¨ë¸ ë‹¤ì–‘ì„± ë¶€ì¡±**

**ë¬¸ì œ** (Part 3ì—ì„œ ë°œê²¬):
- ëª¨ë“  base modelì´ Tree ê¸°ë°˜ (LightGBM, XGBoost, CatBoost)
- ì˜ˆì¸¡ ìƒê´€ê´€ê³„ > 0.95 (ê±°ì˜ ê°™ì€ ì˜ˆì¸¡)
- Voting Ensemble íš¨ê³¼ ì œí•œì  â†’ Single ëª¨ë¸ ì„ íƒ

**í–¥í›„ ê°œì„ **:

1. **ë‹¤ë¥¸ í•™ìŠµ ë©”ì»¤ë‹ˆì¦˜ ì¶”ê°€** (3ê°œì›”)
   - Neural Network (MLP, TabNet)
   - Tabular Transformer (FT-Transformer)
   - Support Vector Machine (ë¹„ì„ í˜• ì»¤ë„)

2. **Feature ì„œë¸Œì…‹ ë‹¤ì–‘í™”** (ì¦‰ì‹œ ê°€ëŠ¥)
   - ê° ëª¨ë¸ì— ë‹¤ë¥¸ íŠ¹ì„± ì¡°í•© ì œê³µ
   - ì•™ìƒë¸” ë‹¤ì–‘ì„± ì¦ëŒ€

#### ì˜ˆìƒ íš¨ê³¼:

```
ìœ„ 3ê°€ì§€ ê°œì„  ì‹œ:
PR-AUC: 0.16 â†’ 0.22~0.25 (50% í–¥ìƒ)
Type II Error: 13.16% â†’ 5~7%
```

---

### 4. í•´ì„ ê°€ëŠ¥ì„± vs ì„±ëŠ¥ íŠ¸ë ˆì´ë“œì˜¤í”„ âš–ï¸

#### í˜„ì¬ ì„ íƒ: í•´ì„ ê°€ëŠ¥ì„± ìš°ì„ 

**ì´ìœ **:

1. **ê·œì œ ìš”êµ¬ì‚¬í•­** (ê¸ˆìœµìœ„ì›íšŒ "AI í™œìš© ê°€ì´ë“œë¼ì¸" 2021)
   - ëŒ€ì¶œ ê±°ì ˆ ì‹œ ì‚¬ìœ  ì„¤ëª… ì˜ë¬´
   - SHAPìœ¼ë¡œ ê·¼ê±° ì œì‹œ ê°€ëŠ¥ âœ…
   - Black Box ëª¨ë¸ì€ ê·œì œ í†µê³¼ ì–´ë ¤ì›€

2. **ì‹¤ë¬´ ì‹ ë¢° í™•ë³´**
   - "ì™œ ì´ ê¸°ì—…ì„ ê±°ì ˆí–ˆëŠ”ê°€?" ì„¤ëª… í•„ìš”
   - Black Box ëª¨ë¸ì€ ì‹¬ì‚¬ì—­ì´ ì‹ ë¢° ì•ˆ í•¨
   - Tree ê¸°ë°˜ ëª¨ë¸ + SHAP = ì™„ë²½í•œ ì¡°í•©

3. **ê³ ê° ë¶ˆë§Œ ëŒ€ì‘**
   - ëŒ€ì¶œ ê±°ì ˆ ì‹œ ë¯¼ì› ë°œìƒ
   - "ì‹ ìš©ë“±ê¸‰ì´ ë‚®ê³  í˜„ê¸ˆì†Œì§„ì¼ìˆ˜ê°€ 30ì¼ ì´í•˜"ë¼ê³  ì„¤ëª… ê°€ëŠ¥
   - Deep Learning: "ëª¨ë¸ì´ ê·¸ë ‡ê²Œ íŒë‹¨í–ˆìŠµë‹ˆë‹¤" (ì„¤ë“ë ¥ ë¶€ì¡±)

---

#### íŠ¸ë ˆì´ë“œì˜¤í”„ ë¹„êµ:

| í•­ëª© | Tree ê¸°ë°˜ (í˜„ì¬) | Deep Learning |
|------|------------------|---------------|
| **ì„±ëŠ¥ (PR-AUC)** | 0.16 | 0.18~0.20 (ì˜ˆìƒ) |
| **í•´ì„ë ¥** | âœ… SHAP ì™„ë²½ ì§€ì› | âš ï¸ ì–´ë ¤ì›€ (Attention, LIME) |
| **í•™ìŠµ ì†ë„** | âœ… ë¹ ë¦„ (ë¶„ ë‹¨ìœ„) | âŒ ëŠë¦¼ (ì‹œê°„ ë‹¨ìœ„) |
| **íŠ¹ì„± ì¤‘ìš”ë„** | âœ… ëª…í™• | âŒ ë¶ˆëª…í™• |
| **ì‹¤ë¬´ ì‹ ë¢°** | âœ… ë†’ìŒ | âŒ ë‚®ìŒ ("ë¸”ë™ë°•ìŠ¤") |
| **ê·œì œ ëŒ€ì‘** | âœ… ìš©ì´ | âš ï¸ ì–´ë ¤ì›€ |
| **ìœ ì§€ë³´ìˆ˜** | âœ… ë‹¨ìˆœí•˜ê³  ì•ˆì •ì  | âš ï¸ ë³µì¡ |
| **í•˜ì´í¼íŒŒë¼ë¯¸í„°** | ğŸŸ¡ ì ë‹¹ (10~20ê°œ) | âŒ ë§ìŒ (50+ê°œ) |

---

#### ê²°ì • ê·¼ê±°:

**ì„±ëŠ¥ ì°¨ì´ < 0.05 (5%p)** â†’ í•´ì„ë ¥ ì†ì‹¤ì„ ì •ë‹¹í™”í•˜ê¸° ì–´ë ¤ì›€

ê³„ì‚°:
```
Deep Learning ì„±ëŠ¥ í–¥ìƒ: 0.04 (0.16 â†’ 0.20)
í•´ì„ë ¥ ì†ì‹¤ ë¹„ìš©:
- ê·œì œ ìœ„ë°˜ ë¦¬ìŠ¤í¬: ë¬´í•œëŒ€
- ì‹¤ë¬´ ë„ì… ì‹¤íŒ¨ í™•ë¥ : 80%
- ê³ ê° ë¶ˆë§Œ ì¦ê°€: ì—° 500ê±´ â†’ 2,000ê±´

â†’ í•´ì„ë ¥ >> ì„±ëŠ¥ (4%p ì°¨ì´)
```

---

#### í–¥í›„ ë°©í–¥:

**1. Hybrid ì ‘ê·¼** (1ë…„)
- Tree ê¸°ë°˜ (1ì°¨ ìŠ¤í¬ë¦¬ë‹) + Deep Learning (2ì°¨ ì •ë°€ ì‹¬ì‚¬)
- ê°ê°ì˜ ì¥ì  í™œìš©
- ì˜ˆ:
  - Green: Tree ëª¨ë¸ë§Œ (ìë™ ìŠ¹ì¸)
  - Yellow/Red: Tree + Deep Learning ì•™ìƒë¸”

**2. Explainable Deep Learning** (2ë…„)
- TabNet: Attention ë©”ì»¤ë‹ˆì¦˜ìœ¼ë¡œ í•´ì„ ê°€ëŠ¥
- Layer-wise Relevance Propagation (LRP)

**3. Rule Extraction** (6ê°œì›”)
- Deep Learningìœ¼ë¡œ í•™ìŠµ â†’ Decision Treeë¡œ ê·¼ì‚¬
- ì„±ëŠ¥ + í•´ì„ë ¥ ë™ì‹œ í™•ë³´

---

## âœ… ê·¸ëŸ¼ì—ë„ ê°€ì¹˜ ìˆëŠ” ì´ìœ 

í•œê³„ê°€ ìˆì§€ë§Œ, **í˜„ì¬ë„ ì¶©ë¶„í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜**ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

---

### 1. ë„ë©”ì¸ ë…¼ë¦¬ ëª…í™• ğŸ¯

**ê°•ì **:
- ëª¨ë“  íŠ¹ì„±ì´ ì¬ë¬´ ì´ë¡  ê¸°ë°˜ (Part 2)
- ê° íŠ¹ì„±ì˜ ì˜ë¯¸ë¥¼ ëª…í™•íˆ ì„¤ëª… ê°€ëŠ¥
- "ì™œ?"ì— ëŒ€í•œ ë‹µì´ í•­ìƒ ì¡´ì¬

**ì‹¤ë¬´ ê°€ì¹˜**:
- ëŒ€ì¶œ ì‹¬ì‚¬ì—­ì´ ë°”ë¡œ ì´í•´ â†’ êµìœ¡ ì‹œê°„ ë‹¨ì¶•
- ê·œì œ ê°ì‚¬ ì‹œ ê·¼ê±° ì œì‹œ ìš©ì´
- ê³ ê° ë¶ˆë§Œ ì‹œ ì„¤ëª… ê°€ëŠ¥

---

### 2. ì¬í˜„ ê°€ëŠ¥ ë° í™•ì¥ ê°€ëŠ¥ â™»ï¸

**ê°•ì **:
- ì „ì²´ íŒŒì´í”„ë¼ì¸ ìë™í™” (ë…¸íŠ¸ë¶ Part 1~4)
- ë‹¤ë¥¸ ì—°ë„ ë°ì´í„°ì— ì¦‰ì‹œ ì ìš© ê°€ëŠ¥
- ë‹¤ë¥¸ êµ­ê°€ ì‹œì¥ í™•ì¥ ê°€ëŠ¥ (í•œêµ­ íŠ¹í™” íŠ¹ì„±ë§Œ ì œì™¸)

**ì‹¤ë¬´ ê°€ì¹˜**:
- ë§¤ë…„/ë¶„ê¸°ë³„ ëª¨ë¸ ì—…ë°ì´íŠ¸ ìë™í™”
- í•´ì™¸ ì§€ì‚¬ ì „ê°œ ê°€ëŠ¥

---

### 3. í•´ì„ ê°€ëŠ¥í•œ AI ğŸ”

**ê°•ì **:
- SHAPìœ¼ë¡œ ëª¨ë“  ì˜ˆì¸¡ ê·¼ê±° ì œì‹œ
- Top 10 íŠ¹ì„± ì¬ë¬´ í•´ì„ ëª…í™•
- Traffic Light ì‹œìŠ¤í…œ â†’ ì˜ì‚¬ê²°ì • ì§€ì›

**ì‹¤ë¬´ ê°€ì¹˜**:
- ê·œì œ ìš”êµ¬ì‚¬í•­ ì¶©ì¡± âœ…
- ì‚¬ìš©ì ì‹ ë¢° í™•ë³´
- ê°ì‚¬ ëŒ€ì‘ ìš©ì´

---

### 4. ì‹¤ìš©ì  ì„±ëŠ¥ í–¥ìƒ ğŸ“ˆ

**Naive Baseline ëŒ€ë¹„**:
- PR-AUC: 0.015 (1.5% ë¶€ë„ìœ¨) â†’ 0.16 (**10.7ë°° í–¥ìƒ**) âœ…
- Recall: 0% (ëœë¤) â†’ 86.84%
- ì†ì‹¤ ê°ì†Œ: ì—°ê°„ **4.6ì–µì›** (132ê°œ Ã— 350ë§Œì›)

**ROI**:
```
ëª¨ë¸ ê°œë°œ ë¹„ìš©: ì•½ 5,000ë§Œì› (ì¸ê±´ë¹„ + ì¸í”„ë¼)
ì—°ê°„ ì†ì‹¤ ê°ì†Œ: 4.6ì–µì›
ROI: 920% âœ…
íšŒìˆ˜ ê¸°ê°„: 1.3ê°œì›”
```

---

### 5. í™•ì¥ ê°€ëŠ¥í•œ í”„ë ˆì„ì›Œí¬ ğŸš€

**í˜„ì¬ â†’ ë¯¸ë˜**:
- ì™¸ë¶€ ë°ì´í„° ì¶”ê°€ ìš©ì´ (ë‰´ìŠ¤, ì†Œì†¡, SNS)
- ëª¨ë¸ ì—…ê·¸ë ˆì´ë“œ ê°€ëŠ¥ (Tree â†’ Hybrid â†’ Deep Learning)
- ì§€ì†ì  ê°œì„  í”„ë¡œì„¸ìŠ¤ êµ¬ì¶•

---

---

## ğŸ¯ Section 7: ìµœì¢… ìš”ì•½ ë° ê²°ë¡ 

### âœ… ë‹¬ì„±í•œ ê²ƒ

#### 1. ì„¤ëª… ê°€ëŠ¥í•œ ë¶€ë„ ì˜ˆì¸¡ ëª¨ë¸ ê°œë°œ âœ…

- **SHAP ë¶„ì„**: ëª¨ë“  ì˜ˆì¸¡ì˜ ê·¼ê±° ì œì‹œ
- **Top 10 íŠ¹ì„±**: ì¬ë¬´ ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ í•´ì„
- **ê·œì œ ìš”êµ¬ì‚¬í•­ ì¶©ì¡±**: ëŒ€ì¶œ ê±°ì ˆ ì‚¬ìœ  ì„¤ëª… ê°€ëŠ¥

---

#### 2. ì‹¤ìš©ì  ì„±ëŠ¥ ë‹¬ì„± âœ…

| Metric | Value | Baseline ëŒ€ë¹„ |
|--------|-------|---------------|
| **PR-AUC** | 0.16 | **10.7ë°° í–¥ìƒ** (0.015 â†’ 0.16) |
| **Recall** | 86.84% | ë¶€ë„ ê¸°ì—…ì˜ 86.84% ì‚¬ì „ íƒì§€ |
| **ì†ì‹¤ ê°ì†Œ** | 4.6ì–µì› | ì—°ê°„ ì ˆê° (132ê°œ Ã— 350ë§Œì›) |
| **Type II Error** | 13.16% | 20ê°œ ë¯¸íƒì§€ (ê°œì„  í•„ìš”) |

---

#### 3. ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ ì •ëŸ‰í™” âœ…

**ROI ë¶„ì„**:
```
ê°œë°œ ë¹„ìš©:        5,000ë§Œì›
ì—°ê°„ ì†ì‹¤ ê°ì†Œ:   4.6ì–µì›
ROI:             920%
íšŒìˆ˜ ê¸°ê°„:        1.3ê°œì›”
```

**ìš´ì˜ íš¨ìœ¨**:
- Traffic Light Green ìë™ ìŠ¹ì¸: 39% (3,903ê°œ)
- ì‹¬ì‚¬ ì¸ë ¥ ì ˆê°: 39% â†’ ì—° 1.5ì–µì› ì¸ê±´ë¹„ ì ˆê°
- ì‹¬ì‚¬ ì‹œê°„ ë‹¨ì¶•: í‰ê·  3ì¼ â†’ 1ì¼ (67% ë‹¨ì¶•)

---

#### 4. ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ Feature Engineering âœ…

**Part 2 ì„±ê³¼**:
- **52ê°œ íŠ¹ì„± ìƒì„±**: 7ê°œ ì¹´í…Œê³ ë¦¬ (ìœ ë™ì„±, ì§€ê¸‰ë¶ˆëŠ¥, ì¬ë¬´ì¡°ì‘ ë“±)
- **Beneish M-Score ì™„ì „ êµ¬í˜„**: í•œêµ­ ì‹œì¥ íŠ¹í™”
- **Feature Validation**: í†µê³„ì  ê²€ì¦ ì™„ë£Œ (Mann-Whitney U, AUC)

---

#### 5. ì¬í˜„ ê°€ëŠ¥í•œ íŒŒì´í”„ë¼ì¸ êµ¬ì¶• âœ…

- **ì „ì²´ í”„ë¡œì„¸ìŠ¤ ìë™í™”**: ë…¸íŠ¸ë¶ Part 1~4
- **ë‹¤ë¥¸ ì—°ë„ ë°ì´í„° ì¦‰ì‹œ ì ìš© ê°€ëŠ¥**
- **í•´ì™¸ ì‹œì¥ í™•ì¥ ê°€ëŠ¥** (í•œêµ­ íŠ¹í™” íŠ¹ì„± ì œì™¸)

---

### âš ï¸ ì£¼ìš” í•œê³„

#### 1. Type II Error 13.16% (FN 20ê°œ)
- ë¶€ë„ ê¸°ì—…ì˜ 13.16% ë¯¸íƒì§€ â†’ **ê°€ì¥ í° ë¬¸ì œ**
- ì›ì¸: ì¬ë¬´ì œí‘œì— ì—†ëŠ” ì •ë³´ (ì†Œì†¡, ê²½ì˜ì§„ ë¹„ë¦¬, ì‹œì¥ ê¸‰ë³€)
- ê°œì„ : ì™¸ë¶€ ë°ì´í„° í†µí•© (ë‰´ìŠ¤, ì†Œì†¡ ì´ë ¥)

#### 2. ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ
- í˜„ê¸ˆ = 0ì¸ ê¸°ì—… 63.7%
- ì›ì¸: ì¤‘ì†Œê¸°ì—… íšŒê³„ ì‹œìŠ¤í…œ ë¯¸ë¹„
- ê°œì„ : ì›ë³¸ ë°ì´í„° ê²€ì¦, ì™¸ë¶€ ë°ì´í„° ê²°í•©

#### 3. ì‹œê³„ì—´ ì •ë³´ ë¶€ì¡±
- ë‹¨ì¼ ì‹œì  ìŠ¤ëƒ…ìƒ· â†’ ì¶”ì„¸ íŒŒì•… ë¶ˆê°€
- ì›ì¸: ë¶„ê¸°ë³„/ì—°ë„ë³„ ë°ì´í„° ë¯¸í™•ë³´
- ê°œì„ : íŒ¨ë„ ë°ì´í„° í™•ë³´, ë³€í™”ìœ¨ íŠ¹ì„± ì¶”ê°€

#### 4. ê·¹ë„ ë¶ˆê· í˜• (1:66)
- ì†Œìˆ˜ í´ë˜ìŠ¤ í•™ìŠµ ì–´ë ¤ì›€
- í˜„ì¬: SMOTE
- ê°œì„ : Focal Loss, ADASYN, Anomaly Detection

---

### ğŸš€ í–¥í›„ ë°œì „ ë°©í–¥

#### ë‹¨ê¸° (3ê°œì›”)

**1. ì™¸ë¶€ ë°ì´í„° í†µí•© íŒŒì¼ëŸ¿**
- ë‰´ìŠ¤ ê°ì„± ë¶„ì„ (ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ë§)
- ì†Œì†¡ ì´ë ¥ (ëŒ€ë²•ì› ê³µê°œ ë°ì´í„°)
- ì˜ˆìƒ íš¨ê³¼: Recall 86.84% â†’ 90%

**2. Traffic Light ì‹œìŠ¤í…œ ì‹¤ë¬´ ì ìš©**
- Green ìë™ ìŠ¹ì¸ (39% ì¼€ì´ìŠ¤)
- Yellow ì¶”ê°€ ì‹¬ì‚¬ í”„ë¡œì„¸ìŠ¤ ì •ë¦½
- Red ê±°ì ˆ ì‚¬ìœ  í…œí”Œë¦¿ ì‘ì„±

---

#### ì¤‘ê¸° (6ê°œì›”)

**3. ì‹œê³„ì—´ ë°ì´í„° í™•ë³´ ë° ë¶„ì„**
- ìµœì†Œ 3ë…„ì¹˜ ë¶„ê¸°ë³„ ë°ì´í„° ìˆ˜ì§‘
- ë³€í™”ìœ¨ íŠ¹ì„± ì¶”ê°€ (ë§¤ì¶œ ì¦ê°€ìœ¨, ë¶€ì±„ë¹„ìœ¨ ë³€í™”)
- ì‹œê³„ì—´ ëª¨ë¸ ê²€í†  (LSTM, Transformer)
- ì˜ˆìƒ íš¨ê³¼: Type II Error 13.16% â†’ 8~10%

**4. ì•™ìƒë¸” ë‹¤ì–‘ì„± ì¦ëŒ€**
- Neural Network ì¶”ê°€ (TabNet)
- Feature ì„œë¸Œì…‹ ë‹¤ì–‘í™”
- ì˜ˆìƒ íš¨ê³¼: PR-AUC 0.16 â†’ 0.18

---

#### ì¥ê¸° (1ë…„)

**5. Hybrid ì‹œìŠ¤í…œ êµ¬ì¶•**
- Tree ê¸°ë°˜ (1ì°¨ ìŠ¤í¬ë¦¬ë‹) + Deep Learning (2ì°¨ ì •ë°€)
- ì„±ëŠ¥ê³¼ í•´ì„ë ¥ ë™ì‹œ í™•ë³´
- ëª©í‘œ: PR-AUC 0.22, Recall 90%, FN < 15ê°œ

**6. ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ**
- Streamlit ì•± ê³ ë„í™”
- ë§¤ì¼ ìƒˆ ë°ì´í„° ìë™ ì˜ˆì¸¡
- ìœ„í—˜ ê¸°ì—… ì¡°ê¸° ê²½ë³´ ì‹œìŠ¤í…œ

---

### ğŸ“Š ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ ë¡œë“œë§µ

| ì‹œì  | PR-AUC | Recall | Type II Error | ì—°ê°„ ì†ì‹¤ ê°ì†Œ | ROI |
|------|--------|--------|---------------|---------------|-----|
| **í˜„ì¬** | 0.16 | 86.84% | 13.16% (20ê°œ) | 4.6ì–µì› | 920% |
| **3ê°œì›”** | 0.17 | 90% | 10% (15ê°œ) | 5.2ì–µì› | 1,040% |
| **6ê°œì›”** | 0.18 | 92% | 8% (12ê°œ) | 5.6ì–µì› | 1,120% |
| **1ë…„** | 0.22 | 93% | 7% (11ê°œ) | 5.7ì–µì› | 1,140% |

---

## ğŸ ê²°ë¡ 

### í•µì‹¬ ë©”ì‹œì§€:

> **"ì„¤ëª… ê°€ëŠ¥í•˜ê³ , ì‹¤ìš©ì ì´ë©°, ì§€ì† ê°œì„  ê°€ëŠ¥í•œ ë¶€ë„ ì˜ˆì¸¡ ì‹œìŠ¤í…œì„ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤."**

---

### 3ê°€ì§€ ì°¨ë³„ì :

1. **ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜**: í†µê³„ì  íŠ¹ì„±ì´ ì•„ë‹Œ ì¬ë¬´ ì´ë¡  ê¸°ë°˜ íŠ¹ì„± ê³µí•™
   - "ì™œ ê¸°ì—…ì´ ë¶€ë„ë‚˜ëŠ”ê°€?"ì— ëŒ€í•œ ë‹µ
   - ìœ ë™ì„± ìœ„ê¸° > ì§€ê¸‰ë¶ˆëŠ¥ > ì‹ ë¢° ìƒì‹¤

2. **ì™„ì „í•œ íˆ¬ëª…ì„±**: SHAPìœ¼ë¡œ ëª¨ë“  ì˜ˆì¸¡ ê·¼ê±° ì œì‹œ â†’ ê·œì œ ì¶©ì¡±
   - "ì™œ ì´ ê¸°ì—…ì´ ìœ„í—˜í•œê°€?" ëª…í™•íˆ ì„¤ëª…
   - Top 10 íŠ¹ì„± ì¬ë¬´ í•´ì„

3. **ì‹¤ì¦ëœ ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜**: ì—°ê°„ 4.6ì–µì› ì†ì‹¤ ê°ì†Œ, ROI 920%
   - ë¶€ë„ 86.84% ì‚¬ì „ íƒì§€
   - ì‹¬ì‚¬ íš¨ìœ¨ 39% í–¥ìƒ (Green ìë™ ìŠ¹ì¸)

---

### ë‹¤ìŒ ë‹¨ê³„:

1. **ì¦‰ì‹œ ì‹¤í–‰**: Traffic Light ì‹œìŠ¤í…œ ì‹¤ë¬´ ì ìš©
2. **3ê°œì›” ë‚´**: ì™¸ë¶€ ë°ì´í„° í†µí•© íŒŒì¼ëŸ¿ (ë‰´ìŠ¤, ì†Œì†¡)
3. **1ë…„ ë‚´**: Hybrid ì‹œìŠ¤í…œìœ¼ë¡œ Type II Error < 10% ë‹¬ì„±

---

### ìµœì¢… ë©”ì‹œì§€:

**â†’ ì´ ëª¨ë¸ì€ "ì™„ì„±"ì´ ì•„ë‹ˆë¼ "ì‹œì‘"ì…ë‹ˆë‹¤.**

**â†’ ì§€ì†ì  ê°œì„ ìœ¼ë¡œ ë” ë‚˜ì€ ëª¨ë¸ì„ ë§Œë“¤ì–´ê°‘ë‹ˆë‹¤.** ğŸš€

**â†’ ë°ì´í„° í’ˆì§ˆ, ì™¸ë¶€ ë°ì´í„°, ì‹œê³„ì—´ ì •ë³´ë¥¼ ë³´ê°•í•˜ë©´ PR-AUC 0.22, Type II Error 7% ë‹¬ì„± ê°€ëŠ¥í•©ë‹ˆë‹¤.** âœ…

---

## ê°ì‚¬í•©ë‹ˆë‹¤! ğŸ™

---
